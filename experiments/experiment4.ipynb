{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/crux82/ganbert-pytorch/blob/main/GANBERT_pytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fUpqAwtN8rTA"
      },
      "source": [
        "# GAN-BERT (in Pytorch and compatible with HuggingFace)\n",
        "\n",
        "This is a Pytorch (+ **Huggingface** transformers) implementation of the GAN-BERT model from https://github.com/crux82/ganbert. While the original GAN-BERT was an extension of BERT, this implementation can be adapted to several architectures, ranging from Roberta to Albert!\n",
        "\n",
        "**NOTE**: given that this implementation is different from the original one in Tensorflow, some results can be slighty different.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q0m5KR34gmRH"
      },
      "source": [
        "Let's GO!\n",
        "\n",
        "Required Imports."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UIqpm34x2rms",
        "outputId": "d1ce9a8c-7e63-4e30-85a4-fd4c017545bc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers==4.3.2\n",
            "  Downloading transformers-4.3.2-py3-none-any.whl.metadata (36 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers==4.3.2) (3.16.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.3.2) (1.26.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from transformers==4.3.2) (24.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.3.2) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers==4.3.2) (2.32.3)\n",
            "Collecting sacremoses (from transformers==4.3.2)\n",
            "  Downloading sacremoses-0.1.1-py3-none-any.whl.metadata (8.3 kB)\n",
            "Collecting tokenizers<0.11,>=0.10.1 (from transformers==4.3.2)\n",
            "  Downloading tokenizers-0.10.3.tar.gz (212 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m212.7/212.7 kB\u001b[0m \u001b[31m19.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers==4.3.2) (4.67.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.3.2) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.3.2) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.3.2) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.3.2) (2024.12.14)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from sacremoses->transformers==4.3.2) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from sacremoses->transformers==4.3.2) (1.4.2)\n",
            "Downloading transformers-4.3.2-py3-none-any.whl (1.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m70.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sacremoses-0.1.1-py3-none-any.whl (897 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m897.5/897.5 kB\u001b[0m \u001b[31m56.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: tokenizers\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mBuilding wheel for tokenizers \u001b[0m\u001b[1;32m(\u001b[0m\u001b[32mpyproject.toml\u001b[0m\u001b[1;32m)\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Building wheel for tokenizers (pyproject.toml) ... \u001b[?25l\u001b[?25herror\n",
            "\u001b[31m  ERROR: Failed building wheel for tokenizers\u001b[0m\u001b[31m\n",
            "\u001b[0mFailed to build tokenizers\n",
            "\u001b[31mERROR: ERROR: Failed to build installable wheels for some pyproject.toml based projects (tokenizers)\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "GroupViT models are not usable since `tensorflow_probability` can't be loaded. It seems you have `tensorflow_probability` installed with the wrong tensorflow version.Please try to reinstall it following the instructions here: https://github.com/tensorflow/probability.\n",
            "TAPAS models are not usable since `tensorflow_probability` can't be loaded. It seems you have `tensorflow_probability` installed with the wrong tensorflow version. Please try to reinstall it following the instructions here: https://github.com/tensorflow/probability.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "!pip install transformers==4.3.2\n",
        "import torch\n",
        "import io\n",
        "import torch.nn.functional as F\n",
        "import random\n",
        "import numpy as np\n",
        "import time\n",
        "import math\n",
        "import datetime\n",
        "import torch.nn as nn\n",
        "from transformers import *\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "#!pip install torch==1.7.1+cu101 torchvision==0.8.2+cu101 -f https://download.pytorch.org/whl/torch_stable.html\n",
        "#!pip install sentencepiece\n",
        "import nltk\n",
        "from nltk.tokenize import sent_tokenize\n",
        "\n",
        "# Baixar o recurso de pontuação da NLTK (apenas na primeira vez)\n",
        "nltk.download(\"punkt\")\n",
        "\n",
        "\n",
        "##Set random values\n",
        "seed_val = 42\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "if torch.cuda.is_available():\n",
        "  torch.cuda.manual_seed_all(seed_val)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LeZgRup520II",
        "outputId": "2474af96-ea52-4d68-c990-8f43e2a3379d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla T4\n"
          ]
        }
      ],
      "source": [
        "# If there's a GPU available...\n",
        "if torch.cuda.is_available():\n",
        "    # Tell PyTorch to use the GPU.\n",
        "    device = torch.device(\"cuda\")\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "# If not...\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AU3ns8Ic7I-h"
      },
      "source": [
        "### Input Parameters\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jw0HC_hU3FUy",
        "outputId": "ef1ae3e8-0968-476e-d5c3-202a9666e317"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'ganbert'...\n",
            "remote: Enumerating objects: 181, done.\u001b[K\n",
            "remote: Counting objects: 100% (181/181), done.\u001b[K\n",
            "remote: Compressing objects: 100% (180/180), done.\u001b[K\n",
            "remote: Total 181 (delta 109), reused 0 (delta 0), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (181/181), 9.85 MiB | 6.00 MiB/s, done.\n",
            "Resolving deltas: 100% (109/109), done.\n"
          ]
        }
      ],
      "source": [
        "max_seq_length = 256 #comprimento máximo de sequência de tokens\n",
        "batch_size = 16 #número de exemplos de treinamento que serão processados\n",
        "\n",
        "#--------------------------------\n",
        "#  GAN-BERT specific parameters\n",
        "#--------------------------------\n",
        "# number of hidden layers in the generator,\n",
        "# each of the size of the output space\n",
        "num_hidden_layers_g = 3;\n",
        "# number of hidden layers in the discriminator,\n",
        "# each of the size of the input space\n",
        "num_hidden_layers_d = 2;\n",
        "# size of the generator's input noisy vectors\n",
        "noise_size = 128\n",
        "# dropout to be applied to discriminator's input vectors\n",
        "out_dropout_rate = 0.2\n",
        "\n",
        "# Replicate labeled data to balance poorly represented datasets,\n",
        "# e.g., less than 1% of labeled material\n",
        "apply_balance = True\n",
        "\n",
        "#--------------------------------\n",
        "#  Optimization parameters\n",
        "#--------------------------------\n",
        "learning_rate_discriminator = 3e-5\n",
        "learning_rate_generator = 3e-5\n",
        "epsilon = 1e-8 #evita divisão por zero\n",
        "num_train_epochs = 30 #número de épocas para treinar o modelo\n",
        "multi_gpu = True\n",
        "# Scheduler\n",
        "apply_scheduler = False\n",
        "warmup_proportion = 0.15\n",
        "# Print\n",
        "print_each_n_step = 10\n",
        "\n",
        "#--------------------------------\n",
        "#  Adopted Tranformer model\n",
        "#--------------------------------\n",
        "# Since this version is compatible with Huggingface transformers, you can uncomment\n",
        "# (or add) transformer models compatible with GAN\n",
        "\n",
        "model_name = \"bert-base-cased\"\n",
        "#model_name = \"bert-base-uncased\"\n",
        "#model_name = \"roberta-base\"\n",
        "#model_name = \"albert-base-v2\"\n",
        "#model_name = \"xlm-roberta-base\"\n",
        "#model_name = \"amazon/bort\"\n",
        "\n",
        "#--------------------------------\n",
        "#  Retrieve the TREC QC Dataset\n",
        "#--------------------------------\n",
        "! git clone https://github.com/mauriciokonrath/ganbert.git\n",
        "\n",
        "#  NOTE: in this setting 50 classes are involved\n",
        "labeled_file = \"./ganbert/data/standardized_labeled_monsanto_withoutSub.tsv\"\n",
        "unlabeled_file = \"./ganbert/data/final_extracted_descriptions.tsv\"\n",
        "test_filename = \"./ganbert/data/standardized_test_monsanto_withoutSub.tsv\"\n",
        "\n",
        "#categorias de rótulos que o modelo deve aprender a classificar.\n",
        "#categorias de rótulos que o modelo deve aprender a classificar.\n",
        "label_list = [\"UNK_UNK\",\"GHOST_ghost\", \"TOXIC_toxic\",\n",
        "              \"CHEMI_chemi\", \"REGUL_regul\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R6Q5jzVioTHb"
      },
      "source": [
        "Load the Tranformer Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "9a21f5cb59334b87bf88778ace59b233",
            "0d6d878f31a7486eb711a9df7f2f8416",
            "64fa51f191a34d95b71b43dd5262d908",
            "75adc85ad5a0491f9b7ce80a80716f87",
            "1b65832dd18545f4b966eb4fcd35ff1f",
            "628fc8339d0e44af8fbab2a6af4f79ec",
            "009a91515e8846edac4ef20be29014e9",
            "fd0e9069580943888f7f5f64b827cf20",
            "6c60348aedfb4b3e92471904270519bb",
            "a5a450af5a5d42fcb138fc7bfee7403f",
            "9fcff26dda244381be993917b516a9b3",
            "25bc61ddf9394550ad8db1e31596c378",
            "3b2c7a4b9eec41f9a0111826b0e449a5",
            "8a366b05f1904b8480dedef846ecea7d",
            "000c4bee81da46b885fdf2fb6d3d674a",
            "91d85aef51a44af2b2c52b4a8e01ce2f",
            "f9471716df1344af87261b1af26a6834",
            "063a295338614e538721e088877bde5c",
            "9501de1fb478463a9ac0301aee08ca23",
            "0853add93b45427cad0bbb67a13bf0ac",
            "6ce0e5ccfe854f1a876988e271273195",
            "91a3a1a5b0b74e89920feb296f59aeb2",
            "fdf7f385fe8347de8cc2057a45842ca8",
            "5f2e004a3ebd4be59ba2651622b8e8a6",
            "e11f7ab14986410e82e0a6a72ba01f22",
            "eb5c3e6a8dce4528ba7cef0ffd39b805",
            "893adb802cf04a24ad876c67e1eae70c",
            "073bf6a5a2294eb79bdf72110ee13629",
            "42f6b5b7b44142659d0204bc3e8898e0",
            "3246a158f2e8432cb5e602aa33f0fae2",
            "dcd7a4bd423442a1b00136cd77d6e9c7",
            "6f2e60db4d954148b8bdcc2603c9d9b2",
            "9e0aa2dc9db24a8983d22758285784fc",
            "011a4c0c8ea94a25b147ee45edada1d2",
            "10bd7328a03f4289a85a058713b90701",
            "ad2badd2f89646b4a2eb4608bb42203b",
            "657fd587a36f42478b08d4f94c02ed89",
            "50b819c91cb94d449805be3dca3191fb",
            "55c6ef6cf98f4fccb5e4179abb69c6c2",
            "c173eb4c372a480db771517061628a00",
            "cc7a8238e5404c54889823326ab82729",
            "ccc8389be70f43c693c77458efba44d1",
            "6a243193714c4aefa154916cfff9968f",
            "2714b7ba9ffd4901bd17e935eb208b95",
            "6911421a843844a58937aa2997005a6f",
            "1d19b47d5c78419bb4a5689110f8cfb3",
            "17d5ae7a300b49648fc36393bf975152",
            "cea6feff0311474bb22796a487ef52d2",
            "f4595f15494645f29c0214d396c202a5",
            "cf52d3b7cd4242e98063810baae49ea8",
            "681f5fec5ac94317beab08b2508b8f67",
            "b77df58e65504b79b83506e78d1f4f50",
            "d2f258d7588b49519b9d5cd5ee1d8019",
            "ead69b417e754be6a4132868e75928b0",
            "c989f4f3b7df46958d773423df5349e9"
          ]
        },
        "id": "gxghkkZq3Gbn",
        "outputId": "e8e60c19-ceb0-497b-be28-4967a3e3c794"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9a21f5cb59334b87bf88778ace59b233"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--bert-base-cased/snapshots/cd5ef92a9fb2f889e972770a36d4ed042daf221e/config.json\n",
            "Model config BertConfig {\n",
            "  \"_name_or_path\": \"bert-base-cased\",\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.47.1\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 28996\n",
            "}\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/436M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "25bc61ddf9394550ad8db1e31596c378"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading weights file model.safetensors from cache at /root/.cache/huggingface/hub/models--bert-base-cased/snapshots/cd5ef92a9fb2f889e972770a36d4ed042daf221e/model.safetensors\n",
            "A pretrained model of type `BertModel` contains parameters that have been renamed internally (a few are listed below but more are present in the model):\n",
            "* `bert.embeddings.LayerNorm.gamma` -> `bert.embeddings.LayerNorm.weight`\n",
            "* `bert.encoder.layer.0.attention.output.LayerNorm.gamma` -> `{'bert.embeddings.LayerNorm.gamma': 'bert.embeddings.LayerNorm.weight', 'bert.encoder.layer.0.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.0.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.output.LayerNorm.gamma': {...}, 'cls.predictions.transform.LayerNorm.gamma': {...}}`\n",
            "* `bert.encoder.layer.0.output.LayerNorm.gamma` -> `{'bert.embeddings.LayerNorm.gamma': 'bert.embeddings.LayerNorm.weight', 'bert.encoder.layer.0.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.0.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.output.LayerNorm.gamma': {...}, 'cls.predictions.transform.LayerNorm.gamma': {...}}`\n",
            "* `bert.encoder.layer.1.attention.output.LayerNorm.gamma` -> `{'bert.embeddings.LayerNorm.gamma': 'bert.embeddings.LayerNorm.weight', 'bert.encoder.layer.0.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.0.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.output.LayerNorm.gamma': {...}, 'cls.predictions.transform.LayerNorm.gamma': {...}}`\n",
            "* `bert.encoder.layer.1.output.LayerNorm.gamma` -> `{'bert.embeddings.LayerNorm.gamma': 'bert.embeddings.LayerNorm.weight', 'bert.encoder.layer.0.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.0.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.output.LayerNorm.gamma': {...}, 'cls.predictions.transform.LayerNorm.gamma': {...}}`\n",
            "* `bert.encoder.layer.10.attention.output.LayerNorm.gamma` -> `{'bert.embeddings.LayerNorm.gamma': 'bert.embeddings.LayerNorm.weight', 'bert.encoder.layer.0.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.0.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.output.LayerNorm.gamma': {...}, 'cls.predictions.transform.LayerNorm.gamma': {...}}`\n",
            "* `bert.encoder.layer.10.output.LayerNorm.gamma` -> `{'bert.embeddings.LayerNorm.gamma': 'bert.embeddings.LayerNorm.weight', 'bert.encoder.layer.0.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.0.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.output.LayerNorm.gamma': {...}, 'cls.predictions.transform.LayerNorm.gamma': {...}}`\n",
            "* `bert.encoder.layer.11.attention.output.LayerNorm.gamma` -> `{'bert.embeddings.LayerNorm.gamma': 'bert.embeddings.LayerNorm.weight', 'bert.encoder.layer.0.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.0.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.output.LayerNorm.gamma': {...}, 'cls.predictions.transform.LayerNorm.gamma': {...}}`\n",
            "* `bert.encoder.layer.11.output.LayerNorm.gamma` -> `{'bert.embeddings.LayerNorm.gamma': 'bert.embeddings.LayerNorm.weight', 'bert.encoder.layer.0.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.0.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.output.LayerNorm.gamma': {...}, 'cls.predictions.transform.LayerNorm.gamma': {...}}`\n",
            "* `bert.encoder.layer.2.attention.output.LayerNorm.gamma` -> `{'bert.embeddings.LayerNorm.gamma': 'bert.embeddings.LayerNorm.weight', 'bert.encoder.layer.0.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.0.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.output.LayerNorm.gamma': {...}, 'cls.predictions.transform.LayerNorm.gamma': {...}}`\n",
            "* `bert.encoder.layer.2.output.LayerNorm.gamma` -> `{'bert.embeddings.LayerNorm.gamma': 'bert.embeddings.LayerNorm.weight', 'bert.encoder.layer.0.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.0.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.output.LayerNorm.gamma': {...}, 'cls.predictions.transform.LayerNorm.gamma': {...}}`\n",
            "* `bert.encoder.layer.3.attention.output.LayerNorm.gamma` -> `{'bert.embeddings.LayerNorm.gamma': 'bert.embeddings.LayerNorm.weight', 'bert.encoder.layer.0.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.0.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.output.LayerNorm.gamma': {...}, 'cls.predictions.transform.LayerNorm.gamma': {...}}`\n",
            "* `bert.encoder.layer.3.output.LayerNorm.gamma` -> `{'bert.embeddings.LayerNorm.gamma': 'bert.embeddings.LayerNorm.weight', 'bert.encoder.layer.0.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.0.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.output.LayerNorm.gamma': {...}, 'cls.predictions.transform.LayerNorm.gamma': {...}}`\n",
            "* `bert.encoder.layer.4.attention.output.LayerNorm.gamma` -> `{'bert.embeddings.LayerNorm.gamma': 'bert.embeddings.LayerNorm.weight', 'bert.encoder.layer.0.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.0.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.output.LayerNorm.gamma': {...}, 'cls.predictions.transform.LayerNorm.gamma': {...}}`\n",
            "* `bert.encoder.layer.4.output.LayerNorm.gamma` -> `{'bert.embeddings.LayerNorm.gamma': 'bert.embeddings.LayerNorm.weight', 'bert.encoder.layer.0.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.0.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.output.LayerNorm.gamma': {...}, 'cls.predictions.transform.LayerNorm.gamma': {...}}`\n",
            "* `bert.encoder.layer.5.attention.output.LayerNorm.gamma` -> `{'bert.embeddings.LayerNorm.gamma': 'bert.embeddings.LayerNorm.weight', 'bert.encoder.layer.0.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.0.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.output.LayerNorm.gamma': {...}, 'cls.predictions.transform.LayerNorm.gamma': {...}}`\n",
            "* `bert.encoder.layer.5.output.LayerNorm.gamma` -> `{'bert.embeddings.LayerNorm.gamma': 'bert.embeddings.LayerNorm.weight', 'bert.encoder.layer.0.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.0.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.output.LayerNorm.gamma': {...}, 'cls.predictions.transform.LayerNorm.gamma': {...}}`\n",
            "* `bert.encoder.layer.6.attention.output.LayerNorm.gamma` -> `{'bert.embeddings.LayerNorm.gamma': 'bert.embeddings.LayerNorm.weight', 'bert.encoder.layer.0.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.0.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.output.LayerNorm.gamma': {...}, 'cls.predictions.transform.LayerNorm.gamma': {...}}`\n",
            "* `bert.encoder.layer.6.output.LayerNorm.gamma` -> `{'bert.embeddings.LayerNorm.gamma': 'bert.embeddings.LayerNorm.weight', 'bert.encoder.layer.0.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.0.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.output.LayerNorm.gamma': {...}, 'cls.predictions.transform.LayerNorm.gamma': {...}}`\n",
            "* `bert.encoder.layer.7.attention.output.LayerNorm.gamma` -> `{'bert.embeddings.LayerNorm.gamma': 'bert.embeddings.LayerNorm.weight', 'bert.encoder.layer.0.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.0.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.output.LayerNorm.gamma': {...}, 'cls.predictions.transform.LayerNorm.gamma': {...}}`\n",
            "* `bert.encoder.layer.7.output.LayerNorm.gamma` -> `{'bert.embeddings.LayerNorm.gamma': 'bert.embeddings.LayerNorm.weight', 'bert.encoder.layer.0.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.0.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.output.LayerNorm.gamma': {...}, 'cls.predictions.transform.LayerNorm.gamma': {...}}`\n",
            "* `bert.encoder.layer.8.attention.output.LayerNorm.gamma` -> `{'bert.embeddings.LayerNorm.gamma': 'bert.embeddings.LayerNorm.weight', 'bert.encoder.layer.0.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.0.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.output.LayerNorm.gamma': {...}, 'cls.predictions.transform.LayerNorm.gamma': {...}}`\n",
            "* `bert.encoder.layer.8.output.LayerNorm.gamma` -> `{'bert.embeddings.LayerNorm.gamma': 'bert.embeddings.LayerNorm.weight', 'bert.encoder.layer.0.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.0.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.output.LayerNorm.gamma': {...}, 'cls.predictions.transform.LayerNorm.gamma': {...}}`\n",
            "* `bert.encoder.layer.9.attention.output.LayerNorm.gamma` -> `{'bert.embeddings.LayerNorm.gamma': 'bert.embeddings.LayerNorm.weight', 'bert.encoder.layer.0.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.0.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.output.LayerNorm.gamma': {...}, 'cls.predictions.transform.LayerNorm.gamma': {...}}`\n",
            "* `bert.encoder.layer.9.output.LayerNorm.gamma` -> `{'bert.embeddings.LayerNorm.gamma': 'bert.embeddings.LayerNorm.weight', 'bert.encoder.layer.0.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.0.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.output.LayerNorm.gamma': {...}, 'cls.predictions.transform.LayerNorm.gamma': {...}}`\n",
            "* `cls.predictions.transform.LayerNorm.gamma` -> `{'bert.embeddings.LayerNorm.gamma': 'bert.embeddings.LayerNorm.weight', 'bert.encoder.layer.0.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.0.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.1.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.10.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.11.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.2.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.3.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.4.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.5.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.6.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.7.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.8.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.gamma': {...}, 'bert.encoder.layer.9.output.LayerNorm.gamma': {...}, 'cls.predictions.transform.LayerNorm.gamma': {...}}`\n",
            "* `bert.embeddings.LayerNorm.beta` -> `bert.embeddings.LayerNorm.bias`\n",
            "* `bert.encoder.layer.0.attention.output.LayerNorm.beta` -> `{'bert.embeddings.LayerNorm.beta': 'bert.embeddings.LayerNorm.bias', 'bert.encoder.layer.0.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.0.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.output.LayerNorm.beta': {...}, 'cls.predictions.transform.LayerNorm.beta': {...}}`\n",
            "* `bert.encoder.layer.0.output.LayerNorm.beta` -> `{'bert.embeddings.LayerNorm.beta': 'bert.embeddings.LayerNorm.bias', 'bert.encoder.layer.0.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.0.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.output.LayerNorm.beta': {...}, 'cls.predictions.transform.LayerNorm.beta': {...}}`\n",
            "* `bert.encoder.layer.1.attention.output.LayerNorm.beta` -> `{'bert.embeddings.LayerNorm.beta': 'bert.embeddings.LayerNorm.bias', 'bert.encoder.layer.0.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.0.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.output.LayerNorm.beta': {...}, 'cls.predictions.transform.LayerNorm.beta': {...}}`\n",
            "* `bert.encoder.layer.1.output.LayerNorm.beta` -> `{'bert.embeddings.LayerNorm.beta': 'bert.embeddings.LayerNorm.bias', 'bert.encoder.layer.0.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.0.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.output.LayerNorm.beta': {...}, 'cls.predictions.transform.LayerNorm.beta': {...}}`\n",
            "* `bert.encoder.layer.10.attention.output.LayerNorm.beta` -> `{'bert.embeddings.LayerNorm.beta': 'bert.embeddings.LayerNorm.bias', 'bert.encoder.layer.0.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.0.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.output.LayerNorm.beta': {...}, 'cls.predictions.transform.LayerNorm.beta': {...}}`\n",
            "* `bert.encoder.layer.10.output.LayerNorm.beta` -> `{'bert.embeddings.LayerNorm.beta': 'bert.embeddings.LayerNorm.bias', 'bert.encoder.layer.0.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.0.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.output.LayerNorm.beta': {...}, 'cls.predictions.transform.LayerNorm.beta': {...}}`\n",
            "* `bert.encoder.layer.11.attention.output.LayerNorm.beta` -> `{'bert.embeddings.LayerNorm.beta': 'bert.embeddings.LayerNorm.bias', 'bert.encoder.layer.0.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.0.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.output.LayerNorm.beta': {...}, 'cls.predictions.transform.LayerNorm.beta': {...}}`\n",
            "* `bert.encoder.layer.11.output.LayerNorm.beta` -> `{'bert.embeddings.LayerNorm.beta': 'bert.embeddings.LayerNorm.bias', 'bert.encoder.layer.0.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.0.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.output.LayerNorm.beta': {...}, 'cls.predictions.transform.LayerNorm.beta': {...}}`\n",
            "* `bert.encoder.layer.2.attention.output.LayerNorm.beta` -> `{'bert.embeddings.LayerNorm.beta': 'bert.embeddings.LayerNorm.bias', 'bert.encoder.layer.0.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.0.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.output.LayerNorm.beta': {...}, 'cls.predictions.transform.LayerNorm.beta': {...}}`\n",
            "* `bert.encoder.layer.2.output.LayerNorm.beta` -> `{'bert.embeddings.LayerNorm.beta': 'bert.embeddings.LayerNorm.bias', 'bert.encoder.layer.0.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.0.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.output.LayerNorm.beta': {...}, 'cls.predictions.transform.LayerNorm.beta': {...}}`\n",
            "* `bert.encoder.layer.3.attention.output.LayerNorm.beta` -> `{'bert.embeddings.LayerNorm.beta': 'bert.embeddings.LayerNorm.bias', 'bert.encoder.layer.0.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.0.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.output.LayerNorm.beta': {...}, 'cls.predictions.transform.LayerNorm.beta': {...}}`\n",
            "* `bert.encoder.layer.3.output.LayerNorm.beta` -> `{'bert.embeddings.LayerNorm.beta': 'bert.embeddings.LayerNorm.bias', 'bert.encoder.layer.0.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.0.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.output.LayerNorm.beta': {...}, 'cls.predictions.transform.LayerNorm.beta': {...}}`\n",
            "* `bert.encoder.layer.4.attention.output.LayerNorm.beta` -> `{'bert.embeddings.LayerNorm.beta': 'bert.embeddings.LayerNorm.bias', 'bert.encoder.layer.0.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.0.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.output.LayerNorm.beta': {...}, 'cls.predictions.transform.LayerNorm.beta': {...}}`\n",
            "* `bert.encoder.layer.4.output.LayerNorm.beta` -> `{'bert.embeddings.LayerNorm.beta': 'bert.embeddings.LayerNorm.bias', 'bert.encoder.layer.0.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.0.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.output.LayerNorm.beta': {...}, 'cls.predictions.transform.LayerNorm.beta': {...}}`\n",
            "* `bert.encoder.layer.5.attention.output.LayerNorm.beta` -> `{'bert.embeddings.LayerNorm.beta': 'bert.embeddings.LayerNorm.bias', 'bert.encoder.layer.0.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.0.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.output.LayerNorm.beta': {...}, 'cls.predictions.transform.LayerNorm.beta': {...}}`\n",
            "* `bert.encoder.layer.5.output.LayerNorm.beta` -> `{'bert.embeddings.LayerNorm.beta': 'bert.embeddings.LayerNorm.bias', 'bert.encoder.layer.0.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.0.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.output.LayerNorm.beta': {...}, 'cls.predictions.transform.LayerNorm.beta': {...}}`\n",
            "* `bert.encoder.layer.6.attention.output.LayerNorm.beta` -> `{'bert.embeddings.LayerNorm.beta': 'bert.embeddings.LayerNorm.bias', 'bert.encoder.layer.0.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.0.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.output.LayerNorm.beta': {...}, 'cls.predictions.transform.LayerNorm.beta': {...}}`\n",
            "* `bert.encoder.layer.6.output.LayerNorm.beta` -> `{'bert.embeddings.LayerNorm.beta': 'bert.embeddings.LayerNorm.bias', 'bert.encoder.layer.0.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.0.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.output.LayerNorm.beta': {...}, 'cls.predictions.transform.LayerNorm.beta': {...}}`\n",
            "* `bert.encoder.layer.7.attention.output.LayerNorm.beta` -> `{'bert.embeddings.LayerNorm.beta': 'bert.embeddings.LayerNorm.bias', 'bert.encoder.layer.0.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.0.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.output.LayerNorm.beta': {...}, 'cls.predictions.transform.LayerNorm.beta': {...}}`\n",
            "* `bert.encoder.layer.7.output.LayerNorm.beta` -> `{'bert.embeddings.LayerNorm.beta': 'bert.embeddings.LayerNorm.bias', 'bert.encoder.layer.0.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.0.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.output.LayerNorm.beta': {...}, 'cls.predictions.transform.LayerNorm.beta': {...}}`\n",
            "* `bert.encoder.layer.8.attention.output.LayerNorm.beta` -> `{'bert.embeddings.LayerNorm.beta': 'bert.embeddings.LayerNorm.bias', 'bert.encoder.layer.0.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.0.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.output.LayerNorm.beta': {...}, 'cls.predictions.transform.LayerNorm.beta': {...}}`\n",
            "* `bert.encoder.layer.8.output.LayerNorm.beta` -> `{'bert.embeddings.LayerNorm.beta': 'bert.embeddings.LayerNorm.bias', 'bert.encoder.layer.0.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.0.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.output.LayerNorm.beta': {...}, 'cls.predictions.transform.LayerNorm.beta': {...}}`\n",
            "* `bert.encoder.layer.9.attention.output.LayerNorm.beta` -> `{'bert.embeddings.LayerNorm.beta': 'bert.embeddings.LayerNorm.bias', 'bert.encoder.layer.0.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.0.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.output.LayerNorm.beta': {...}, 'cls.predictions.transform.LayerNorm.beta': {...}}`\n",
            "* `bert.encoder.layer.9.output.LayerNorm.beta` -> `{'bert.embeddings.LayerNorm.beta': 'bert.embeddings.LayerNorm.bias', 'bert.encoder.layer.0.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.0.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.output.LayerNorm.beta': {...}, 'cls.predictions.transform.LayerNorm.beta': {...}}`\n",
            "* `cls.predictions.transform.LayerNorm.beta` -> `{'bert.embeddings.LayerNorm.beta': 'bert.embeddings.LayerNorm.bias', 'bert.encoder.layer.0.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.0.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.1.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.10.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.11.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.2.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.3.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.4.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.5.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.6.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.7.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.8.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.attention.output.LayerNorm.beta': {...}, 'bert.encoder.layer.9.output.LayerNorm.beta': {...}, 'cls.predictions.transform.LayerNorm.beta': {...}}`\n",
            "If you are using a model from the Hub, consider submitting a PR to adjust these weights and help future users.\n",
            "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the weights of BertModel were initialized from the model checkpoint at bert-base-cased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertModel for predictions without further training.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/49.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fdf7f385fe8347de8cc2057a45842ca8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--bert-base-cased/snapshots/cd5ef92a9fb2f889e972770a36d4ed042daf221e/config.json\n",
            "Model config BertConfig {\n",
            "  \"_name_or_path\": \"bert-base-cased\",\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.47.1\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 28996\n",
            "}\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/213k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "011a4c0c8ea94a25b147ee45edada1d2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/436k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6911421a843844a58937aa2997005a6f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading file vocab.txt from cache at /root/.cache/huggingface/hub/models--bert-base-cased/snapshots/cd5ef92a9fb2f889e972770a36d4ed042daf221e/vocab.txt\n",
            "loading file tokenizer.json from cache at /root/.cache/huggingface/hub/models--bert-base-cased/snapshots/cd5ef92a9fb2f889e972770a36d4ed042daf221e/tokenizer.json\n",
            "loading file added_tokens.json from cache at None\n",
            "loading file special_tokens_map.json from cache at None\n",
            "loading file tokenizer_config.json from cache at /root/.cache/huggingface/hub/models--bert-base-cased/snapshots/cd5ef92a9fb2f889e972770a36d4ed042daf221e/tokenizer_config.json\n",
            "loading file chat_template.jinja from cache at None\n",
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--bert-base-cased/snapshots/cd5ef92a9fb2f889e972770a36d4ed042daf221e/config.json\n",
            "Model config BertConfig {\n",
            "  \"_name_or_path\": \"bert-base-cased\",\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.47.1\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 28996\n",
            "}\n",
            "\n"
          ]
        }
      ],
      "source": [
        "transformer = AutoModel.from_pretrained(model_name)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rd_ixn5qn_zV"
      },
      "source": [
        "Function required to load the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "W7cP8q7K3BId"
      },
      "outputs": [],
      "source": [
        "#ler um arquivo de texto contendo dados de perguntas e criar exemplos de treinamento ou desenvolvimento\n",
        "def get_qc_examples(input_file):\n",
        "  \"\"\"Creates examples for the training and dev sets.\"\"\"\n",
        "  examples = []\n",
        "\n",
        "  with open(input_file, 'r') as f:\n",
        "      contents = f.read()\n",
        "      file_as_list = contents.splitlines()\n",
        "      for line in file_as_list[1:]:\n",
        "          split = line.split(\" \")\n",
        "          question = ' '.join(split[1:])\n",
        "\n",
        "          text_a = question\n",
        "          inn_split = split[0].split(\":\")\n",
        "          label = inn_split[0] + \"_\" + inn_split[1]\n",
        "          examples.append((text_a, label))\n",
        "      f.close()\n",
        "\n",
        "  return examples"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K43tOavNqib4"
      },
      "source": [
        "**Load** the input QC dataset (fine-grained)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "cXCwFyF2qhw7"
      },
      "outputs": [],
      "source": [
        "#Load the examples\n",
        "labeled_examples = get_qc_examples(labeled_file)\n",
        "unlabeled_examples = get_qc_examples(unlabeled_file)\n",
        "test_examples = get_qc_examples(test_filename)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JBhaW5vBfR6B"
      },
      "source": [
        "Functions required to convert examples into Dataloader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "fmKL5AD7I4Zg"
      },
      "outputs": [],
      "source": [
        "def generate_data_loader(input_examples, label_masks, label_map, do_shuffle = False, balance_label_examples = False):\n",
        "  '''\n",
        "  Generate a Dataloader given the input examples, eventually masked if they are\n",
        "  to be considered NOT labeled.\n",
        "  '''\n",
        "  examples = []\n",
        "\n",
        "  # Count the percentage of labeled examples\n",
        "  num_labeled_examples = 0\n",
        "  for label_mask in label_masks:\n",
        "    if label_mask:\n",
        "      num_labeled_examples += 1\n",
        "  label_mask_rate = num_labeled_examples/len(input_examples)\n",
        "\n",
        "  # if required it applies the balance\n",
        "  for index, ex in enumerate(input_examples):\n",
        "    if label_mask_rate == 1 or not balance_label_examples:\n",
        "      examples.append((ex, label_masks[index]))\n",
        "    else:\n",
        "      # IT SIMULATE A LABELED EXAMPLE\n",
        "      if label_masks[index]:\n",
        "        balance = int(1/label_mask_rate)\n",
        "        balance = int(math.log(balance,2))\n",
        "        if balance < 1:\n",
        "          balance = 1\n",
        "        for b in range(0, int(balance)):\n",
        "          examples.append((ex, label_masks[index]))\n",
        "      else:\n",
        "        examples.append((ex, label_masks[index]))\n",
        "\n",
        "  #-----------------------------------------------\n",
        "  # Generate input examples to the Transformer\n",
        "  #-----------------------------------------------\n",
        "  input_ids = []\n",
        "  input_mask_array = []\n",
        "  label_mask_array = []\n",
        "  label_id_array = []\n",
        "\n",
        "  # Tokenization\n",
        "  for (text, label_mask) in examples:\n",
        "    encoded_sent = tokenizer.encode(text[0], add_special_tokens=True, max_length=max_seq_length, padding=\"max_length\", truncation=True)\n",
        "    input_ids.append(encoded_sent)\n",
        "    label_id_array.append(label_map[text[1]])\n",
        "    label_mask_array.append(label_mask)\n",
        "\n",
        "  # Attention to token (to ignore padded input wordpieces)\n",
        "  for sent in input_ids:\n",
        "    att_mask = [int(token_id > 0) for token_id in sent]\n",
        "    input_mask_array.append(att_mask)\n",
        "  # Convertion to Tensor\n",
        "  input_ids = torch.tensor(input_ids)\n",
        "  input_mask_array = torch.tensor(input_mask_array)\n",
        "  label_id_array = torch.tensor(label_id_array, dtype=torch.long)\n",
        "  label_mask_array = torch.tensor(label_mask_array)\n",
        "\n",
        "  # Building the TensorDataset\n",
        "  dataset = TensorDataset(input_ids, input_mask_array, label_id_array, label_mask_array)\n",
        "\n",
        "  if do_shuffle:\n",
        "    sampler = RandomSampler\n",
        "  else:\n",
        "    sampler = SequentialSampler\n",
        "\n",
        "  # Building the DataLoader\n",
        "  return DataLoader(\n",
        "              dataset,  # The training samples.\n",
        "              sampler = sampler(dataset),\n",
        "              batch_size = batch_size) # Trains with this batch size.\n",
        "\n",
        "def format_time(elapsed):\n",
        "    '''\n",
        "    Takes a time in seconds and returns a string hh:mm:ss\n",
        "    '''\n",
        "    # Round to the nearest second.\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    # Format as hh:mm:ss\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nCRJWsuxjGqb"
      },
      "source": [
        "Prepares input data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "WINaaC0KjIDx"
      },
      "outputs": [],
      "source": [
        "#MODIFICADO\n",
        "def generate_data_loader(input_examples, label_masks, label_map, do_shuffle = False, balance_label_examples = False):\n",
        "  '''\n",
        "  Generate a Dataloader given the input examples, eventually masked if they are\n",
        "  to be considered NOT labeled.\n",
        "  '''\n",
        "  examples = []\n",
        "\n",
        "  # Count the percentage of labeled examples\n",
        "  num_labeled_examples = 0\n",
        "  for label_mask in label_masks:\n",
        "    if label_mask:\n",
        "      num_labeled_examples += 1\n",
        "  label_mask_rate = num_labeled_examples/len(input_examples)\n",
        "\n",
        "\n",
        "  # if required it applies the balance\n",
        "  for index, ex in enumerate(input_examples):\n",
        "    if label_mask_rate == 1 or not balance_label_examples:\n",
        "      examples.append((ex, label_masks[index]))\n",
        "    else:\n",
        "      # IT SIMULATE A LABELED EXAMPLE\n",
        "      if label_masks[index]:\n",
        "        balance = int(1/label_mask_rate)\n",
        "        balance = int(math.log(balance,2))\n",
        "        if balance < 1:\n",
        "          balance = 1\n",
        "        for b in range(0, int(balance)):\n",
        "          examples.append((ex, label_masks[index]))\n",
        "      else:\n",
        "        examples.append((ex, label_masks[index]))\n",
        "\n",
        "  #-----------------------------------------------\n",
        "  # Generate input examples to the Transformer\n",
        "  #-----------------------------------------------\n",
        "  input_ids = []\n",
        "  input_mask_array = []\n",
        "  label_mask_array = []\n",
        "  label_id_array = []\n",
        "\n",
        "  # Tokenization\n",
        "  for (text, label_mask) in examples:\n",
        "    # Clean up the label by removing extraneous characters and text\n",
        "    label = text[1].split('\\t')[0]\n",
        "    encoded_sent = tokenizer.encode(text[0], add_special_tokens=True, max_length=max_seq_length, padding=\"max_length\", truncation=True)\n",
        "    input_ids.append(encoded_sent)\n",
        "\n",
        "    # Check if the label is in the label_map\n",
        "    if label in label_map:\n",
        "      label_id_array.append(label_map[label])\n",
        "    else:\n",
        "      # Handle the case where the label is not in label_map\n",
        "      # Here we assign the label 'UNK_UNK' if not found\n",
        "      label_id_array.append(label_map['UNK_UNK'])\n",
        "\n",
        "    label_mask_array.append(label_mask)\n",
        "\n",
        "  # Attention to token (to ignore padded input wordpieces)\n",
        "  for sent in input_ids:\n",
        "    att_mask = [int(token_id > 0) for token_id in sent]\n",
        "    input_mask_array.append(att_mask)\n",
        "  # Convertion to Tensor\n",
        "  input_ids = torch.tensor(input_ids)\n",
        "  input_mask_array = torch.tensor(input_mask_array)\n",
        "  label_id_array = torch.tensor(label_id_array, dtype=torch.long)\n",
        "  label_mask_array = torch.tensor(label_mask_array)\n",
        "\n",
        "  # Building the TensorDataset\n",
        "  dataset = TensorDataset(input_ids, input_mask_array, label_id_array, label_mask_array)\n",
        "\n",
        "  if do_shuffle:\n",
        "    sampler = RandomSampler\n",
        "  else:\n",
        "    sampler = SequentialSampler\n",
        "\n",
        "  # Building the DataLoader\n",
        "  return DataLoader(\n",
        "              dataset,  # The training samples.\n",
        "              sampler = sampler(dataset),\n",
        "              batch_size = batch_size) # Trains with this batch size.\n",
        "\n",
        "def format_time(elapsed):\n",
        "    '''\n",
        "    Takes a time in seconds and returns a string hh:mm:ss\n",
        "    '''\n",
        "    # Round to the nearest second.\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    # Format as hh:mm:ss\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Do3O-VeefT3g"
      },
      "source": [
        "Convert the input examples into DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4c-nsMXlKX-D",
        "outputId": "244f3961-56d9-4a65-b893-602692441fbb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-8-b6233fd3d80c>:66: DeprecationWarning: In future, it will be an error for 'np.bool_' scalars to be interpreted as an index\n",
            "  label_mask_array = torch.tensor(label_mask_array)\n"
          ]
        }
      ],
      "source": [
        "label_map = {}\n",
        "for (i, label) in enumerate(label_list):\n",
        "  label_map[label] = i\n",
        "#------------------------------\n",
        "#   Load the train dataset\n",
        "#------------------------------\n",
        "train_examples = labeled_examples\n",
        "#The labeled (train) dataset is assigned with a mask set to True\n",
        "train_label_masks = np.ones(len(labeled_examples), dtype=bool)\n",
        "#If unlabel examples are available\n",
        "if unlabeled_examples:\n",
        "  train_examples = train_examples + unlabeled_examples\n",
        "  #The unlabeled (train) dataset is assigned with a mask set to False\n",
        "  tmp_masks = np.zeros(len(unlabeled_examples), dtype=bool)\n",
        "  train_label_masks = np.concatenate([train_label_masks,tmp_masks])\n",
        "\n",
        "train_dataloader = generate_data_loader(train_examples, train_label_masks, label_map, do_shuffle = True, balance_label_examples = apply_balance)\n",
        "\n",
        "#------------------------------\n",
        "#   Load the test dataset\n",
        "#------------------------------\n",
        "#The labeled (test) dataset is assigned with a mask set to True\n",
        "test_label_masks = np.ones(len(test_examples), dtype=bool)\n",
        "\n",
        "test_dataloader = generate_data_loader(test_examples, test_label_masks, label_map, do_shuffle = False, balance_label_examples = False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Ihcw3vquaQm"
      },
      "source": [
        "We define the Generator and Discriminator as discussed in https://www.aclweb.org/anthology/2020.acl-main.191/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "18kY64-n3I6y"
      },
      "outputs": [],
      "source": [
        "#------------------------------\n",
        "#   The Generator as in\n",
        "#   https://www.aclweb.org/anthology/2020.acl-main.191/\n",
        "#   https://github.com/crux82/ganbert\n",
        "#------------------------------\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self, noise_size=100, output_size=512, hidden_sizes=[512], dropout_rate=0.1):\n",
        "        super(Generator, self).__init__()\n",
        "        layers = []\n",
        "        hidden_sizes = [noise_size] + hidden_sizes\n",
        "        for i in range(len(hidden_sizes)-1):\n",
        "            layers.extend([nn.Linear(hidden_sizes[i], hidden_sizes[i+1]), nn.LeakyReLU(0.2, inplace=True), nn.Dropout(dropout_rate)])\n",
        "\n",
        "        layers.append(nn.Linear(hidden_sizes[-1],output_size))\n",
        "        self.layers = nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, noise):\n",
        "        output_rep = self.layers(noise)\n",
        "        return output_rep\n",
        "\n",
        "#------------------------------\n",
        "#   The Discriminator\n",
        "#   https://www.aclweb.org/anthology/2020.acl-main.191/\n",
        "#   https://github.com/crux82/ganbert\n",
        "#------------------------------\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, input_size=512, hidden_sizes=[512], num_labels=2, dropout_rate=0.1):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.input_dropout = nn.Dropout(p=dropout_rate)\n",
        "        layers = []\n",
        "        hidden_sizes = [input_size] + hidden_sizes\n",
        "        for i in range(len(hidden_sizes)-1):\n",
        "            layers.extend([nn.Linear(hidden_sizes[i], hidden_sizes[i+1]), nn.LeakyReLU(0.2, inplace=True), nn.Dropout(dropout_rate)])\n",
        "\n",
        "        self.layers = nn.Sequential(*layers) #per il flatten\n",
        "        self.logit = nn.Linear(hidden_sizes[-1],num_labels+1) # +1 for the probability of this sample being fake/real.\n",
        "        self.softmax = nn.Softmax(dim=-1)\n",
        "\n",
        "    def forward(self, input_rep):\n",
        "        input_rep = self.input_dropout(input_rep)\n",
        "        last_rep = self.layers(input_rep)\n",
        "        logits = self.logit(last_rep)\n",
        "        probs = self.softmax(logits)\n",
        "        return last_rep, logits, probs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uje9s2zQunFc"
      },
      "source": [
        "We instantiate the Discriminator and Generator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ylz5rvqE3U2S",
        "outputId": "37281715-f4bd-472c-ece5-825b880f4da0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--bert-base-cased/snapshots/cd5ef92a9fb2f889e972770a36d4ed042daf221e/config.json\n",
            "Model config BertConfig {\n",
            "  \"_name_or_path\": \"bert-base-cased\",\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.47.1\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 28996\n",
            "}\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# The config file is required to get the dimension of the vector produced by\n",
        "# the underlying transformer\n",
        "config = AutoConfig.from_pretrained(model_name)\n",
        "hidden_size = int(config.hidden_size)\n",
        "# Define the number and width of hidden layers\n",
        "hidden_levels_g = [hidden_size for i in range(0, num_hidden_layers_g)]\n",
        "hidden_levels_d = [hidden_size for i in range(0, num_hidden_layers_d)]\n",
        "\n",
        "#-------------------------------------------------\n",
        "#   Instantiate the Generator and Discriminator\n",
        "#-------------------------------------------------\n",
        "generator = Generator(noise_size=noise_size, output_size=hidden_size, hidden_sizes=hidden_levels_g, dropout_rate=out_dropout_rate)\n",
        "discriminator = Discriminator(input_size=hidden_size, hidden_sizes=hidden_levels_d, num_labels=len(label_list), dropout_rate=out_dropout_rate)\n",
        "\n",
        "# Put everything in the GPU if available\n",
        "if torch.cuda.is_available():\n",
        "  generator.cuda()\n",
        "  discriminator.cuda()\n",
        "  transformer.cuda()\n",
        "  if multi_gpu:\n",
        "    transformer = torch.nn.DataParallel(transformer)\n",
        "\n",
        "# print(config)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VG3qzp2-usZE"
      },
      "source": [
        "Let's go with the training procedure"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NhqylHGK3Va4",
        "outputId": "5de63bb6-0271-4c2d-da65-bf9d00f77088"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======== Epoch 1 / 30 ========\n",
            "Training...\n",
            "  Batch 10  of  42.    Elapsed: 11.93s.\n",
            "  Batch 20  of  42.    Elapsed: 21.72s.\n",
            "  Batch 30  of  42.    Elapsed: 31.56s.\n",
            "  Batch 40  of  42.    Elapsed: 41.46s.\n",
            "  Average training loss generator: 0.243\n",
            "  Average training loss discriminator: 3.201\n",
            "  Training epoch took: 43.23s\n",
            "\n",
            "Running Test...\n",
            "  Accuracy: 0.368\n",
            "  Test Loss: 1.434\n",
            "  Test took: 44.2s\n",
            "\n",
            "======== Epoch 2 / 30 ========\n",
            "Training...\n",
            "  Batch 10  of  42.    Elapsed: 9.99s.\n",
            "  Batch 20  of  42.    Elapsed: 20.01s.\n",
            "  Batch 30  of  42.    Elapsed: 30.11s.\n",
            "  Batch 40  of  42.    Elapsed: 40.29s.\n",
            "  Average training loss generator: 0.680\n",
            "  Average training loss discriminator: 2.052\n",
            "  Training epoch took: 42.11s\n",
            "\n",
            "Running Test...\n",
            "  Accuracy: 0.395\n",
            "  Test Loss: 1.335\n",
            "  Test took: 43.04s\n",
            "\n",
            "======== Epoch 3 / 30 ========\n",
            "Training...\n",
            "  Batch 10  of  42.    Elapsed: 10.22s.\n",
            "  Batch 20  of  42.    Elapsed: 20.46s.\n",
            "  Batch 30  of  42.    Elapsed: 30.76s.\n",
            "  Batch 40  of  42.    Elapsed: 41.1s.\n",
            "  Average training loss generator: 0.735\n",
            "  Average training loss discriminator: 1.626\n",
            "  Training epoch took: 42.94s\n",
            "\n",
            "Running Test...\n",
            "  Accuracy: 0.461\n",
            "  Test Loss: 1.306\n",
            "  Test took: 43.88s\n",
            "\n",
            "======== Epoch 4 / 30 ========\n",
            "Training...\n",
            "  Batch 10  of  42.    Elapsed: 10.39s.\n",
            "  Batch 20  of  42.    Elapsed: 20.74s.\n",
            "  Batch 30  of  42.    Elapsed: 31.13s.\n",
            "  Batch 40  of  42.    Elapsed: 41.56s.\n",
            "  Average training loss generator: 0.742\n",
            "  Average training loss discriminator: 1.279\n",
            "  Training epoch took: 43.42s\n",
            "\n",
            "Running Test...\n",
            "  Accuracy: 0.461\n",
            "  Test Loss: 1.693\n",
            "  Test took: 44.38s\n",
            "\n",
            "======== Epoch 5 / 30 ========\n",
            "Training...\n",
            "  Batch 10  of  42.    Elapsed: 10.47s.\n",
            "  Batch 20  of  42.    Elapsed: 20.93s.\n",
            "  Batch 30  of  42.    Elapsed: 31.42s.\n",
            "  Batch 40  of  42.    Elapsed: 41.91s.\n",
            "  Average training loss generator: 0.737\n",
            "  Average training loss discriminator: 1.018\n",
            "  Training epoch took: 43.79s\n",
            "\n",
            "Running Test...\n",
            "  Accuracy: 0.487\n",
            "  Test Loss: 1.376\n",
            "  Test took: 44.76s\n",
            "\n",
            "======== Epoch 6 / 30 ========\n",
            "Training...\n",
            "  Batch 10  of  42.    Elapsed: 10.52s.\n",
            "  Batch 20  of  42.    Elapsed: 21.09s.\n",
            "  Batch 30  of  42.    Elapsed: 31.69s.\n",
            "  Batch 40  of  42.    Elapsed: 42.26s.\n",
            "  Average training loss generator: 0.733\n",
            "  Average training loss discriminator: 0.859\n",
            "  Training epoch took: 44.15s\n",
            "\n",
            "Running Test...\n",
            "  Accuracy: 0.579\n",
            "  Test Loss: 1.715\n",
            "  Test took: 45.12s\n",
            "\n",
            "======== Epoch 7 / 30 ========\n",
            "Training...\n",
            "  Batch 10  of  42.    Elapsed: 10.63s.\n",
            "  Batch 20  of  42.    Elapsed: 21.31s.\n",
            "  Batch 30  of  42.    Elapsed: 31.99s.\n",
            "  Batch 40  of  42.    Elapsed: 42.7s.\n",
            "  Average training loss generator: 0.727\n",
            "  Average training loss discriminator: 0.786\n",
            "  Training epoch took: 44.6s\n",
            "\n",
            "Running Test...\n",
            "  Accuracy: 0.539\n",
            "  Test Loss: 1.849\n",
            "  Test took: 45.59s\n",
            "\n",
            "======== Epoch 8 / 30 ========\n",
            "Training...\n",
            "  Batch 10  of  42.    Elapsed: 10.66s.\n",
            "  Batch 20  of  42.    Elapsed: 21.29s.\n",
            "  Batch 30  of  42.    Elapsed: 31.93s.\n",
            "  Batch 40  of  42.    Elapsed: 42.57s.\n",
            "  Average training loss generator: 0.727\n",
            "  Average training loss discriminator: 0.761\n",
            "  Training epoch took: 44.46s\n",
            "\n",
            "Running Test...\n",
            "  Accuracy: 0.553\n",
            "  Test Loss: 2.084\n",
            "  Test took: 45.44s\n",
            "\n",
            "======== Epoch 9 / 30 ========\n",
            "Training...\n",
            "  Batch 10  of  42.    Elapsed: 10.65s.\n",
            "  Batch 20  of  42.    Elapsed: 21.34s.\n",
            "  Batch 30  of  42.    Elapsed: 32.0s.\n",
            "  Batch 40  of  42.    Elapsed: 42.71s.\n",
            "  Average training loss generator: 0.722\n",
            "  Average training loss discriminator: 0.747\n",
            "  Training epoch took: 44.61s\n",
            "\n",
            "Running Test...\n",
            "  Accuracy: 0.579\n",
            "  Test Loss: 2.205\n",
            "  Test took: 45.59s\n",
            "\n",
            "======== Epoch 10 / 30 ========\n",
            "Training...\n",
            "  Batch 10  of  42.    Elapsed: 10.69s.\n",
            "  Batch 20  of  42.    Elapsed: 21.34s.\n",
            "  Batch 30  of  42.    Elapsed: 32.03s.\n",
            "  Batch 40  of  42.    Elapsed: 42.68s.\n",
            "  Average training loss generator: 0.720\n",
            "  Average training loss discriminator: 0.743\n",
            "  Training epoch took: 44.59s\n",
            "\n",
            "Running Test...\n",
            "  Accuracy: 0.605\n",
            "  Test Loss: 1.974\n",
            "  Test took: 45.57s\n",
            "\n",
            "======== Epoch 11 / 30 ========\n",
            "Training...\n",
            "  Batch 10  of  42.    Elapsed: 10.68s.\n",
            "  Batch 20  of  42.    Elapsed: 21.31s.\n",
            "  Batch 30  of  42.    Elapsed: 31.96s.\n",
            "  Batch 40  of  42.    Elapsed: 42.62s.\n",
            "  Average training loss generator: 0.721\n",
            "  Average training loss discriminator: 0.732\n",
            "  Training epoch took: 44.52s\n",
            "\n",
            "Running Test...\n",
            "  Accuracy: 0.605\n",
            "  Test Loss: 2.077\n",
            "  Test took: 45.5s\n",
            "\n",
            "======== Epoch 12 / 30 ========\n",
            "Training...\n",
            "  Batch 10  of  42.    Elapsed: 10.67s.\n",
            "  Batch 20  of  42.    Elapsed: 21.36s.\n",
            "  Batch 30  of  42.    Elapsed: 32.02s.\n",
            "  Batch 40  of  42.    Elapsed: 42.7s.\n",
            "  Average training loss generator: 0.718\n",
            "  Average training loss discriminator: 0.732\n",
            "  Training epoch took: 44.6s\n",
            "\n",
            "Running Test...\n",
            "  Accuracy: 0.618\n",
            "  Test Loss: 2.088\n",
            "  Test took: 45.58s\n",
            "\n",
            "======== Epoch 13 / 30 ========\n",
            "Training...\n",
            "  Batch 10  of  42.    Elapsed: 10.67s.\n",
            "  Batch 20  of  42.    Elapsed: 21.33s.\n",
            "  Batch 30  of  42.    Elapsed: 32.01s.\n",
            "  Batch 40  of  42.    Elapsed: 42.7s.\n",
            "  Average training loss generator: 0.716\n",
            "  Average training loss discriminator: 0.731\n",
            "  Training epoch took: 44.59s\n",
            "\n",
            "Running Test...\n",
            "  Accuracy: 0.645\n",
            "  Test Loss: 2.000\n",
            "  Test took: 45.58s\n",
            "\n",
            "======== Epoch 14 / 30 ========\n",
            "Training...\n",
            "  Batch 10  of  42.    Elapsed: 10.68s.\n",
            "  Batch 20  of  42.    Elapsed: 21.34s.\n",
            "  Batch 30  of  42.    Elapsed: 32.01s.\n",
            "  Batch 40  of  42.    Elapsed: 42.69s.\n",
            "  Average training loss generator: 0.720\n",
            "  Average training loss discriminator: 0.722\n",
            "  Training epoch took: 44.6s\n",
            "\n",
            "Running Test...\n",
            "  Accuracy: 0.658\n",
            "  Test Loss: 2.017\n",
            "  Test took: 45.58s\n",
            "\n",
            "======== Epoch 15 / 30 ========\n",
            "Training...\n",
            "  Batch 10  of  42.    Elapsed: 10.66s.\n",
            "  Batch 20  of  42.    Elapsed: 21.32s.\n",
            "  Batch 30  of  42.    Elapsed: 32.0s.\n",
            "  Batch 40  of  42.    Elapsed: 42.66s.\n",
            "  Average training loss generator: 0.715\n",
            "  Average training loss discriminator: 0.727\n",
            "  Training epoch took: 44.57s\n",
            "\n",
            "Running Test...\n",
            "  Accuracy: 0.618\n",
            "  Test Loss: 1.943\n",
            "  Test took: 45.55s\n",
            "\n",
            "======== Epoch 16 / 30 ========\n",
            "Training...\n",
            "  Batch 10  of  42.    Elapsed: 10.67s.\n",
            "  Batch 20  of  42.    Elapsed: 21.32s.\n",
            "  Batch 30  of  42.    Elapsed: 31.97s.\n",
            "  Batch 40  of  42.    Elapsed: 42.65s.\n",
            "  Average training loss generator: 0.717\n",
            "  Average training loss discriminator: 0.722\n",
            "  Training epoch took: 44.54s\n",
            "\n",
            "Running Test...\n",
            "  Accuracy: 0.632\n",
            "  Test Loss: 2.150\n",
            "  Test took: 45.52s\n",
            "\n",
            "======== Epoch 17 / 30 ========\n",
            "Training...\n",
            "  Batch 10  of  42.    Elapsed: 10.65s.\n",
            "  Batch 20  of  42.    Elapsed: 21.29s.\n",
            "  Batch 30  of  42.    Elapsed: 32.01s.\n",
            "  Batch 40  of  42.    Elapsed: 42.7s.\n",
            "  Average training loss generator: 0.713\n",
            "  Average training loss discriminator: 0.722\n",
            "  Training epoch took: 44.62s\n",
            "\n",
            "Running Test...\n",
            "  Accuracy: 0.645\n",
            "  Test Loss: 2.189\n",
            "  Test took: 45.61s\n",
            "\n",
            "======== Epoch 18 / 30 ========\n",
            "Training...\n",
            "  Batch 10  of  42.    Elapsed: 10.66s.\n",
            "  Batch 20  of  42.    Elapsed: 21.35s.\n",
            "  Batch 30  of  42.    Elapsed: 32.06s.\n",
            "  Batch 40  of  42.    Elapsed: 42.75s.\n",
            "  Average training loss generator: 0.712\n",
            "  Average training loss discriminator: 0.722\n",
            "  Training epoch took: 44.65s\n",
            "\n",
            "Running Test...\n",
            "  Accuracy: 0.645\n",
            "  Test Loss: 2.250\n",
            "  Test took: 45.64s\n",
            "\n",
            "======== Epoch 19 / 30 ========\n",
            "Training...\n",
            "  Batch 10  of  42.    Elapsed: 10.71s.\n",
            "  Batch 20  of  42.    Elapsed: 21.36s.\n",
            "  Batch 30  of  42.    Elapsed: 32.02s.\n",
            "  Batch 40  of  42.    Elapsed: 42.72s.\n",
            "  Average training loss generator: 0.715\n",
            "  Average training loss discriminator: 0.721\n",
            "  Training epoch took: 44.61s\n",
            "\n",
            "Running Test...\n",
            "  Accuracy: 0.618\n",
            "  Test Loss: 2.269\n",
            "  Test took: 45.59s\n",
            "\n",
            "======== Epoch 20 / 30 ========\n",
            "Training...\n",
            "  Batch 10  of  42.    Elapsed: 10.69s.\n",
            "  Batch 20  of  42.    Elapsed: 21.34s.\n",
            "  Batch 30  of  42.    Elapsed: 32.03s.\n",
            "  Batch 40  of  42.    Elapsed: 42.72s.\n",
            "  Average training loss generator: 0.712\n",
            "  Average training loss discriminator: 0.721\n",
            "  Training epoch took: 44.61s\n",
            "\n",
            "Running Test...\n",
            "  Accuracy: 0.605\n",
            "  Test Loss: 2.581\n",
            "  Test took: 45.6s\n",
            "\n",
            "======== Epoch 21 / 30 ========\n",
            "Training...\n",
            "  Batch 10  of  42.    Elapsed: 10.69s.\n",
            "  Batch 20  of  42.    Elapsed: 21.37s.\n",
            "  Batch 30  of  42.    Elapsed: 32.05s.\n",
            "  Batch 40  of  42.    Elapsed: 42.69s.\n",
            "  Average training loss generator: 0.712\n",
            "  Average training loss discriminator: 0.717\n",
            "  Training epoch took: 44.59s\n",
            "\n",
            "Running Test...\n",
            "  Accuracy: 0.605\n",
            "  Test Loss: 2.664\n",
            "  Test took: 45.58s\n",
            "\n",
            "======== Epoch 22 / 30 ========\n",
            "Training...\n",
            "  Batch 10  of  42.    Elapsed: 10.71s.\n",
            "  Batch 20  of  42.    Elapsed: 21.35s.\n",
            "  Batch 30  of  42.    Elapsed: 32.01s.\n",
            "  Batch 40  of  42.    Elapsed: 42.66s.\n",
            "  Average training loss generator: 0.710\n",
            "  Average training loss discriminator: 0.721\n",
            "  Training epoch took: 44.56s\n",
            "\n",
            "Running Test...\n",
            "  Accuracy: 0.645\n",
            "  Test Loss: 2.555\n",
            "  Test took: 45.54s\n",
            "\n",
            "======== Epoch 23 / 30 ========\n",
            "Training...\n",
            "  Batch 10  of  42.    Elapsed: 10.69s.\n",
            "  Batch 20  of  42.    Elapsed: 21.35s.\n",
            "  Batch 30  of  42.    Elapsed: 32.0s.\n",
            "  Batch 40  of  42.    Elapsed: 42.66s.\n",
            "  Average training loss generator: 0.711\n",
            "  Average training loss discriminator: 0.716\n",
            "  Training epoch took: 44.56s\n",
            "\n",
            "Running Test...\n",
            "  Accuracy: 0.605\n",
            "  Test Loss: 2.633\n",
            "  Test took: 45.55s\n",
            "\n",
            "======== Epoch 24 / 30 ========\n",
            "Training...\n",
            "  Batch 10  of  42.    Elapsed: 10.69s.\n",
            "  Batch 20  of  42.    Elapsed: 21.34s.\n",
            "  Batch 30  of  42.    Elapsed: 31.99s.\n",
            "  Batch 40  of  42.    Elapsed: 42.65s.\n",
            "  Average training loss generator: 0.711\n",
            "  Average training loss discriminator: 0.716\n",
            "  Training epoch took: 44.56s\n",
            "\n",
            "Running Test...\n",
            "  Accuracy: 0.618\n",
            "  Test Loss: 2.509\n",
            "  Test took: 45.54s\n",
            "\n",
            "======== Epoch 25 / 30 ========\n",
            "Training...\n",
            "  Batch 10  of  42.    Elapsed: 10.66s.\n",
            "  Batch 20  of  42.    Elapsed: 21.33s.\n",
            "  Batch 30  of  42.    Elapsed: 32.01s.\n",
            "  Batch 40  of  42.    Elapsed: 42.66s.\n",
            "  Average training loss generator: 0.711\n",
            "  Average training loss discriminator: 0.716\n",
            "  Training epoch took: 44.56s\n",
            "\n",
            "Running Test...\n",
            "  Accuracy: 0.618\n",
            "  Test Loss: 2.620\n",
            "  Test took: 45.55s\n",
            "\n",
            "======== Epoch 26 / 30 ========\n",
            "Training...\n",
            "  Batch 10  of  42.    Elapsed: 10.66s.\n",
            "  Batch 20  of  42.    Elapsed: 21.35s.\n",
            "  Batch 30  of  42.    Elapsed: 32.02s.\n",
            "  Batch 40  of  42.    Elapsed: 42.66s.\n",
            "  Average training loss generator: 0.711\n",
            "  Average training loss discriminator: 0.717\n",
            "  Training epoch took: 44.56s\n",
            "\n",
            "Running Test...\n",
            "  Accuracy: 0.618\n",
            "  Test Loss: 2.630\n",
            "  Test took: 45.54s\n",
            "\n",
            "======== Epoch 27 / 30 ========\n",
            "Training...\n",
            "  Batch 10  of  42.    Elapsed: 10.69s.\n",
            "  Batch 20  of  42.    Elapsed: 21.35s.\n",
            "  Batch 30  of  42.    Elapsed: 32.0s.\n",
            "  Batch 40  of  42.    Elapsed: 42.65s.\n",
            "  Average training loss generator: 0.712\n",
            "  Average training loss discriminator: 0.713\n",
            "  Training epoch took: 44.56s\n",
            "\n",
            "Running Test...\n",
            "  Accuracy: 0.618\n",
            "  Test Loss: 2.645\n",
            "  Test took: 45.55s\n",
            "\n",
            "======== Epoch 28 / 30 ========\n",
            "Training...\n",
            "  Batch 10  of  42.    Elapsed: 10.66s.\n",
            "  Batch 20  of  42.    Elapsed: 21.33s.\n",
            "  Batch 30  of  42.    Elapsed: 32.01s.\n",
            "  Batch 40  of  42.    Elapsed: 42.69s.\n",
            "  Average training loss generator: 0.709\n",
            "  Average training loss discriminator: 0.718\n",
            "  Training epoch took: 44.6s\n",
            "\n",
            "Running Test...\n",
            "  Accuracy: 0.632\n",
            "  Test Loss: 2.686\n",
            "  Test took: 45.58s\n",
            "\n",
            "======== Epoch 29 / 30 ========\n",
            "Training...\n",
            "  Batch 10  of  42.    Elapsed: 10.68s.\n",
            "  Batch 20  of  42.    Elapsed: 21.36s.\n",
            "  Batch 30  of  42.    Elapsed: 32.01s.\n",
            "  Batch 40  of  42.    Elapsed: 42.71s.\n",
            "  Average training loss generator: 0.709\n",
            "  Average training loss discriminator: 0.713\n",
            "  Training epoch took: 44.6s\n",
            "\n",
            "Running Test...\n",
            "  Accuracy: 0.645\n",
            "  Test Loss: 2.707\n",
            "  Test took: 45.59s\n",
            "\n",
            "======== Epoch 30 / 30 ========\n",
            "Training...\n",
            "  Batch 10  of  42.    Elapsed: 10.7s.\n",
            "  Batch 20  of  42.    Elapsed: 21.35s.\n",
            "  Batch 30  of  42.    Elapsed: 32.06s.\n",
            "  Batch 40  of  42.    Elapsed: 42.71s.\n",
            "  Average training loss generator: 0.710\n",
            "  Average training loss discriminator: 0.714\n",
            "  Training epoch took: 44.61s\n",
            "\n",
            "Running Test...\n",
            "  Accuracy: 0.632\n",
            "  Test Loss: 2.737\n",
            "  Test took: 45.59s\n",
            "\n",
            "Final Evaluation...\n",
            "[2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4\n",
            " 4 4]\n",
            "[3 3 3 3 3 2 2 3 2 2 2 2 2 1 2 4 1 1 2 1 3 1 1 1 1 1 1 4 1 1 1 1 1 1 1 1 1\n",
            " 1 4 3 3 3 3 3 2 3 3 3 3 2 3 3 3 3 3 3 3 3 2 2 1 1 3 3 3 2 4 4 4 3 3 4 3 2\n",
            " 4 4]\n",
            "17\n",
            "5\n",
            "<module 'numpy' from '/usr/local/lib/python3.10/dist-packages/numpy/__init__.py'>\n",
            "0.8947368421052632\n",
            "0.7727272727272727\n",
            "0.8292682926829269\n",
            "9\n",
            "6\n",
            "<module 'numpy' from '/usr/local/lib/python3.10/dist-packages/numpy/__init__.py'>\n",
            "0.47368421052631576\n",
            "0.6\n",
            "0.5294117647058824\n",
            "16\n",
            "14\n",
            "<module 'numpy' from '/usr/local/lib/python3.10/dist-packages/numpy/__init__.py'>\n",
            "0.8421052631578947\n",
            "0.5333333333333333\n",
            "0.653061224489796\n",
            "6\n",
            "3\n",
            "<module 'numpy' from '/usr/local/lib/python3.10/dist-packages/numpy/__init__.py'>\n",
            "0.3157894736842105\n",
            "0.6666666666666666\n",
            "0.42857142857142855\n",
            "0.631578947368421\n",
            "0.6431818181818181\n",
            "0.6100781776125085\n",
            "Final Recall: 0.632\n",
            "Final Precision: 0.643\n",
            "Final F1 Score: 0.610\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "\n",
        "# Função para calcular Recall, Precision e F1-Score manualmente para múltiplas classes\n",
        "def calculate_recall_precision_f1_multiclass(y_true, y_pred):\n",
        "    # Classes únicas\n",
        "    classes = np.unique(y_true)\n",
        "\n",
        "    recalls = []\n",
        "    precisions = []\n",
        "    f1_scores = []\n",
        "\n",
        "    for cls in classes:\n",
        "        # True Positives, False Positives, False Negatives para a classe atual\n",
        "        tp = np.sum((y_true == cls) & (y_pred == cls))\n",
        "        fp = np.sum((y_true != cls) & (y_pred == cls))\n",
        "        fn = np.sum((y_true == cls) & (y_pred != cls))\n",
        "        print(tp)\n",
        "        print(fp)\n",
        "        print(np)\n",
        "\n",
        "        # Recall\n",
        "        recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
        "        recalls.append(recall)\n",
        "        print(recall)\n",
        "        # Precision\n",
        "        precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
        "        precisions.append(precision)\n",
        "        print(precision)\n",
        "        # F1 Score\n",
        "        f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
        "        f1_scores.append(f1)\n",
        "        print(f1)\n",
        "    # Média das métricas por classe\n",
        "    avg_recall = np.mean(recalls)\n",
        "    avg_precision = np.mean(precisions)\n",
        "    avg_f1 = np.mean(f1_scores)\n",
        "    print(avg_recall)\n",
        "    print(avg_precision)\n",
        "    print(avg_f1)\n",
        "    return avg_recall, avg_precision, avg_f1\n",
        "\n",
        "# Função auxiliar para formatar o tempo\n",
        "def format_time(elapsed):\n",
        "    return str(round(elapsed, 2)) + \"s\"\n",
        "\n",
        "training_stats = []\n",
        "\n",
        "# Measure the total training time for the whole run.\n",
        "total_t0 = time.time()\n",
        "\n",
        "# Optimizers\n",
        "transformer_vars = [i for i in transformer.parameters()]\n",
        "d_vars = transformer_vars + [v for v in discriminator.parameters()]\n",
        "g_vars = [v for v in generator.parameters()]\n",
        "\n",
        "dis_optimizer = torch.optim.AdamW(d_vars, lr=learning_rate_discriminator)\n",
        "gen_optimizer = torch.optim.AdamW(g_vars, lr=learning_rate_generator)\n",
        "\n",
        "# Scheduler\n",
        "if apply_scheduler:\n",
        "    num_train_examples = len(train_examples)\n",
        "    num_train_steps = int(num_train_examples / batch_size * num_train_epochs)\n",
        "    num_warmup_steps = int(num_train_steps * warmup_proportion)\n",
        "\n",
        "    scheduler_d = get_constant_schedule_with_warmup(dis_optimizer, num_warmup_steps=num_warmup_steps)\n",
        "    scheduler_g = get_constant_schedule_with_warmup(gen_optimizer, num_warmup_steps=num_warmup_steps)\n",
        "\n",
        "# Treinamento do modelo\n",
        "for epoch_i in range(0, num_train_epochs):\n",
        "    print(\"\")\n",
        "    print(f\"======== Epoch {epoch_i + 1} / {num_train_epochs} ========\")\n",
        "    print(\"Training...\")\n",
        "\n",
        "    t0 = time.time()\n",
        "    tr_g_loss = 0\n",
        "    tr_d_loss = 0\n",
        "\n",
        "    transformer.train()\n",
        "    generator.train()\n",
        "    discriminator.train()\n",
        "\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "        if step % print_each_n_step == 0 and not step == 0:\n",
        "            elapsed = format_time(time.time() - t0)\n",
        "            print(f\"  Batch {step:,}  of  {len(train_dataloader):,}.    Elapsed: {elapsed}.\")\n",
        "\n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "        b_label_mask = batch[3].to(device)\n",
        "\n",
        "        real_batch_size = b_input_ids.shape[0]\n",
        "\n",
        "        model_outputs = transformer(b_input_ids, attention_mask=b_input_mask)\n",
        "        hidden_states = model_outputs[-1]\n",
        "\n",
        "        noise = torch.zeros(real_batch_size, noise_size, device=device).uniform_(0, 1)\n",
        "        gen_rep = generator(noise)\n",
        "\n",
        "        disciminator_input = torch.cat([hidden_states, gen_rep], dim=0)\n",
        "        features, logits, probs = discriminator(disciminator_input)\n",
        "\n",
        "        features_list = torch.split(features, real_batch_size)\n",
        "        D_real_features, D_fake_features = features_list\n",
        "\n",
        "        logits_list = torch.split(logits, real_batch_size)\n",
        "        D_real_logits, D_fake_logits = logits_list\n",
        "\n",
        "        probs_list = torch.split(probs, real_batch_size)\n",
        "        D_real_probs, D_fake_probs = probs_list\n",
        "\n",
        "        # Generator loss\n",
        "        g_loss_d = -torch.mean(torch.log(1 - D_fake_probs[:, -1] + epsilon))\n",
        "        g_feat_reg = torch.mean(torch.pow(torch.mean(D_real_features, dim=0) - torch.mean(D_fake_features, dim=0), 2))\n",
        "        g_loss = g_loss_d + g_feat_reg\n",
        "\n",
        "        # Discriminator loss\n",
        "        logits = D_real_logits[:, :-1]\n",
        "        log_probs = F.log_softmax(logits, dim=-1)\n",
        "        label2one_hot = F.one_hot(b_labels, len(label_list))\n",
        "        per_example_loss = -torch.sum(label2one_hot * log_probs, dim=-1)\n",
        "        per_example_loss = torch.masked_select(per_example_loss, b_label_mask.to(device))\n",
        "        labeled_example_count = per_example_loss.numel()\n",
        "\n",
        "        if labeled_example_count == 0:\n",
        "            D_L_Supervised = 0\n",
        "        else:\n",
        "            D_L_Supervised = torch.sum(per_example_loss) / labeled_example_count\n",
        "\n",
        "        D_L_unsupervised1U = -torch.mean(torch.log(1 - D_real_probs[:, -1] + epsilon))\n",
        "        D_L_unsupervised2U = -torch.mean(torch.log(D_fake_probs[:, -1] + epsilon))\n",
        "        d_loss = D_L_Supervised + D_L_unsupervised1U + D_L_unsupervised2U\n",
        "\n",
        "        gen_optimizer.zero_grad()\n",
        "        dis_optimizer.zero_grad()\n",
        "\n",
        "        g_loss.backward(retain_graph=True)\n",
        "        d_loss.backward()\n",
        "\n",
        "        gen_optimizer.step()\n",
        "        dis_optimizer.step()\n",
        "\n",
        "        tr_g_loss += g_loss.item()\n",
        "        tr_d_loss += d_loss.item()\n",
        "\n",
        "        if apply_scheduler:\n",
        "            scheduler_d.step()\n",
        "            scheduler_g.step()\n",
        "\n",
        "    avg_train_loss_g = tr_g_loss / len(train_dataloader)\n",
        "    avg_train_loss_d = tr_d_loss / len(train_dataloader)\n",
        "    training_time = format_time(time.time() - t0)\n",
        "\n",
        "    print(f\"  Average training loss generator: {avg_train_loss_g:.3f}\")\n",
        "    print(f\"  Average training loss discriminator: {avg_train_loss_d:.3f}\")\n",
        "    print(f\"  Training epoch took: {training_time}\")\n",
        "\n",
        "    # Avaliação por época para calcular a acurácia\n",
        "    print(\"\\nRunning Test...\")\n",
        "\n",
        "    all_preds = []\n",
        "    all_labels_ids = []\n",
        "    total_test_loss = 0\n",
        "\n",
        "    transformer.eval()\n",
        "    discriminator.eval()\n",
        "    generator.eval()\n",
        "\n",
        "    for batch in test_dataloader:\n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            model_outputs = transformer(b_input_ids, attention_mask=b_input_mask)\n",
        "            hidden_states = model_outputs[-1]\n",
        "            _, logits, probs = discriminator(hidden_states)\n",
        "            filtered_logits = logits[:, :-1]\n",
        "            total_test_loss += F.cross_entropy(filtered_logits, b_labels, ignore_index=-1)\n",
        "\n",
        "            _, preds = torch.max(filtered_logits, 1)\n",
        "            all_preds += preds.detach().cpu()\n",
        "            all_labels_ids += b_labels.detach().cpu()\n",
        "\n",
        "    # Cálculo da acurácia para cada rodada\n",
        "    all_preds = torch.stack(all_preds).numpy()\n",
        "    all_labels_ids = torch.stack(all_labels_ids).numpy()\n",
        "    test_accuracy = np.sum(all_preds == all_labels_ids) / len(all_preds)\n",
        "\n",
        "    print(f\"  Accuracy: {test_accuracy:.3f}\")\n",
        "    avg_test_loss = total_test_loss / len(test_dataloader)\n",
        "    avg_test_loss = avg_test_loss.item()\n",
        "    test_time = format_time(time.time() - t0)\n",
        "\n",
        "    print(f\"  Test Loss: {avg_test_loss:.3f}\")\n",
        "    print(f\"  Test took: {test_time}\")\n",
        "\n",
        "    training_stats.append({\n",
        "        'epoch': epoch_i + 1,\n",
        "        'Training Loss generator': avg_train_loss_g,\n",
        "        'Training Loss discriminator': avg_train_loss_d,\n",
        "        'Valid. Loss': avg_test_loss,\n",
        "        'Valid. Accur.': test_accuracy,\n",
        "        'Training Time': training_time,\n",
        "        'Test Time': test_time\n",
        "    })\n",
        "\n",
        "# Avaliação do modelo no final do treinamento\n",
        "print(\"\\nFinal Evaluation...\")\n",
        "\n",
        "print(all_labels_ids)\n",
        "print(all_preds)\n",
        "recall, precision, f1 = calculate_recall_precision_f1_multiclass(all_labels_ids, all_preds)\n",
        "\n",
        "print(f\"Final Recall: {recall:.3f}\")\n",
        "print(f\"Final Precision: {precision:.3f}\")\n",
        "print(f\"Final F1 Score: {f1:.3f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dDm9NProRB4c",
        "outputId": "841ee1ef-19d8-4b15-9ef1-d2b9e24876d1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'epoch': 1, 'Training Loss generator': 0.24330371334439233, 'Training Loss discriminator': 3.2005899974278043, 'Valid. Loss': 1.434151291847229, 'Valid. Accur.': 0.3684210526315789, 'Training Time': '43.23s', 'Test Time': '44.2s'}\n",
            "{'epoch': 2, 'Training Loss generator': 0.6802311809290023, 'Training Loss discriminator': 2.0515365529628027, 'Valid. Loss': 1.3346976041793823, 'Valid. Accur.': 0.39473684210526316, 'Training Time': '42.11s', 'Test Time': '43.04s'}\n",
            "{'epoch': 3, 'Training Loss generator': 0.7354555470602853, 'Training Loss discriminator': 1.6258378710065569, 'Valid. Loss': 1.3060786724090576, 'Valid. Accur.': 0.4605263157894737, 'Training Time': '42.94s', 'Test Time': '43.88s'}\n",
            "{'epoch': 4, 'Training Loss generator': 0.7418520606699444, 'Training Loss discriminator': 1.2788383648509072, 'Valid. Loss': 1.6926847696304321, 'Valid. Accur.': 0.4605263157894737, 'Training Time': '43.42s', 'Test Time': '44.38s'}\n",
            "{'epoch': 5, 'Training Loss generator': 0.7365128355366843, 'Training Loss discriminator': 1.0179510088193984, 'Valid. Loss': 1.37612783908844, 'Valid. Accur.': 0.4868421052631579, 'Training Time': '43.79s', 'Test Time': '44.76s'}\n",
            "{'epoch': 6, 'Training Loss generator': 0.7333640058835348, 'Training Loss discriminator': 0.858962764342626, 'Valid. Loss': 1.714847207069397, 'Valid. Accur.': 0.5789473684210527, 'Training Time': '44.15s', 'Test Time': '45.12s'}\n",
            "{'epoch': 7, 'Training Loss generator': 0.7265275518099467, 'Training Loss discriminator': 0.7861538642928714, 'Valid. Loss': 1.8489716053009033, 'Valid. Accur.': 0.5394736842105263, 'Training Time': '44.6s', 'Test Time': '45.59s'}\n",
            "{'epoch': 8, 'Training Loss generator': 0.7265372631095705, 'Training Loss discriminator': 0.7610271771748861, 'Valid. Loss': 2.0841972827911377, 'Valid. Accur.': 0.5526315789473685, 'Training Time': '44.46s', 'Test Time': '45.44s'}\n",
            "{'epoch': 9, 'Training Loss generator': 0.721517142795381, 'Training Loss discriminator': 0.7467088330359686, 'Valid. Loss': 2.20491623878479, 'Valid. Accur.': 0.5789473684210527, 'Training Time': '44.61s', 'Test Time': '45.59s'}\n",
            "{'epoch': 10, 'Training Loss generator': 0.7195224109150115, 'Training Loss discriminator': 0.7427382582709903, 'Valid. Loss': 1.974199652671814, 'Valid. Accur.': 0.6052631578947368, 'Training Time': '44.59s', 'Test Time': '45.57s'}\n",
            "{'epoch': 11, 'Training Loss generator': 0.7212981851327986, 'Training Loss discriminator': 0.7324896539960589, 'Valid. Loss': 2.077415704727173, 'Valid. Accur.': 0.6052631578947368, 'Training Time': '44.52s', 'Test Time': '45.5s'}\n",
            "{'epoch': 12, 'Training Loss generator': 0.7183558940887451, 'Training Loss discriminator': 0.7321690959589822, 'Valid. Loss': 2.0879392623901367, 'Valid. Accur.': 0.618421052631579, 'Training Time': '44.6s', 'Test Time': '45.58s'}\n",
            "{'epoch': 13, 'Training Loss generator': 0.7155914959453401, 'Training Loss discriminator': 0.7309408443314689, 'Valid. Loss': 1.999890685081482, 'Valid. Accur.': 0.6447368421052632, 'Training Time': '44.59s', 'Test Time': '45.58s'}\n",
            "{'epoch': 14, 'Training Loss generator': 0.7200841960452852, 'Training Loss discriminator': 0.7219091398375375, 'Valid. Loss': 2.0165798664093018, 'Valid. Accur.': 0.6578947368421053, 'Training Time': '44.6s', 'Test Time': '45.58s'}\n",
            "{'epoch': 15, 'Training Loss generator': 0.7145631980328333, 'Training Loss discriminator': 0.726965878690992, 'Valid. Loss': 1.9432833194732666, 'Valid. Accur.': 0.618421052631579, 'Training Time': '44.57s', 'Test Time': '45.55s'}\n",
            "{'epoch': 16, 'Training Loss generator': 0.7166566139175778, 'Training Loss discriminator': 0.7219088020778838, 'Valid. Loss': 2.1504971981048584, 'Valid. Accur.': 0.631578947368421, 'Training Time': '44.54s', 'Test Time': '45.52s'}\n",
            "{'epoch': 17, 'Training Loss generator': 0.7128653057983944, 'Training Loss discriminator': 0.7215322185130346, 'Valid. Loss': 2.189343214035034, 'Valid. Accur.': 0.6447368421052632, 'Training Time': '44.62s', 'Test Time': '45.61s'}\n",
            "{'epoch': 18, 'Training Loss generator': 0.7116406049047198, 'Training Loss discriminator': 0.7215525280861628, 'Valid. Loss': 2.2503397464752197, 'Valid. Accur.': 0.6447368421052632, 'Training Time': '44.65s', 'Test Time': '45.64s'}\n",
            "{'epoch': 19, 'Training Loss generator': 0.7154176604180109, 'Training Loss discriminator': 0.720959165266582, 'Valid. Loss': 2.268629789352417, 'Valid. Accur.': 0.618421052631579, 'Training Time': '44.61s', 'Test Time': '45.59s'}\n",
            "{'epoch': 20, 'Training Loss generator': 0.712152415797824, 'Training Loss discriminator': 0.7207488545349666, 'Valid. Loss': 2.580932855606079, 'Valid. Accur.': 0.6052631578947368, 'Training Time': '44.61s', 'Test Time': '45.6s'}\n",
            "{'epoch': 21, 'Training Loss generator': 0.7121493305478778, 'Training Loss discriminator': 0.7168482939402262, 'Valid. Loss': 2.6643452644348145, 'Valid. Accur.': 0.6052631578947368, 'Training Time': '44.59s', 'Test Time': '45.58s'}\n",
            "{'epoch': 22, 'Training Loss generator': 0.7097767463752201, 'Training Loss discriminator': 0.7207680514880589, 'Valid. Loss': 2.554912567138672, 'Valid. Accur.': 0.6447368421052632, 'Training Time': '44.56s', 'Test Time': '45.54s'}\n",
            "{'epoch': 23, 'Training Loss generator': 0.7113266800131116, 'Training Loss discriminator': 0.7158465754418146, 'Valid. Loss': 2.6331393718719482, 'Valid. Accur.': 0.6052631578947368, 'Training Time': '44.56s', 'Test Time': '45.55s'}\n",
            "{'epoch': 24, 'Training Loss generator': 0.7105197906494141, 'Training Loss discriminator': 0.7161541254747481, 'Valid. Loss': 2.5090091228485107, 'Valid. Accur.': 0.618421052631579, 'Training Time': '44.56s', 'Test Time': '45.54s'}\n",
            "{'epoch': 25, 'Training Loss generator': 0.7112532357374827, 'Training Loss discriminator': 0.7164595822493235, 'Valid. Loss': 2.6201794147491455, 'Valid. Accur.': 0.618421052631579, 'Training Time': '44.56s', 'Test Time': '45.55s'}\n",
            "{'epoch': 26, 'Training Loss generator': 0.7110859439486549, 'Training Loss discriminator': 0.7170215987023854, 'Valid. Loss': 2.629744291305542, 'Valid. Accur.': 0.618421052631579, 'Training Time': '44.56s', 'Test Time': '45.54s'}\n",
            "{'epoch': 27, 'Training Loss generator': 0.7122164695035844, 'Training Loss discriminator': 0.7128560372761318, 'Valid. Loss': 2.6453616619110107, 'Valid. Accur.': 0.618421052631579, 'Training Time': '44.56s', 'Test Time': '45.55s'}\n",
            "{'epoch': 28, 'Training Loss generator': 0.708986527863003, 'Training Loss discriminator': 0.7179710254782722, 'Valid. Loss': 2.68619704246521, 'Valid. Accur.': 0.631578947368421, 'Training Time': '44.6s', 'Test Time': '45.58s'}\n",
            "{'epoch': 29, 'Training Loss generator': 0.7089518095765796, 'Training Loss discriminator': 0.7132770376546043, 'Valid. Loss': 2.7071869373321533, 'Valid. Accur.': 0.6447368421052632, 'Training Time': '44.6s', 'Test Time': '45.59s'}\n",
            "{'epoch': 30, 'Training Loss generator': 0.7102849469298408, 'Training Loss discriminator': 0.7139662816410973, 'Valid. Loss': 2.7366597652435303, 'Valid. Accur.': 0.631578947368421, 'Training Time': '44.61s', 'Test Time': '45.59s'}\n",
            "\n",
            "Training complete!\n",
            "Total training took 1358.99s (h:mm:ss)\n",
            "Tempo de execução: 1408.0221 segundos\n"
          ]
        }
      ],
      "source": [
        "for stat in training_stats:\n",
        "  print(stat)\n",
        "\n",
        "print(\"\\nTraining complete!\")\n",
        "\n",
        "print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))\n",
        "\n",
        "resultado = sum(range(10**6))\n",
        "\n",
        "end_time = time.time()\n",
        "execution_time = end_time - start_time\n",
        "print(f\"Tempo de execução: {execution_time:.4f} segundos\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "n1SLK1oerBG8"
      },
      "outputs": [],
      "source": [
        "#ADICIONADO\n",
        "# Salvar os modelos\n",
        "torch.save(generator.state_dict(), 'generator.pt')\n",
        "torch.save(discriminator.state_dict(), 'discriminator.pt')\n",
        "torch.save(transformer.state_dict(), 'transformer.pt')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S74HP191rDh8",
        "outputId": "d829739b-328b-48b0-803f-4c2d0757ce36"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-15-4889753bf3fa>:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  generator.load_state_dict(torch.load('generator.pt'))\n",
            "<ipython-input-15-4889753bf3fa>:4: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  discriminator.load_state_dict(torch.load('discriminator.pt'))\n",
            "<ipython-input-15-4889753bf3fa>:5: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  transformer.load_state_dict(torch.load('transformer.pt'))\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "#ADICIONADO\n",
        "# Carregar os modelos\n",
        "generator.load_state_dict(torch.load('generator.pt'))\n",
        "discriminator.load_state_dict(torch.load('discriminator.pt'))\n",
        "transformer.load_state_dict(torch.load('transformer.pt'))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "31FQmDM7sIeG"
      },
      "source": [
        "Preparar o Tokenizer e Configuração do Modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WTvcKqvnrK6r",
        "outputId": "5deab70b-fae9-47a2-a04a-b2d5d8cb8359"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--bert-base-cased/snapshots/cd5ef92a9fb2f889e972770a36d4ed042daf221e/config.json\n",
            "Model config BertConfig {\n",
            "  \"_name_or_path\": \"bert-base-cased\",\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.47.1\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 28996\n",
            "}\n",
            "\n",
            "loading file vocab.txt from cache at /root/.cache/huggingface/hub/models--bert-base-cased/snapshots/cd5ef92a9fb2f889e972770a36d4ed042daf221e/vocab.txt\n",
            "loading file tokenizer.json from cache at /root/.cache/huggingface/hub/models--bert-base-cased/snapshots/cd5ef92a9fb2f889e972770a36d4ed042daf221e/tokenizer.json\n",
            "loading file added_tokens.json from cache at None\n",
            "loading file special_tokens_map.json from cache at None\n",
            "loading file tokenizer_config.json from cache at /root/.cache/huggingface/hub/models--bert-base-cased/snapshots/cd5ef92a9fb2f889e972770a36d4ed042daf221e/tokenizer_config.json\n",
            "loading file chat_template.jinja from cache at None\n",
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--bert-base-cased/snapshots/cd5ef92a9fb2f889e972770a36d4ed042daf221e/config.json\n",
            "Model config BertConfig {\n",
            "  \"_name_or_path\": \"bert-base-cased\",\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.47.1\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 28996\n",
            "}\n",
            "\n",
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--bert-base-cased/snapshots/cd5ef92a9fb2f889e972770a36d4ed042daf221e/config.json\n",
            "Model config BertConfig {\n",
            "  \"_name_or_path\": \"bert-base-cased\",\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.47.1\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 28996\n",
            "}\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#ADICIONADO\n",
        "from transformers import AutoTokenizer, AutoModel, AutoConfig\n",
        "\n",
        "# Nome do modelo usado durante o treinamento\n",
        "model_name = \"bert-base-cased\"\n",
        "\n",
        "# Carregar tokenizer e configuração\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "config = AutoConfig.from_pretrained(model_name)\n",
        "hidden_size = int(config.hidden_size)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sJUdJ0WAsRNn"
      },
      "source": [
        "Função de Pré-processamento"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "E8Qei1jlrPJ7"
      },
      "outputs": [],
      "source": [
        "#ADICIONADO\n",
        "def preprocess(text, max_seq_length=64):\n",
        "    encoded_sent = tokenizer.encode(text, add_special_tokens=True, max_length=max_seq_length, padding=\"max_length\", truncation=True)\n",
        "    input_ids = torch.tensor([encoded_sent])\n",
        "    attention_mask = torch.tensor([[int(token_id > 0) for token_id in encoded_sent]])\n",
        "    return input_ids, attention_mask\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dKm2EnJasTLq"
      },
      "source": [
        "Classificação de Novas Perguntas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r0jskTGwrQkF",
        "outputId": "b47c8987-63b3-4603-db4a-4ac41df0810a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted Label: CHEMI_chemi\n"
          ]
        }
      ],
      "source": [
        "#ADICIONADO\n",
        "def classify_question(text):\n",
        "    transformer.eval()\n",
        "    discriminator.eval()\n",
        "\n",
        "    # Pré-processar a nova pergunta\n",
        "    input_ids, attention_mask = preprocess(text)\n",
        "\n",
        "    input_ids = input_ids.to(device)\n",
        "    attention_mask = attention_mask.to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        # Passar pela transformer\n",
        "        model_outputs = transformer(input_ids, attention_mask=attention_mask)\n",
        "        hidden_states = model_outputs[-1]\n",
        "\n",
        "        # Passar pelo discriminator\n",
        "        _, logits, probs = discriminator(hidden_states)\n",
        "\n",
        "        # Filtrar os logits\n",
        "        filtered_logits = logits[:, :-1]\n",
        "\n",
        "        # Obter a predição\n",
        "        pred = torch.argmax(filtered_logits, dim=1).item()\n",
        "\n",
        "    return label_list[pred]\n",
        "\n",
        "# Exemplo de uso\n",
        "new_question = \"Who is the current president of the United States?\"\n",
        "predicted_label = classify_question(new_question)\n",
        "print(f\"Predicted Label: {predicted_label}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q4ckQzknquzR",
        "outputId": "df4701e6-28f1-493c-8a03-4b0cfffa1b05"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted Label: REGUL_regul\n"
          ]
        }
      ],
      "source": [
        "# Exemplo de uso\n",
        "new_question = \"An internal email discussing concerns over new regulatory guidelines for glyphosate, with Monsanto executives planning outreach to key figures in the regulatory process.\"\n",
        "predicted_label = classify_question(new_question)\n",
        "print(f\"Predicted Label: {predicted_label}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QyRqjKCEk5o3",
        "outputId": "f3b803ff-7505-4626-ec62-e65d8917e317"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted Label: GHOST_ghost\n"
          ]
        }
      ],
      "source": [
        "# Exemplo de uso\n",
        "new_question = \"I am forwarding for review the article titled Effects of Automation in the Financial Sector, submitted for the next issue of the journal. Please provide your comments and suggestions for revision by the end of the week.\"\n",
        "predicted_label = classify_question(new_question)\n",
        "print(f\"Predicted Label: {predicted_label}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O5euPNb9pL0v",
        "outputId": "88f87d63-78d3-41c4-a853-5a5a38b914c8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted Label: CHEMI_chemi\n"
          ]
        }
      ],
      "source": [
        "# Exemplo de uso\n",
        "new_question = \"What is the boiling point of water in Celsius?\"\n",
        "predicted_label = classify_question(new_question)\n",
        "print(f\"Predicted Label: {predicted_label}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ypMufqz_7pvc"
      },
      "source": [
        "Testing\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Md-eYDqb7XFA",
        "outputId": "ffadaaaf-912d-41f9-f537-c2b44adbb707"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted Label: GHOST_ghost\n"
          ]
        }
      ],
      "source": [
        "# Exemplo de uso\n",
        "new_question = \"Dear Larry, As we discussed earlier, we will be proceeding with the draft of the manuscript for the Expert Panel. We want to ensure that the final version has your expertise woven into it, particularly in the genotoxicity section. Please let us know your availability so we can finalize the consulting agreement, which should cover the necessary writing hours—roughly around 12K for 2015.Best regards, Donna Farmer Monsanto Toxicologist\"\n",
        "predicted_label = classify_question(new_question)\n",
        "print(f\"Predicted Label: {predicted_label}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2WL6QIMX7k9_",
        "outputId": "8de30969-0462-4bc8-dbd5-e49798be6460"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted Label: GHOST_ghost\n"
          ]
        }
      ],
      "source": [
        "# Exemplo de uso\n",
        "new_question = \"I’ve been asked to review a recent study on glyphosate’s cytotoxicity in rats. Given your expertise in the field, I believe it would be beneficial for both of you to act as peer reviewers. Once you’ve collated your comments, I’ll submit the final review on our behalf.\"\n",
        "predicted_label = classify_question(new_question)\n",
        "print(f\"Predicted Label: {predicted_label}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9PjC3FmB7l7H",
        "outputId": "c3c00ac6-7ad1-4318-9145-cc0e47a422ba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted Label: GHOST_ghost\n"
          ]
        }
      ],
      "source": [
        "# Exemplo de uso\n",
        "new_question = \"I wanted to reach out regarding the recent publication by Professor Seralini. Given the numerous inaccuracies in the study, I would recommend retracting the paper and restarting the review process. Let’s ensure we maintain scientific credibility.\"\n",
        "predicted_label = classify_question(new_question)\n",
        "print(f\"Predicted Label: {predicted_label}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xD2YzkRG7lyh",
        "outputId": "98d4e21c-f946-4bbb-a7c7-d97a51e958f3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted Label: TOXIC_toxic\n"
          ]
        }
      ],
      "source": [
        "# Exemplo de uso\n",
        "new_question = \"The surfactant used in our Roundup formulation may play a significant role in the skin tumor promotion study we’ve been analyzing. I believe this needs to be addressed in the manuscript to ensure that the surfactant's effects are fully acknowledged in the safety data.\"\n",
        "predicted_label = classify_question(new_question)\n",
        "print(f\"Predicted Label: {predicted_label}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hVQPIv2W7lne",
        "outputId": "eaf10e3b-9b7e-4af4-f9e9-d149cfa2c483"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted Label: REGUL_regul\n"
          ]
        }
      ],
      "source": [
        "# Exemplo de uso\n",
        "new_question = \"Following our internal review of the NNG carcinogenicity study in male mice, the results show a significant increase in malignant lymphomas. I am compiling the data to assess the risk, but we must be careful in framing this study as it could lead to regulatory challenges.\"\n",
        "predicted_label = classify_question(new_question)\n",
        "print(f\"Predicted Label: {predicted_label}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PmZuc7lv7lbd",
        "outputId": "f82f6634-9e5d-474f-8fa9-11975278149d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted Label: REGUL_regul\n"
          ]
        }
      ],
      "source": [
        "# Exemplo de uso\n",
        "new_question = \"Our recent storage tests for glyphosate show increased levels of NNG due to long-term storage conditions. I suggest we draft a report clarifying that these results are not representative of normal product aging to avoid unnecessary regulatory concerns.\"\n",
        "predicted_label = classify_question(new_question)\n",
        "print(f\"Predicted Label: {predicted_label}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uPWUdzPG8UCM",
        "outputId": "d815f8df-0839-40fd-9c4f-1526e0da0046"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted Label: CHEMI_chemi\n"
          ]
        }
      ],
      "source": [
        "# Exemplo de uso\n",
        "new_question = \"Our recent study confirms that surfactants in the Roundup formulation significantly increase glyphosate absorption through the skin. This presents a challenge in terms of risk evaluations, and we may need to reevaluate our safety guidelines in light of this.\"\n",
        "predicted_label = classify_question(new_question)\n",
        "print(f\"Predicted Label: {predicted_label}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D5LYn5of8T0L",
        "outputId": "edf7910d-7909-4f79-ea1e-39b0e7de3309"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted Label: CHEMI_chemi\n"
          ]
        }
      ],
      "source": [
        "# Exemplo de uso\n",
        "new_question = \"In response to the deposition questions, I can confirm that there is no scientific basis for claiming that glyphosate absorbed through the skin is excreted through feces. This should be communicated clearly in our defense, as the current evidence only supports excretion via urine.\"\n",
        "predicted_label = classify_question(new_question)\n",
        "print(f\"Predicted Label: {predicted_label}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i72kJFIQ8TQi",
        "outputId": "22756f0f-5105-4908-bf80-ac3197e4148d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted Label: CHEMI_chemi\n"
          ]
        }
      ],
      "source": [
        "# Exemplo de uso\n",
        "new_question = \"Our internal review of glyphosate metabolism shows continued uncertainty regarding dermal absorption rates. Additional studies might clarify the issue, but this also introduces the risk of discovering new metabolites, which could complicate our current safety profile.\"\n",
        "predicted_label = classify_question(new_question)\n",
        "print(f\"Predicted Label: {predicted_label}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "43-75NXw8ZsV",
        "outputId": "022782ad-0e87-4b1f-b229-74dd7a5196d3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted Label: CHEMI_chemi\n"
          ]
        }
      ],
      "source": [
        "# Exemplo de uso\n",
        "new_question = \"We need to gather further data on the excretion of glyphosate through dermal exposure. Thus far, the assumption has been that it’s primarily excreted through urine, but this might need more scrutiny, especially in light of regulatory concerns.\"\n",
        "predicted_label = classify_question(new_question)\n",
        "print(f\"Predicted Label: {predicted_label}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1SNKQt_o8lyG",
        "outputId": "040ca0f1-d5ef-4b91-8348-384161e5d222"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted Label: REGUL_regul\n"
          ]
        }
      ],
      "source": [
        "# Exemplo de uso\n",
        "new_question = \"As discussed, we need to escalate our efforts to gain favorable regulatory assessments in Europe. A mix of scientific review and political strategy will be essential to ensure glyphosate is not classified as a carcinogen. Let’s initiate a communication campaign to address any doubts regulators may have.\"\n",
        "predicted_label = classify_question(new_question)\n",
        "print(f\"Predicted Label: {predicted_label}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yMHkVTR38loq",
        "outputId": "94922fb5-43d4-4443-817b-b7843c9fa3f3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted Label: REGUL_regul\n"
          ]
        }
      ],
      "source": [
        "# Exemplo de uso\n",
        "new_question = \"I met with EPA officials earlier this afternoon, and we discussed delaying the risk assessment for glyphosate. It seems we have support from key figures, but we’ll need to strategize to ensure there are no surprises from other government agencies.\"\n",
        "predicted_label = classify_question(new_question)\n",
        "print(f\"Predicted Label: {predicted_label}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JVebW6FEB5k1",
        "outputId": "b36042ad-b60a-41cb-a385-f5452b73127f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted Label: TOXIC_toxic\n"
          ]
        }
      ],
      "source": [
        "# Exemplo de uso\n",
        "new_question = \"Roundup used to kill people\"\n",
        "predicted_label = classify_question(new_question)\n",
        "print(f\"Predicted Label: {predicted_label}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4TqWCO9UC0lT",
        "outputId": "ccd6e751-ba22-45c4-9fe9-4568ff43a5b6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted Label: REGUL_regul\n"
          ]
        }
      ],
      "source": [
        "# Exemplo de uso\n",
        "new_question = \"There have been significant updates regarding our ongoing work on biochemical processes, and it is crucial that we handle the next steps with extreme vigilance. The information we are about to relay to government authorities contains delicate aspects that could draw unwelcome interest if not meticulously safeguarded. We must ensure that every part of this operation remains in strict confidentiality, especially considering the nature of the sensitive data at hand. Any kind of exposure could resul\"\n",
        "predicted_label = classify_question(new_question)\n",
        "print(f\"Predicted Label: {predicted_label}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tFOnhYcya4ep"
      },
      "source": [
        "#Testando Text Split\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "daMpnHdob8Kl",
        "outputId": "272096cb-1872-44f2-c3dd-23ac7768ca75"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentence: I’ve been asked to review a recent study on glyphosate’s cytotoxicity in rats.\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: Given your expertise in the field, I believe it would be beneficial for both of you to act as peer reviewers.\n",
            "Predicted Label: GHOST_ghost\n",
            "\n",
            "Sentence: Once you’ve collated your comments, I’ll submit the final review on our behalf.\n",
            "Predicted Label: GHOST_ghost\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "from nltk.tokenize import sent_tokenize\n",
        "\n",
        "# Download the necessary data for tokenization\n",
        "nltk.download('punkt_tab')\n",
        "\n",
        "# Your existing code for text and sentence tokenization\n",
        "text = \"I’ve been asked to review a recent study on glyphosate’s cytotoxicity in rats. Given your expertise in the field, I believe it would be beneficial for both of you to act as peer reviewers. Once you’ve collated your comments, I’ll submit the final review on our behalf.\"\n",
        "sentences = sent_tokenize(text)\n",
        "\n",
        "# Continue with your code to classify sentences\n",
        "for sentence in sentences:\n",
        "    predicted_label = classify_question(sentence)\n",
        "    print(f\"Sentence: {sentence}\")\n",
        "    print(f\"Predicted Label: {predicted_label}\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GGSGhex0yU2r",
        "outputId": "93784e3a-5625-4f8d-fcaa-14d41c239abe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentence: I met with EPA officials earlier this afternoon, and we discussed delaying the risk assessment for glyphosate.\n",
            "Predicted Label: REGUL_regul\n",
            "\n",
            "Sentence: It seems we have support from key figures, but we’ll need to strategize to ensure there are no surprises from other government agencies.\n",
            "Predicted Label: REGUL_regul\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Texto de entrada\n",
        "text = \"I met with EPA officials earlier this afternoon, and we discussed delaying the risk assessment for glyphosate. It seems we have support from key figures, but we’ll need to strategize to ensure there are no surprises from other government agencies.\"\n",
        "\n",
        "# Dividir o texto em sentenças\n",
        "sentences = sent_tokenize(text)\n",
        "# Classificar cada sentença individualmente\n",
        "for sentence in sentences:\n",
        "    predicted_label = classify_question(sentence)\n",
        "    print(f\"Sentence: {sentence}\")\n",
        "    print(f\"Predicted Label: {predicted_label}\\n\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FpuS2E6Fyh_1",
        "outputId": "c1387cca-aec6-42d6-f3ad-59ea586bb34f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentence: As discussed, we need to escalate our efforts to gain favorable regulatory assessments in Europe.\n",
            "Predicted Label: REGUL_regul\n",
            "\n",
            "Sentence: A mix of scientific review and political strategy will be essential to ensure glyphosate is not classified as a carcinogen.\n",
            "Predicted Label: REGUL_regul\n",
            "\n",
            "Sentence: Let’s initiate a communication campaign to address any doubts regulators may have.\n",
            "Predicted Label: REGUL_regul\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Texto de entrada\n",
        "text = \"As discussed, we need to escalate our efforts to gain favorable regulatory assessments in Europe. A mix of scientific review and political strategy will be essential to ensure glyphosate is not classified as a carcinogen. Let’s initiate a communication campaign to address any doubts regulators may have.\"\n",
        "\n",
        "# Dividir o texto em sentenças\n",
        "sentences = sent_tokenize(text)\n",
        "# Classificar cada sentença individualmente\n",
        "for sentence in sentences:\n",
        "    predicted_label = classify_question(sentence)\n",
        "    print(f\"Sentence: {sentence}\")\n",
        "    print(f\"Predicted Label: {predicted_label}\\n\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_I-wI-IYy6nk",
        "outputId": "5b52cedd-ea08-44dc-ca99-0afd18298b02"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentence: I’ve been asked to review a recent study on glyphosate’s cytotoxicity in rats.\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: Given your expertise in the field, I believe it would be beneficial for both of you to act as peer reviewers.\n",
            "Predicted Label: GHOST_ghost\n",
            "\n",
            "Sentence: Once you’ve collated your comments, I’ll submit the final review on our behalf.\n",
            "Predicted Label: GHOST_ghost\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Texto de entrada\n",
        "text = \"I’ve been asked to review a recent study on glyphosate’s cytotoxicity in rats. Given your expertise in the field, I believe it would be beneficial for both of you to act as peer reviewers. Once you’ve collated your comments, I’ll submit the final review on our behalf.\"\n",
        "\n",
        "# Dividir o texto em sentenças\n",
        "sentences = sent_tokenize(text)\n",
        "# Classificar cada sentença individualmente\n",
        "for sentence in sentences:\n",
        "    predicted_label = classify_question(sentence)\n",
        "    print(f\"Sentence: {sentence}\")\n",
        "    print(f\"Predicted Label: {predicted_label}\\n\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aJWOapOwzQMg",
        "outputId": "4390b28b-d4c8-4c7a-bd74-96c5ed9c1e4c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentence: Our recent study confirms that surfactants in the Roundup formulation significantly increase glyphosate absorption through the skin.\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: This presents a challenge in terms of risk evaluations, and we may need to reevaluate our safety guidelines in light of this.\n",
            "Predicted Label: TOXIC_toxic\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Texto de entrada\n",
        "text = \"Our recent study confirms that surfactants in the Roundup formulation significantly increase glyphosate absorption through the skin. This presents a challenge in terms of risk evaluations, and we may need to reevaluate our safety guidelines in light of this.\"\n",
        "\n",
        "# Dividir o texto em sentenças\n",
        "sentences = sent_tokenize(text)\n",
        "# Classificar cada sentença individualmente\n",
        "for sentence in sentences:\n",
        "    predicted_label = classify_question(sentence)\n",
        "    print(f\"Sentence: {sentence}\")\n",
        "    print(f\"Predicted Label: {predicted_label}\\n\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K9D6BQl1Qx_-",
        "outputId": "cc7ff776-0dc1-4bca-a81f-06a6e595d432"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentence: Our recent study confirms that surfactants in the Roundup formulation significantly increase glyphosate absorption through the skin?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: This presents a challenge in terms of risk evaluations, and we may need to reevaluate our safety guidelines in light of this!\n",
            "Predicted Label: REGUL_regul\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Texto de entrada\n",
        "text = \"Our recent study confirms that surfactants in the Roundup formulation significantly increase glyphosate absorption through the skin? This presents a challenge in terms of risk evaluations, and we may need to reevaluate our safety guidelines in light of this!\"\n",
        "\n",
        "# Dividir o texto em sentenças\n",
        "sentences = sent_tokenize(text)\n",
        "# Classificar cada sentença individualmente\n",
        "for sentence in sentences:\n",
        "    predicted_label = classify_question(sentence)\n",
        "    print(f\"Sentence: {sentence}\")\n",
        "    print(f\"Predicted Label: {predicted_label}\\n\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KkhgVvrdz6Ti",
        "outputId": "227b9ce0-dcdc-4e70-83e4-e3f134e73c6e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentence: good morning.\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: Our recent study confirms that surfactants in the Roundup formulation significantly increase glyphosate absorption through the skin?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Texto de entrada\n",
        "text = \"good morning. Our recent study confirms that surfactants in the Roundup formulation significantly increase glyphosate absorption through the skin?\"\n",
        "\n",
        "# Dividir o texto em sentenças\n",
        "sentences = sent_tokenize(text)\n",
        "# Classificar cada sentença individualmente\n",
        "for sentence in sentences:\n",
        "    predicted_label = classify_question(sentence)\n",
        "    print(f\"Sentence: {sentence}\")\n",
        "    print(f\"Predicted Label: {predicted_label}\\n\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vDSE2-u4hyPL",
        "outputId": "cfb8fb73-7ab3-4664-85cf-060e4bb52faa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentence:  How far is it from Denver to Aspen .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What county is Modesto\n",
            " Who was Galileo .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is an atom .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: When did Hawaii become a state .\n",
            "Predicted Label: TOXIC_toxic\n",
            "\n",
            "Sentence: How tall is the Sears Building .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: George Bush purchased a small interest in which baseball team .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is Australia s national flower .\n",
            "Predicted Label: TOXIC_toxic\n",
            "\n",
            "Sentence: Why does the moon turn orange .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is autism .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What city had a world fair in 1900 .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What person s head is on a dime .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is the average weight of a Yellow Labrador .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: Who was the first man to fly across the Pacific Ocean .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: When did Idaho become a state .\n",
            "Predicted Label: TOXIC_toxic\n",
            "\n",
            "Sentence: What is the life expectancy for crickets .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What metal has the highest melting point .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: Who developed the vaccination against polio .\n",
            "Predicted Label: TOXIC_toxic\n",
            "\n",
            "Sentence: What is epilepsy .\n",
            "Predicted Label: TOXIC_toxic\n",
            "\n",
            "Sentence: What year did the Titanic sink .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: Who was the first American to walk in space .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is a biosphere .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What river in the US is known as the Big Muddy .\n",
            "Predicted Label: TOXIC_toxic\n",
            "\n",
            "Sentence: What is bipolar disorder .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is cholesterol .\n",
            "Predicted Label: TOXIC_toxic\n",
            "\n",
            "Sentence: Who developed the Macintosh computer .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is caffeine .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What imaginary line is halfway between the North and South Poles .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: Where is John Wayne airport .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What hemisphere is the Philippines in .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is the average speed of the horses at the Kentucky Derby .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: Where are the Rocky Mountains .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What are invertebrates .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is the temperature at the center of the earth .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: When did John F. Kennedy get elected as President .\n",
            "Predicted Label: TOXIC_toxic\n",
            "\n",
            "Sentence: How old was Elvis Presley when he died .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: Where is the Orinoco River .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: How far is the service line from the net in tennis .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: How much fiber should you have per day .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: How many Great Lakes are there .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: Material called linen is made from what plant .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is Teflon .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is amitriptyline .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is a shaman .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is the proper name for a female walrus .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is a group of turkeys called .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: How long did Rip Van Winkle sleep .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What are triglycerides .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: How many liters in a gallon .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is the name of the chocolate company in San Francisco .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What are amphibians .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: Who discovered x-rays .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: Which comedian s signature line is `` Can we talk  .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is fibromyalgia .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is done with worn or outdated flags .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What does cc in engines mean .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: When did Elvis Presley die .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is the capital of Yugoslavia .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: Where is Milan .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is the speed hummingbirds fly .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is the oldest city in the United States .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What was W.C. Fields  real name .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What river flows between Fargo\n",
            " What do bats eat .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What state did the Battle of Bighorn take place in .\n",
            "Predicted Label: TOXIC_toxic\n",
            "\n",
            "Sentence: Who was Abraham Lincoln .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What do you call a newborn kangaroo .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What are spider veins .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What day and month did John Lennon die .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What strait separates North America from Asia .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is the population of Seattle .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: How much was a ticket for the Titanic .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is the largest city in the world .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What American composer wrote the music for `` West Side Story  .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: Where is the Mall of the America .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is the pH scale .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What type of currency is used in Australia .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: How tall is the Gateway Arch in St. Louis\n",
            " How much does the human adult female brain weigh .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: Who was the first governor of Alaska .\n",
            "Predicted Label: TOXIC_toxic\n",
            "\n",
            "Sentence: What is a prism .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: When was the first liver transplant .\n",
            "Predicted Label: TOXIC_toxic\n",
            "\n",
            "Sentence: Who was elected president of South Africa in 1994 .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is the population of China .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: When was Rosa Parks born .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: Why is a ladybug helpful .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is amoxicillin .\n",
            "Predicted Label: TOXIC_toxic\n",
            "\n",
            "Sentence: Who was the first female United States Representative .\n",
            "Predicted Label: TOXIC_toxic\n",
            "\n",
            "Sentence: What are xerophytes .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What country did Ponce de Leon come from .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: The U.S. Department of Treasury first issued paper currency for the U.S. during which war .\n",
            "Predicted Label: REGUL_regul\n",
            "\n",
            "Sentence: What is desktop publishing .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is the temperature of the sun s surface .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What year did Canada join the United Nations .\n",
            "Predicted Label: TOXIC_toxic\n",
            "\n",
            "Sentence: What is the oldest university in the US .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: Where is Prince Edward Island .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: Mercury\n",
            " What is cryogenics .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What are coral reefs .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is the longest major league baseball-winning streak .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is neurology .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: Who invented the calculator .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: How do you measure earthquakes .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: Who is Duke Ellington .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What county is Phoenix\n",
            " What is a micron .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: The sun s core\n",
            " What is the Ohio state bird .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: When were William Shakespeare s twins born .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is the highest dam in the U.S. .\n",
            "Predicted Label: TOXIC_toxic\n",
            "\n",
            "Sentence: What color is a poison arrow frog .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is acupuncture .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is the length of the coastline of the state of Alaska .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is the name of Neil Armstrong s wife .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is Hawaii s state flower .\n",
            "Predicted Label: TOXIC_toxic\n",
            "\n",
            "Sentence: Who won Ms. American in 1989 .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: When did the Hindenberg crash .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What mineral helps prevent osteoporosis .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What was the last year that the Chicago Cubs won the World Series .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: Where is Perth .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What year did WWII begin .\n",
            "Predicted Label: TOXIC_toxic\n",
            "\n",
            "Sentence: What is the diameter of a golf ball .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is an eclipse .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: Who discovered America .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is the earth s diameter .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: Which president was unmarried .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: How wide is the Milky Way galaxy .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: During which season do most thunderstorms occur .\n",
            "Predicted Label: TOXIC_toxic\n",
            "\n",
            "Sentence: What is Wimbledon .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is the gestation period for a cat .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: How far is a nautical mile .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: Who was the abolitionist who led the raid on Harper s Ferry in 1859 .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What does target heart rate mean .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What was the first satellite to go into space .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is foreclosure .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is the major fault line near Kentucky .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: Where is the Holland Tunnel .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: Who wrote the hymn `` Amazing Grace  .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What position did Willie Davis play in baseball .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What are platelets .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is severance pay .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is the name of Roy Roger s dog .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: Where are the National Archives .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is a baby turkey called .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is poliomyelitis .\n",
            "Predicted Label: TOXIC_toxic\n",
            "\n",
            "Sentence: What is the longest bone in the human body .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: Who is a German philosopher .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What were Christopher Columbus  three ships .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What does Phi Beta Kappa mean .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is nicotine .\n",
            "Predicted Label: TOXIC_toxic\n",
            "\n",
            "Sentence: What is another name for vitamin B1 .\n",
            "Predicted Label: TOXIC_toxic\n",
            "\n",
            "Sentence: Who discovered radium .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What are sunspots .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: When was Algeria colonized .\n",
            "Predicted Label: TOXIC_toxic\n",
            "\n",
            "Sentence: What baseball team was the first to make numbers part of their uniform .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What continent is Egypt on .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is the capital of Mongolia .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is nanotechnology .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: In the late 1700 s British convicts were used to populate which colony .\n",
            "Predicted Label: TOXIC_toxic\n",
            "\n",
            "Sentence: What state is the geographic center of the lower 48 states .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is an obtuse angle .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What are polymers .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: When is hurricane season in the Caribbean .\n",
            "Predicted Label: TOXIC_toxic\n",
            "\n",
            "Sentence: Where is the volcano Mauna Loa .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is another astronomic term for the Northern Lights .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What peninsula is Spain part of .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: When was Lyndon B. Johnson born .\n",
            "Predicted Label: TOXIC_toxic\n",
            "\n",
            "Sentence: What is acetaminophen .\n",
            "Predicted Label: TOXIC_toxic\n",
            "\n",
            "Sentence: What state has the least amount of rain per year .\n",
            "Predicted Label: TOXIC_toxic\n",
            "\n",
            "Sentence: Who founded American Red Cross .\n",
            "Predicted Label: TOXIC_toxic\n",
            "\n",
            "Sentence: What year did the Milwaukee Braves become the Atlanta Braves .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: How fast is alcohol absorbed .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: When is the summer solstice .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is supernova .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: Where is the Shawnee National Forest .\n",
            "Predicted Label: TOXIC_toxic\n",
            "\n",
            "Sentence: What U.S. state s motto is `` Live free or Die  .\n",
            "Predicted Label: REGUL_regul\n",
            "\n",
            "Sentence: Where is the Lourve .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: When was the first stamp issued .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What primary colors do you mix to make orange .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: How far is Pluto from the sun .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What body of water are the Canary Islands in .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is neuropathy .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: Where is the Euphrates River .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is cryptography .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is natural gas composed of .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: Who is the Prime Minister of Canada .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What French ruler was defeated at the battle of Waterloo .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is leukemia .\n",
            "Predicted Label: TOXIC_toxic\n",
            "\n",
            "Sentence: Where did Howard Hughes die .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is the birthstone for June .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is the sales tax in Minnesota .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is the distance in miles from the earth to the sun .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is the average life span for a chicken .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: When was the first Wal-Mart store opened .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is relative humidity .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What city has the zip code of 35824 .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What currency is used in Algeria .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: Who invented the hula hoop .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What was the most popular toy in 1957 .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is pastrami made of .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is the name of the satellite that the Soviet Union sent into space in 1957 .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What city s newspaper is called `` The Enquirer  .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: Who invented the slinky .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What are the animals that don t have backbones called .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is the melting point of copper .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: Where is the volcano Olympus Mons located .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: Who was the 23rd president of the United States .\n",
            "Predicted Label: TOXIC_toxic\n",
            "\n",
            "Sentence: What is the average body temperature .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What does a defibrillator do .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is the effect of acid rain .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What year did the United States abolish the draft .\n",
            "Predicted Label: TOXIC_toxic\n",
            "\n",
            "Sentence: How fast is the speed of light .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What province is Montreal in .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What New York City structure is also known as the Twin Towers .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is fungus .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is the most frequently spoken language in the Netherlands .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is sodium chloride .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What are the spots on dominoes called .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: How many pounds in a ton .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is influenza .\n",
            "Predicted Label: TOXIC_toxic\n",
            "\n",
            "Sentence: What is ozone depletion .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What year was the Mona Lisa painted .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What does `` Sitting Shiva  mean .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is the electrical output in Madrid\n",
            " Which mountain range in North America stretches from Maine to Georgia .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is plastic made of .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is the population of Nigeria .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What does your spleen do .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: Where is the Grand Canyon .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: Who invented the telephone .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What year did the U.S. buy Alaska .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is the name of the leader of Ireland .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is phenylalanine .\n",
            "Predicted Label: TOXIC_toxic\n",
            "\n",
            "Sentence: How many gallons of water are there in a cubic foot .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What are the two houses of the Legislative branch .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is sonar .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: In Poland\n",
            " What is phosphorus .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is the location of the Sea of Tranquility .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: How fast is sound .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What French province is cognac produced in .\n",
            "Predicted Label: TOXIC_toxic\n",
            "\n",
            "Sentence: What is Valentine s Day .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What causes gray hair .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is hypertension .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is bandwidth .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is the longest suspension bridge in the U.S. .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is a parasite .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is home equity .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What do meteorologists do .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is the criterion for being legally blind .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: Who is the tallest man in the world .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What are the twin cities .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What did Edward Binney and Howard Smith invent in 1903 .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is the statue of liberty made of .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is pilates .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What planet is known as the `` red  planet .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is the depth of the Nile river .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is the colorful Korean traditional dress called .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is Mardi Gras .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: Mexican pesos are worth what in U.S. dollars .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: Who was the first African American to play for the Brooklyn Dodgers .\n",
            "Predicted Label: TOXIC_toxic\n",
            "\n",
            "Sentence: Who was the first Prime Minister of Canada .\n",
            "Predicted Label: TOXIC_toxic\n",
            "\n",
            "Sentence: How many Admirals are there in the U.S. Navy .\n",
            "Predicted Label: TOXIC_toxic\n",
            "\n",
            "Sentence: What instrument did Glenn Miller play .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: How old was Joan of Arc when she died .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What does the word fortnight mean .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is dianetics .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is the capital of Ethiopia .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: For how long is an elephant pregnant .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: How did Janice Joplin die .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is the primary language in Iceland .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is the difference between AM radio stations and FM radio stations .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is osteoporosis .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: Who was the first woman governor in the U.S. .\n",
            "Predicted Label: TOXIC_toxic\n",
            "\n",
            "Sentence: What is peyote .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is the esophagus used for .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is viscosity .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What year did Oklahoma become a state .\n",
            "Predicted Label: TOXIC_toxic\n",
            "\n",
            "Sentence: What is the abbreviation for Texas .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is a mirror made out of .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: Where on the body is a mortarboard worn .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What was J.F.K.\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: s wife s name .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What does I.V.\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: stand for .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is the chunnel .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: Where is Hitler buried .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What are antacids .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is pulmonary fibrosis .\n",
            "Predicted Label: TOXIC_toxic\n",
            "\n",
            "Sentence: What are Quaaludes .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is naproxen .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is strep throat .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is the largest city in the U.S. .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is foot and mouth disease .\n",
            "Predicted Label: TOXIC_toxic\n",
            "\n",
            "Sentence: What is the life expectancy of a dollar bill .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What do you call a professional map drawer .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What are Aborigines .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is hybridization .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What color is indigo .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: How old do you have to be in order to rent a car in Italy .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What does a barometer measure .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What color is a giraffe s tongue .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What does USPS stand for .\n",
            "Predicted Label: REGUL_regul\n",
            "\n",
            "Sentence: What year did the NFL go on strike .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is solar wind .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What date did Neil Armstrong land on the moon .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: When was Hiroshima bombed .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: Where is the Savannah River .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: Who was the first woman killed in the Vietnam War .\n",
            "Predicted Label: TOXIC_toxic\n",
            "\n",
            "Sentence: What planet has the strongest magnetic field of all the planets .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: Who is the governor of Alaska .\n",
            "Predicted Label: TOXIC_toxic\n",
            "\n",
            "Sentence: What year did Mussolini seize power in Italy .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is the capital of Persia .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: Where is the Eiffel Tower .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: How many hearts does an octopus have .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is pneumonia .\n",
            "Predicted Label: TOXIC_toxic\n",
            "\n",
            "Sentence: What is the deepest lake in the US .\n",
            "Predicted Label: TOXIC_toxic\n",
            "\n",
            "Sentence: What is a fuel cell .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: Who was the first U.S. president to appear on TV .\n",
            "Predicted Label: TOXIC_toxic\n",
            "\n",
            "Sentence: Where is the Little League Museum .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What are the two types of twins .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is the brightest star .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is diabetes .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: When was President Kennedy shot .\n",
            "Predicted Label: TOXIC_toxic\n",
            "\n",
            "Sentence: What is TMJ .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What color is yak milk .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What date was Dwight D. Eisenhower born .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What does the technical term ISDN mean .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: Why is the sun yellow .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is the conversion rate between dollars and pounds .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: When was Abraham Lincoln born .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is the Milky Way .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is mold .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What year was Mozart born .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is a group of frogs called .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is the name of William Penn s ship .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is the melting point of gold .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is the street address of the White House .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is semolina .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What fruit is Melba sauce made from .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is Ursa Major .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is the percentage of water content in the human body .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: How much does water weigh .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What was President Lyndon Johnson s reform program called .\n",
            "Predicted Label: REGUL_regul\n",
            "\n",
            "Sentence: What is the murder rate in Windsor\n",
            " Who is the only president to serve 2 non-consecutive terms .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is the population of Australia .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: Who painted the ceiling of the Sistine Chapel .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: Name a stimulant .\n",
            "Predicted Label: TOXIC_toxic\n",
            "\n",
            "Sentence: What is the effect of volcanoes on the climate .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What year did the Andy Griffith show begin .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is acid rain .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is the date of Mexico s independence .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is the location of Lake Champlain .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is the Illinois state flower .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is Maryland s state bird .\n",
            "Predicted Label: TOXIC_toxic\n",
            "\n",
            "Sentence: What is quicksilver .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: Who wrote `` The Divine Comedy  .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is the speed of light .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is the width of a football field .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: Why in tennis are zero points called love .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What kind of dog was Toto in the Wizard of Oz .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is a thyroid .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What does ciao mean .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is the only artery that carries blue blood from the heart to the lungs .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: How often does Old Faithful erupt at Yellowstone National Park .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is acetic acid .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is the elevation of St. Louis\n",
            " What color does litmus paper turn when it comes into contact with a strong acid .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What are the colors of the German flag .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is the Moulin Rouge .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What soviet seaport is on the Black Sea .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is the atomic weight of silver .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What currency do they use in Brazil .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What are pathogens .\n",
            "Predicted Label: TOXIC_toxic\n",
            "\n",
            "Sentence: What is mad cow disease .\n",
            "Predicted Label: TOXIC_toxic\n",
            "\n",
            "Sentence: Name a food high in zinc .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: When did North Carolina enter the union .\n",
            "Predicted Label: TOXIC_toxic\n",
            "\n",
            "Sentence: Where do apple snails live .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What are ethics .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What does CPR stand for .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is an annuity .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: Who killed John F. Kennedy .\n",
            "Predicted Label: TOXIC_toxic\n",
            "\n",
            "Sentence: Who was the first vice president of the U.S. .\n",
            "Predicted Label: TOXIC_toxic\n",
            "\n",
            "Sentence: What birthstone is turquoise .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: Who was the first US President to ride in an automobile to his inauguration .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: How old was the youngest president of the United States .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: When was Ulysses S. Grant born .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is Muscular Dystrophy .\n",
            "Predicted Label: TOXIC_toxic\n",
            "\n",
            "Sentence: Who lived in the Neuschwanstein castle .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is propylene glycol .\n",
            "Predicted Label: TOXIC_toxic\n",
            "\n",
            "Sentence: What is a panic disorder .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: Who invented the instant Polaroid camera .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is a carcinogen .\n",
            "Predicted Label: TOXIC_toxic\n",
            "\n",
            "Sentence: What is a baby lion called .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is the world s population .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is nepotism .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is die-casting .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is myopia .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is the sales tax rate in New York .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: Developing nations comprise what percentage of the world s population .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is the fourth highest mountain in the world .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is Shakespeare s nickname .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is the heaviest naturally occurring element .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: When is Father s Day .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What does the acronym NASA stand for .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: How long is the Columbia River in miles .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What city s newspaper is called `` The Star  .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is carbon dioxide .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: Where is the Mason/Dixon line .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: When was the Boston tea party .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is metabolism .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: Which U.S.A. president appeared on `` Laugh-In  .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What are cigarettes made of .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is the capital of Zimbabwe .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What does NASA stand for .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is the state flower of Michigan .\n",
            "Predicted Label: TOXIC_toxic\n",
            "\n",
            "Sentence: What are semiconductors .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is nuclear power .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is a tsunami .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: Who is the congressman from state of Texas on the armed forces committee .\n",
            "Predicted Label: REGUL_regul\n",
            "\n",
            "Sentence: Who was president in 1913 .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: When was the first kidney transplant .\n",
            "Predicted Label: TOXIC_toxic\n",
            "\n",
            "Sentence: What are Canada s two territories .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What was the name of the plane Lindbergh flew solo across the Atlantic .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is genocide .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What continent is Argentina on .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What monastery was raided by Vikings in the late eighth century .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is an earthquake .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: Where is the tallest roller coaster located .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What are enzymes .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: Who discovered oxygen .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is bangers and mash .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is the name given to the Tiger at Louisiana State University .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: Where are the British crown jewels kept .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: Who was the first person to reach the North Pole .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is an ulcer .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is vertigo .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is the spirometer test .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: When is the official first day of summer .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What does the abbreviation SOS mean .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is the smallest bird in Britain .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: Who invented Trivial Pursuit .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What gasses are in the troposphere .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: Which country has the most water pollution .\n",
            "Predicted Label: TOXIC_toxic\n",
            "\n",
            "Sentence: What is the scientific name for elephant .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: Who is the actress known for her role in the movie `` Gypsy  .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What breed of hunting dog did the Beverly Hillbillies own .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is the rainiest place on Earth .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: Who was the first African American to win the Nobel Prize in literature .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: When is St. Patrick s Day .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What was FDR s dog s name .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What colors need to be mixed to get the color pink .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is the most popular sport in Japan .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is the active ingredient in baking soda .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: When was Thomas Jefferson born .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: How cold should a refrigerator be .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: When was the telephone invented .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is the most common eye color .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: Where was the first golf course in the United States .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is schizophrenia .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is angiotensin .\n",
            "Predicted Label: TOXIC_toxic\n",
            "\n",
            "Sentence: What did Jesse Jackson organize .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is New York s state bird .\n",
            "Predicted Label: TOXIC_toxic\n",
            "\n",
            "Sentence: What is the National Park in Utah .\n",
            "Predicted Label: TOXIC_toxic\n",
            "\n",
            "Sentence: What is Susan B. Anthony s birthday .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: In which state would you find the Catskill Mountains .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What do you call a word that is spelled the same backwards and forwards .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What are pediatricians .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What chain store is headquartered in Bentonville\n",
            " What are solar cells .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is compounded interest .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What are capers .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is an antigen .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What currency does Luxembourg use .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is the population of Venezuela .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What type of polymer is used for bulletproof vests .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What currency does Argentina use .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is a thermometer .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What Canadian city has the largest population .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What color are crickets .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: Which country gave New York the Statue of Liberty .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What was the name of the first U.S. satellite sent into space .\n",
            "Predicted Label: TOXIC_toxic\n",
            "\n",
            "Sentence: What precious stone is a form of pure carbon .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What kind of gas is in a fluorescent bulb .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is rheumatoid arthritis .\n",
            "Predicted Label: TOXIC_toxic\n",
            "\n",
            "Sentence: What river runs through Rowe\n",
            " What is cerebral palsy .\n",
            "Predicted Label: TOXIC_toxic\n",
            "\n",
            "Sentence: What city is also known as `` The Gateway to the West  .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: How far away is the moon .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is the source of natural gas .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: In what spacecraft did U.S. astronaut Alan Shepard make his historic 1961 flight .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is pectin .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is bio-diversity .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What s the easiest way to remove wallpaper .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What year did the Titanic start on its journey .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: How much of an apple is water .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: Who was the 22nd President of the US .\n",
            "Predicted Label: TOXIC_toxic\n",
            "\n",
            "Sentence: What is the money they use in Zambia .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: How many feet in a mile .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is the birthstone of October .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is e-coli .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Texto de entrada\n",
        "text = ''' How far is it from Denver to Aspen .\n",
        " What county is Modesto\n",
        " Who was Galileo .\n",
        " What is an atom .\n",
        " When did Hawaii become a state .\n",
        " How tall is the Sears Building .\n",
        " George Bush purchased a small interest in which baseball team .\n",
        " What is Australia s national flower .\n",
        " Why does the moon turn orange .\n",
        " What is autism .\n",
        " What city had a world fair in 1900 .\n",
        " What person s head is on a dime .\n",
        " What is the average weight of a Yellow Labrador .\n",
        " Who was the first man to fly across the Pacific Ocean .\n",
        " When did Idaho become a state .\n",
        " What is the life expectancy for crickets .\n",
        " What metal has the highest melting point .\n",
        " Who developed the vaccination against polio .\n",
        " What is epilepsy .\n",
        " What year did the Titanic sink .\n",
        " Who was the first American to walk in space .\n",
        " What is a biosphere .\n",
        " What river in the US is known as the Big Muddy .\n",
        " What is bipolar disorder .\n",
        " What is cholesterol .\n",
        " Who developed the Macintosh computer .\n",
        " What is caffeine .\n",
        " What imaginary line is halfway between the North and South Poles .\n",
        " Where is John Wayne airport .\n",
        " What hemisphere is the Philippines in .\n",
        " What is the average speed of the horses at the Kentucky Derby .\n",
        " Where are the Rocky Mountains .\n",
        " What are invertebrates .\n",
        " What is the temperature at the center of the earth .\n",
        " When did John F. Kennedy get elected as President .\n",
        " How old was Elvis Presley when he died .\n",
        " Where is the Orinoco River .\n",
        " How far is the service line from the net in tennis .\n",
        " How much fiber should you have per day .\n",
        " How many Great Lakes are there .\n",
        " Material called linen is made from what plant .\n",
        " What is Teflon .\n",
        " What is amitriptyline .\n",
        " What is a shaman .\n",
        " What is the proper name for a female walrus .\n",
        " What is a group of turkeys called .\n",
        " How long did Rip Van Winkle sleep .\n",
        " What are triglycerides .\n",
        " How many liters in a gallon .\n",
        " What is the name of the chocolate company in San Francisco .\n",
        " What are amphibians .\n",
        " Who discovered x-rays .\n",
        " Which comedian s signature line is `` Can we talk  .\n",
        " What is fibromyalgia .\n",
        " What is done with worn or outdated flags .\n",
        " What does cc in engines mean .\n",
        " When did Elvis Presley die .\n",
        " What is the capital of Yugoslavia .\n",
        " Where is Milan .\n",
        " What is the speed hummingbirds fly .\n",
        " What is the oldest city in the United States .\n",
        " What was W.C. Fields  real name .\n",
        " What river flows between Fargo\n",
        " What do bats eat .\n",
        " What state did the Battle of Bighorn take place in .\n",
        " Who was Abraham Lincoln .\n",
        " What do you call a newborn kangaroo .\n",
        " What are spider veins .\n",
        " What day and month did John Lennon die .\n",
        " What strait separates North America from Asia .\n",
        " What is the population of Seattle .\n",
        " How much was a ticket for the Titanic .\n",
        " What is the largest city in the world .\n",
        " What American composer wrote the music for `` West Side Story  .\n",
        " Where is the Mall of the America .\n",
        " What is the pH scale .\n",
        " What type of currency is used in Australia .\n",
        " How tall is the Gateway Arch in St. Louis\n",
        " How much does the human adult female brain weigh .\n",
        " Who was the first governor of Alaska .\n",
        " What is a prism .\n",
        " When was the first liver transplant .\n",
        " Who was elected president of South Africa in 1994 .\n",
        " What is the population of China .\n",
        " When was Rosa Parks born .\n",
        " Why is a ladybug helpful .\n",
        " What is amoxicillin .\n",
        " Who was the first female United States Representative .\n",
        " What are xerophytes .\n",
        " What country did Ponce de Leon come from .\n",
        " The U.S. Department of Treasury first issued paper currency for the U.S. during which war .\n",
        " What is desktop publishing .\n",
        " What is the temperature of the sun s surface .\n",
        " What year did Canada join the United Nations .\n",
        " What is the oldest university in the US .\n",
        " Where is Prince Edward Island .\n",
        " Mercury\n",
        " What is cryogenics .\n",
        " What are coral reefs .\n",
        " What is the longest major league baseball-winning streak .\n",
        " What is neurology .\n",
        " Who invented the calculator .\n",
        " How do you measure earthquakes .\n",
        " Who is Duke Ellington .\n",
        " What county is Phoenix\n",
        " What is a micron .\n",
        " The sun s core\n",
        " What is the Ohio state bird .\n",
        " When were William Shakespeare s twins born .\n",
        " What is the highest dam in the U.S. .\n",
        " What color is a poison arrow frog .\n",
        " What is acupuncture .\n",
        " What is the length of the coastline of the state of Alaska .\n",
        " What is the name of Neil Armstrong s wife .\n",
        " What is Hawaii s state flower .\n",
        " Who won Ms. American in 1989 .\n",
        " When did the Hindenberg crash .\n",
        " What mineral helps prevent osteoporosis .\n",
        " What was the last year that the Chicago Cubs won the World Series .\n",
        " Where is Perth .\n",
        " What year did WWII begin .\n",
        " What is the diameter of a golf ball .\n",
        " What is an eclipse .\n",
        " Who discovered America .\n",
        " What is the earth s diameter .\n",
        " Which president was unmarried .\n",
        " How wide is the Milky Way galaxy .\n",
        " During which season do most thunderstorms occur .\n",
        " What is Wimbledon .\n",
        " What is the gestation period for a cat .\n",
        " How far is a nautical mile .\n",
        " Who was the abolitionist who led the raid on Harper s Ferry in 1859 .\n",
        " What does target heart rate mean .\n",
        " What was the first satellite to go into space .\n",
        " What is foreclosure .\n",
        " What is the major fault line near Kentucky .\n",
        " Where is the Holland Tunnel .\n",
        " Who wrote the hymn `` Amazing Grace  .\n",
        " What position did Willie Davis play in baseball .\n",
        " What are platelets .\n",
        " What is severance pay .\n",
        " What is the name of Roy Roger s dog .\n",
        " Where are the National Archives .\n",
        " What is a baby turkey called .\n",
        " What is poliomyelitis .\n",
        " What is the longest bone in the human body .\n",
        " Who is a German philosopher .\n",
        " What were Christopher Columbus  three ships .\n",
        " What does Phi Beta Kappa mean .\n",
        " What is nicotine .\n",
        " What is another name for vitamin B1 .\n",
        " Who discovered radium .\n",
        " What are sunspots .\n",
        " When was Algeria colonized .\n",
        " What baseball team was the first to make numbers part of their uniform .\n",
        " What continent is Egypt on .\n",
        " What is the capital of Mongolia .\n",
        " What is nanotechnology .\n",
        " In the late 1700 s British convicts were used to populate which colony .\n",
        " What state is the geographic center of the lower 48 states .\n",
        " What is an obtuse angle .\n",
        " What are polymers .\n",
        " When is hurricane season in the Caribbean .\n",
        " Where is the volcano Mauna Loa .\n",
        " What is another astronomic term for the Northern Lights .\n",
        " What peninsula is Spain part of .\n",
        " When was Lyndon B. Johnson born .\n",
        " What is acetaminophen .\n",
        " What state has the least amount of rain per year .\n",
        " Who founded American Red Cross .\n",
        " What year did the Milwaukee Braves become the Atlanta Braves .\n",
        " How fast is alcohol absorbed .\n",
        " When is the summer solstice .\n",
        " What is supernova .\n",
        " Where is the Shawnee National Forest .\n",
        " What U.S. state s motto is `` Live free or Die  .\n",
        " Where is the Lourve .\n",
        " When was the first stamp issued .\n",
        " What primary colors do you mix to make orange .\n",
        " How far is Pluto from the sun .\n",
        " What body of water are the Canary Islands in .\n",
        " What is neuropathy .\n",
        " Where is the Euphrates River .\n",
        " What is cryptography .\n",
        " What is natural gas composed of .\n",
        " Who is the Prime Minister of Canada .\n",
        " What French ruler was defeated at the battle of Waterloo .\n",
        " What is leukemia .\n",
        " Where did Howard Hughes die .\n",
        " What is the birthstone for June .\n",
        " What is the sales tax in Minnesota .\n",
        " What is the distance in miles from the earth to the sun .\n",
        " What is the average life span for a chicken .\n",
        " When was the first Wal-Mart store opened .\n",
        " What is relative humidity .\n",
        " What city has the zip code of 35824 .\n",
        " What currency is used in Algeria .\n",
        " Who invented the hula hoop .\n",
        " What was the most popular toy in 1957 .\n",
        " What is pastrami made of .\n",
        " What is the name of the satellite that the Soviet Union sent into space in 1957 .\n",
        " What city s newspaper is called `` The Enquirer  .\n",
        " Who invented the slinky .\n",
        " What are the animals that don t have backbones called .\n",
        " What is the melting point of copper .\n",
        " Where is the volcano Olympus Mons located .\n",
        " Who was the 23rd president of the United States .\n",
        " What is the average body temperature .\n",
        " What does a defibrillator do .\n",
        " What is the effect of acid rain .\n",
        " What year did the United States abolish the draft .\n",
        " How fast is the speed of light .\n",
        " What province is Montreal in .\n",
        " What New York City structure is also known as the Twin Towers .\n",
        " What is fungus .\n",
        " What is the most frequently spoken language in the Netherlands .\n",
        " What is sodium chloride .\n",
        " What are the spots on dominoes called .\n",
        " How many pounds in a ton .\n",
        " What is influenza .\n",
        " What is ozone depletion .\n",
        " What year was the Mona Lisa painted .\n",
        " What does `` Sitting Shiva  mean .\n",
        " What is the electrical output in Madrid\n",
        " Which mountain range in North America stretches from Maine to Georgia .\n",
        " What is plastic made of .\n",
        " What is the population of Nigeria .\n",
        " What does your spleen do .\n",
        " Where is the Grand Canyon .\n",
        " Who invented the telephone .\n",
        " What year did the U.S. buy Alaska .\n",
        " What is the name of the leader of Ireland .\n",
        " What is phenylalanine .\n",
        " How many gallons of water are there in a cubic foot .\n",
        " What are the two houses of the Legislative branch .\n",
        " What is sonar .\n",
        " In Poland\n",
        " What is phosphorus .\n",
        " What is the location of the Sea of Tranquility .\n",
        " How fast is sound .\n",
        " What French province is cognac produced in .\n",
        " What is Valentine s Day .\n",
        " What causes gray hair .\n",
        " What is hypertension .\n",
        " What is bandwidth .\n",
        " What is the longest suspension bridge in the U.S. .\n",
        " What is a parasite .\n",
        " What is home equity .\n",
        " What do meteorologists do .\n",
        " What is the criterion for being legally blind .\n",
        " Who is the tallest man in the world .\n",
        " What are the twin cities .\n",
        " What did Edward Binney and Howard Smith invent in 1903 .\n",
        " What is the statue of liberty made of .\n",
        " What is pilates .\n",
        " What planet is known as the `` red  planet .\n",
        " What is the depth of the Nile river .\n",
        " What is the colorful Korean traditional dress called .\n",
        " What is Mardi Gras .\n",
        " Mexican pesos are worth what in U.S. dollars .\n",
        " Who was the first African American to play for the Brooklyn Dodgers .\n",
        " Who was the first Prime Minister of Canada .\n",
        " How many Admirals are there in the U.S. Navy .\n",
        " What instrument did Glenn Miller play .\n",
        " How old was Joan of Arc when she died .\n",
        " What does the word fortnight mean .\n",
        " What is dianetics .\n",
        " What is the capital of Ethiopia .\n",
        " For how long is an elephant pregnant .\n",
        " How did Janice Joplin die .\n",
        " What is the primary language in Iceland .\n",
        " What is the difference between AM radio stations and FM radio stations .\n",
        " What is osteoporosis .\n",
        " Who was the first woman governor in the U.S. .\n",
        " What is peyote .\n",
        " What is the esophagus used for .\n",
        " What is viscosity .\n",
        " What year did Oklahoma become a state .\n",
        " What is the abbreviation for Texas .\n",
        " What is a mirror made out of .\n",
        " Where on the body is a mortarboard worn .\n",
        " What was J.F.K. s wife s name .\n",
        " What does I.V. stand for .\n",
        " What is the chunnel .\n",
        " Where is Hitler buried .\n",
        " What are antacids .\n",
        " What is pulmonary fibrosis .\n",
        " What are Quaaludes .\n",
        " What is naproxen .\n",
        " What is strep throat .\n",
        " What is the largest city in the U.S. .\n",
        " What is foot and mouth disease .\n",
        " What is the life expectancy of a dollar bill .\n",
        " What do you call a professional map drawer .\n",
        " What are Aborigines .\n",
        " What is hybridization .\n",
        " What color is indigo .\n",
        " How old do you have to be in order to rent a car in Italy .\n",
        " What does a barometer measure .\n",
        " What color is a giraffe s tongue .\n",
        " What does USPS stand for .\n",
        " What year did the NFL go on strike .\n",
        " What is solar wind .\n",
        " What date did Neil Armstrong land on the moon .\n",
        " When was Hiroshima bombed .\n",
        " Where is the Savannah River .\n",
        " Who was the first woman killed in the Vietnam War .\n",
        " What planet has the strongest magnetic field of all the planets .\n",
        " Who is the governor of Alaska .\n",
        " What year did Mussolini seize power in Italy .\n",
        " What is the capital of Persia .\n",
        " Where is the Eiffel Tower .\n",
        " How many hearts does an octopus have .\n",
        " What is pneumonia .\n",
        " What is the deepest lake in the US .\n",
        " What is a fuel cell .\n",
        " Who was the first U.S. president to appear on TV .\n",
        " Where is the Little League Museum .\n",
        " What are the two types of twins .\n",
        " What is the brightest star .\n",
        " What is diabetes .\n",
        " When was President Kennedy shot .\n",
        " What is TMJ .\n",
        " What color is yak milk .\n",
        " What date was Dwight D. Eisenhower born .\n",
        " What does the technical term ISDN mean .\n",
        " Why is the sun yellow .\n",
        " What is the conversion rate between dollars and pounds .\n",
        " When was Abraham Lincoln born .\n",
        " What is the Milky Way .\n",
        " What is mold .\n",
        " What year was Mozart born .\n",
        " What is a group of frogs called .\n",
        " What is the name of William Penn s ship .\n",
        " What is the melting point of gold .\n",
        " What is the street address of the White House .\n",
        " What is semolina .\n",
        " What fruit is Melba sauce made from .\n",
        " What is Ursa Major .\n",
        " What is the percentage of water content in the human body .\n",
        " How much does water weigh .\n",
        " What was President Lyndon Johnson s reform program called .\n",
        " What is the murder rate in Windsor\n",
        " Who is the only president to serve 2 non-consecutive terms .\n",
        " What is the population of Australia .\n",
        " Who painted the ceiling of the Sistine Chapel .\n",
        " Name a stimulant .\n",
        " What is the effect of volcanoes on the climate .\n",
        " What year did the Andy Griffith show begin .\n",
        " What is acid rain .\n",
        " What is the date of Mexico s independence .\n",
        " What is the location of Lake Champlain .\n",
        " What is the Illinois state flower .\n",
        " What is Maryland s state bird .\n",
        " What is quicksilver .\n",
        " Who wrote `` The Divine Comedy  .\n",
        " What is the speed of light .\n",
        " What is the width of a football field .\n",
        " Why in tennis are zero points called love .\n",
        " What kind of dog was Toto in the Wizard of Oz .\n",
        " What is a thyroid .\n",
        " What does ciao mean .\n",
        " What is the only artery that carries blue blood from the heart to the lungs .\n",
        " How often does Old Faithful erupt at Yellowstone National Park .\n",
        " What is acetic acid .\n",
        " What is the elevation of St. Louis\n",
        " What color does litmus paper turn when it comes into contact with a strong acid .\n",
        " What are the colors of the German flag .\n",
        " What is the Moulin Rouge .\n",
        " What soviet seaport is on the Black Sea .\n",
        " What is the atomic weight of silver .\n",
        " What currency do they use in Brazil .\n",
        " What are pathogens .\n",
        " What is mad cow disease .\n",
        " Name a food high in zinc .\n",
        " When did North Carolina enter the union .\n",
        " Where do apple snails live .\n",
        " What are ethics .\n",
        " What does CPR stand for .\n",
        " What is an annuity .\n",
        " Who killed John F. Kennedy .\n",
        " Who was the first vice president of the U.S. .\n",
        " What birthstone is turquoise .\n",
        " Who was the first US President to ride in an automobile to his inauguration .\n",
        " How old was the youngest president of the United States .\n",
        " When was Ulysses S. Grant born .\n",
        " What is Muscular Dystrophy .\n",
        " Who lived in the Neuschwanstein castle .\n",
        " What is propylene glycol .\n",
        " What is a panic disorder .\n",
        " Who invented the instant Polaroid camera .\n",
        " What is a carcinogen .\n",
        " What is a baby lion called .\n",
        " What is the world s population .\n",
        " What is nepotism .\n",
        " What is die-casting .\n",
        " What is myopia .\n",
        " What is the sales tax rate in New York .\n",
        " Developing nations comprise what percentage of the world s population .\n",
        " What is the fourth highest mountain in the world .\n",
        " What is Shakespeare s nickname .\n",
        " What is the heaviest naturally occurring element .\n",
        " When is Father s Day .\n",
        " What does the acronym NASA stand for .\n",
        " How long is the Columbia River in miles .\n",
        " What city s newspaper is called `` The Star  .\n",
        " What is carbon dioxide .\n",
        " Where is the Mason/Dixon line .\n",
        " When was the Boston tea party .\n",
        " What is metabolism .\n",
        " Which U.S.A. president appeared on `` Laugh-In  .\n",
        " What are cigarettes made of .\n",
        " What is the capital of Zimbabwe .\n",
        " What does NASA stand for .\n",
        " What is the state flower of Michigan .\n",
        " What are semiconductors .\n",
        " What is nuclear power .\n",
        " What is a tsunami .\n",
        " Who is the congressman from state of Texas on the armed forces committee .\n",
        " Who was president in 1913 .\n",
        " When was the first kidney transplant .\n",
        " What are Canada s two territories .\n",
        " What was the name of the plane Lindbergh flew solo across the Atlantic .\n",
        " What is genocide .\n",
        " What continent is Argentina on .\n",
        " What monastery was raided by Vikings in the late eighth century .\n",
        " What is an earthquake .\n",
        " Where is the tallest roller coaster located .\n",
        " What are enzymes .\n",
        " Who discovered oxygen .\n",
        " What is bangers and mash .\n",
        " What is the name given to the Tiger at Louisiana State University .\n",
        " Where are the British crown jewels kept .\n",
        " Who was the first person to reach the North Pole .\n",
        " What is an ulcer .\n",
        " What is vertigo .\n",
        " What is the spirometer test .\n",
        " When is the official first day of summer .\n",
        " What does the abbreviation SOS mean .\n",
        " What is the smallest bird in Britain .\n",
        " Who invented Trivial Pursuit .\n",
        " What gasses are in the troposphere .\n",
        " Which country has the most water pollution .\n",
        " What is the scientific name for elephant .\n",
        " Who is the actress known for her role in the movie `` Gypsy  .\n",
        " What breed of hunting dog did the Beverly Hillbillies own .\n",
        " What is the rainiest place on Earth .\n",
        " Who was the first African American to win the Nobel Prize in literature .\n",
        " When is St. Patrick s Day .\n",
        " What was FDR s dog s name .\n",
        " What colors need to be mixed to get the color pink .\n",
        " What is the most popular sport in Japan .\n",
        " What is the active ingredient in baking soda .\n",
        " When was Thomas Jefferson born .\n",
        " How cold should a refrigerator be .\n",
        " When was the telephone invented .\n",
        " What is the most common eye color .\n",
        " Where was the first golf course in the United States .\n",
        " What is schizophrenia .\n",
        " What is angiotensin .\n",
        " What did Jesse Jackson organize .\n",
        " What is New York s state bird .\n",
        " What is the National Park in Utah .\n",
        " What is Susan B. Anthony s birthday .\n",
        " In which state would you find the Catskill Mountains .\n",
        " What do you call a word that is spelled the same backwards and forwards .\n",
        " What are pediatricians .\n",
        " What chain store is headquartered in Bentonville\n",
        " What are solar cells .\n",
        " What is compounded interest .\n",
        " What are capers .\n",
        " What is an antigen .\n",
        " What currency does Luxembourg use .\n",
        " What is the population of Venezuela .\n",
        " What type of polymer is used for bulletproof vests .\n",
        " What currency does Argentina use .\n",
        " What is a thermometer .\n",
        " What Canadian city has the largest population .\n",
        " What color are crickets .\n",
        " Which country gave New York the Statue of Liberty .\n",
        " What was the name of the first U.S. satellite sent into space .\n",
        " What precious stone is a form of pure carbon .\n",
        " What kind of gas is in a fluorescent bulb .\n",
        " What is rheumatoid arthritis .\n",
        " What river runs through Rowe\n",
        " What is cerebral palsy .\n",
        " What city is also known as `` The Gateway to the West  .\n",
        " How far away is the moon .\n",
        " What is the source of natural gas .\n",
        " In what spacecraft did U.S. astronaut Alan Shepard make his historic 1961 flight .\n",
        " What is pectin .\n",
        " What is bio-diversity .\n",
        " What s the easiest way to remove wallpaper .\n",
        " What year did the Titanic start on its journey .\n",
        " How much of an apple is water .\n",
        " Who was the 22nd President of the US .\n",
        " What is the money they use in Zambia .\n",
        " How many feet in a mile .\n",
        " What is the birthstone of October .\n",
        " What is e-coli .'''\n",
        "\n",
        "# Dividir o texto em sentenças\n",
        "sentences = sent_tokenize(text)\n",
        "# Classificar cada sentença individualmente\n",
        "for sentence in sentences:\n",
        "    predicted_label = classify_question(sentence)\n",
        "    print(f\"Sentence: {sentence}\")\n",
        "    print(f\"Predicted Label: {predicted_label}\\n\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pp_Gec1HkM8N",
        "outputId": "9213783a-3bd2-4e1c-a24c-2d2c2c976a63"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted Label: CHEMI_chemi\n"
          ]
        }
      ],
      "source": [
        "# Exemplo de uso\n",
        "new_question = \"This document contains a study on the absorption of glyphosate through human skin  highlighting concerns about increased absorption when surfactants are used in the formulation.\"\n",
        "predicted_label = classify_question(new_question)\n",
        "print(f\"Predicted Label: {predicted_label}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KSPkkPcHugv2",
        "outputId": "e36b6871-3433-40b3-f803-151f76047da2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentence: \n",
            "     How far is it from Denver to Aspen ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What county is Modesto\n",
            " Who was Galileo ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is an atom ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: When did Hawaii become a state ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: How tall is the Sears Building ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: George Bush purchased a small interest in which baseball team ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is Australia s national flower ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: Why does the moon turn orange ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is autism ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What city had a world fair in 1900 ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What person s head is on a dime ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is the average weight of a Yellow Labrador ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: Who was the first man to fly across the Pacific Ocean ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: When did Idaho become a state ?\n",
            "Predicted Label: TOXIC_toxic\n",
            "\n",
            "Sentence: What is the life expectancy for crickets ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What metal has the highest melting point ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: Who developed the vaccination against polio ?\n",
            "Predicted Label: TOXIC_toxic\n",
            "\n",
            "Sentence: What is epilepsy ?\n",
            "Predicted Label: TOXIC_toxic\n",
            "\n",
            "Sentence: What year did the Titanic sink ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: Who was the first American to walk in space ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is a biosphere ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What river in the US is known as the Big Muddy ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is bipolar disorder ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is cholesterol ?\n",
            "Predicted Label: TOXIC_toxic\n",
            "\n",
            "Sentence: Who developed the Macintosh computer ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is caffeine ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What imaginary line is halfway between the North and South Poles ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: Where is John Wayne airport ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What hemisphere is the Philippines in ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is the average speed of the horses at the Kentucky Derby ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: Where are the Rocky Mountains ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What are invertebrates ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is the temperature at the center of the earth ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: When did John F. Kennedy get elected as President ?\n",
            "Predicted Label: TOXIC_toxic\n",
            "\n",
            "Sentence: How old was Elvis Presley when he died ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: Where is the Orinoco River ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: How far is the service line from the net in tennis ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: How much fiber should you have per day ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: How many Great Lakes are there ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: Material called linen is made from what plant ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is Teflon ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is amitriptyline ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is a shaman ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is the proper name for a female walrus ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is a group of turkeys called ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: How long did Rip Van Winkle sleep ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What are triglycerides ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: How many liters in a gallon ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is the name of the chocolate company in San Francisco ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What are amphibians ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: Who discovered x-rays ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: Which comedian s signature line is  Can we talk  ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is fibromyalgia ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is done with worn or outdated flags ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What does cc in engines mean ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: When did Elvis Presley die ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is the capital of Yugoslavia ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: Where is Milan ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is the speed hummingbirds fly ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is the oldest city in the United States ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What was W.C. Fields  real name ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What river flows between Fargo\n",
            " What do bats eat ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What state did the Battle of Bighorn take place in ?\n",
            "Predicted Label: TOXIC_toxic\n",
            "\n",
            "Sentence: Who was Abraham Lincoln ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What do you call a newborn kangaroo ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What are spider veins ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What day and month did John Lennon die ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What strait separates North America from Asia ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is the population of Seattle ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: How much was a ticket for the Titanic ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is the largest city in the world ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What American composer wrote the music for  West Side Story  ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: Where is the Mall of the America ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is the pH scale ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What type of currency is used in Australia ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: How tall is the Gateway Arch in St. Louis\n",
            " How much does the human adult female brain weigh ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: Who was the first governor of Alaska ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is a prism ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: When was the first liver transplant ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: Who was elected president of South Africa in 1994 ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is the population of China ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: When was Rosa Parks born ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: Why is a ladybug helpful ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is amoxicillin ?\n",
            "Predicted Label: TOXIC_toxic\n",
            "\n",
            "Sentence: Who was the first female United States Representative ?\n",
            "Predicted Label: TOXIC_toxic\n",
            "\n",
            "Sentence: What are xerophytes ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What country did Ponce de Leon come from ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: The U.S. Department of Treasury first issued paper currency for the U.S. during which war ?\n",
            "Predicted Label: REGUL_regul\n",
            "\n",
            "Sentence: What is desktop publishing ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is the temperature of the sun s surface ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What year did Canada join the United Nations ?\n",
            "Predicted Label: TOXIC_toxic\n",
            "\n",
            "Sentence: What is the oldest university in the US ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: Where is Prince Edward Island ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: Mercury\n",
            " What is cryogenics ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What are coral reefs ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is the longest major league baseball-winning streak ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is neurology ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: Who invented the calculator ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: How do you measure earthquakes ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: Who is Duke Ellington ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What county is Phoenix\n",
            " What is a micron ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: The sun s core\n",
            " What is the Ohio state bird ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: When were William Shakespeare s twins born ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is the highest dam in the U.S. ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What color is a poison arrow frog ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is acupuncture ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is the length of the coastline of the state of Alaska ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is the name of Neil Armstrong s wife ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is Hawaii s state flower ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: Who won Ms. American in 1989 ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: When did the Hindenberg crash ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What mineral helps prevent osteoporosis ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What was the last year that the Chicago Cubs won the World Series ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: Where is Perth ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What year did WWII begin ?\n",
            "Predicted Label: TOXIC_toxic\n",
            "\n",
            "Sentence: What is the diameter of a golf ball ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is an eclipse ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: Who discovered America ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is the earth s diameter ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: Which president was unmarried ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: How wide is the Milky Way galaxy ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: During which season do most thunderstorms occur ?\n",
            "Predicted Label: TOXIC_toxic\n",
            "\n",
            "Sentence: What is Wimbledon ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is the gestation period for a cat ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: How far is a nautical mile ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: Who was the abolitionist who led the raid on Harper s Ferry in 1859 ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What does target heart rate mean ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What was the first satellite to go into space ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is foreclosure ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is the major fault line near Kentucky ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: Where is the Holland Tunnel ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: Who wrote the hymn  Amazing Grace  ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What position did Willie Davis play in baseball ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What are platelets ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is severance pay ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is the name of Roy Roger s dog ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: Where are the National Archives ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is a baby turkey called ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is poliomyelitis ?\n",
            "Predicted Label: TOXIC_toxic\n",
            "\n",
            "Sentence: What is the longest bone in the human body ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: Who is a German philosopher ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What were Christopher Columbus  three ships ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What does Phi Beta Kappa mean ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is nicotine ?\n",
            "Predicted Label: TOXIC_toxic\n",
            "\n",
            "Sentence: What is another name for vitamin B1 ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: Who discovered radium ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What are sunspots ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: When was Algeria colonized ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What baseball team was the first to make numbers part of their uniform ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What continent is Egypt on ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is the capital of Mongolia ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is nanotechnology ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: In the late 1700 s British convicts were used to populate which colony ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What state is the geographic center of the lower 48 states ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is an obtuse angle ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What are polymers ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: When is hurricane season in the Caribbean ?\n",
            "Predicted Label: TOXIC_toxic\n",
            "\n",
            "Sentence: Where is the volcano Mauna Loa ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is another astronomic term for the Northern Lights ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What peninsula is Spain part of ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: When was Lyndon B. Johnson born ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is acetaminophen ?\n",
            "Predicted Label: TOXIC_toxic\n",
            "\n",
            "Sentence: What state has the least amount of rain per year ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: Who founded American Red Cross ?\n",
            "Predicted Label: TOXIC_toxic\n",
            "\n",
            "Sentence: What year did the Milwaukee Braves become the Atlanta Braves ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: How fast is alcohol absorbed ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: When is the summer solstice ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is supernova ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: Where is the Shawnee National Forest ?\n",
            "Predicted Label: TOXIC_toxic\n",
            "\n",
            "Sentence: What U.S. state s motto is  Live free or Die  ?\n",
            "Predicted Label: TOXIC_toxic\n",
            "\n",
            "Sentence: Where is the Lourve ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: When was the first stamp issued ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What primary colors do you mix to make orange ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: How far is Pluto from the sun ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What body of water are the Canary Islands in ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is neuropathy ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: Where is the Euphrates River ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is cryptography ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is natural gas composed of ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: Who is the Prime Minister of Canada ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What French ruler was defeated at the battle of Waterloo ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is leukemia ?\n",
            "Predicted Label: TOXIC_toxic\n",
            "\n",
            "Sentence: Where did Howard Hughes die ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is the birthstone for June ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is the sales tax in Minnesota ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is the distance in miles from the earth to the sun ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is the average life span for a chicken ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: When was the first Wal-Mart store opened ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is relative humidity ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What city has the zip code of 35824 ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What currency is used in Algeria ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: Who invented the hula hoop ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What was the most popular toy in 1957 ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is pastrami made of ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is the name of the satellite that the Soviet Union sent into space in 1957 ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What city s newspaper is called  The Enquirer  ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: Who invented the slinky ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What are the animals that don t have backbones called ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is the melting point of copper ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: Where is the volcano Olympus Mons located ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: Who was the 23rd president of the United States ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is the average body temperature ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What does a defibrillator do ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is the effect of acid rain ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What year did the United States abolish the draft ?\n",
            "Predicted Label: TOXIC_toxic\n",
            "\n",
            "Sentence: How fast is the speed of light ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What province is Montreal in ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What New York City structure is also known as the Twin Towers ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is fungus ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is the most frequently spoken language in the Netherlands ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is sodium chloride ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What are the spots on dominoes called ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: How many pounds in a ton ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is influenza ?\n",
            "Predicted Label: TOXIC_toxic\n",
            "\n",
            "Sentence: What is ozone depletion ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What year was the Mona Lisa painted ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What does  Sitting Shiva  mean ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is the electrical output in Madrid\n",
            " Which mountain range in North America stretches from Maine to Georgia ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is plastic made of ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is the population of Nigeria ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What does your spleen do ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: Where is the Grand Canyon ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: Who invented the telephone ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What year did the U.S. buy Alaska ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is the name of the leader of Ireland ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is phenylalanine ?\n",
            "Predicted Label: TOXIC_toxic\n",
            "\n",
            "Sentence: How many gallons of water are there in a cubic foot ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What are the two houses of the Legislative branch ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is sonar ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: In Poland\n",
            " What is phosphorus ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is the location of the Sea of Tranquility ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: How fast is sound ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What French province is cognac produced in ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is Valentine s Day ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What causes gray hair ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is hypertension ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is bandwidth ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is the longest suspension bridge in the U.S. ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is a parasite ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is home equity ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What do meteorologists do ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is the criterion for being legally blind ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: Who is the tallest man in the world ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What are the twin cities ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What did Edward Binney and Howard Smith invent in 1903 ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is the statue of liberty made of ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is pilates ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What planet is known as the  red  planet ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is the depth of the Nile river ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is the colorful Korean traditional dress called ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is Mardi Gras ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: Mexican pesos are worth what in U.S. dollars ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: Who was the first African American to play for the Brooklyn Dodgers ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: Who was the first Prime Minister of Canada ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: How many Admirals are there in the U.S. Navy ?\n",
            "Predicted Label: TOXIC_toxic\n",
            "\n",
            "Sentence: What instrument did Glenn Miller play ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: How old was Joan of Arc when she died ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What does the word fortnight mean ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is dianetics ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is the capital of Ethiopia ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: For how long is an elephant pregnant ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: How did Janice Joplin die ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is the primary language in Iceland ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is the difference between AM radio stations and FM radio stations ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is osteoporosis ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: Who was the first woman governor in the U.S. ?\n",
            "Predicted Label: TOXIC_toxic\n",
            "\n",
            "Sentence: What is peyote ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is the esophagus used for ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is viscosity ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What year did Oklahoma become a state ?\n",
            "Predicted Label: TOXIC_toxic\n",
            "\n",
            "Sentence: What is the abbreviation for Texas ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is a mirror made out of ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: Where on the body is a mortarboard worn ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What was J.F.K.\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: s wife s name ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What does I.V.\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: stand for ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is the chunnel ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: Where is Hitler buried ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What are antacids ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is pulmonary fibrosis ?\n",
            "Predicted Label: TOXIC_toxic\n",
            "\n",
            "Sentence: What are Quaaludes ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is naproxen ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is strep throat ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is the largest city in the U.S. ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is foot and mouth disease ?\n",
            "Predicted Label: TOXIC_toxic\n",
            "\n",
            "Sentence: What is the life expectancy of a dollar bill ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What do you call a professional map drawer ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What are Aborigines ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is hybridization ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What color is indigo ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: How old do you have to be in order to rent a car in Italy ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What does a barometer measure ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What color is a giraffe s tongue ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What does USPS stand for ?\n",
            "Predicted Label: REGUL_regul\n",
            "\n",
            "Sentence: What year did the NFL go on strike ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is solar wind ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What date did Neil Armstrong land on the moon ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: When was Hiroshima bombed ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: Where is the Savannah River ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: Who was the first woman killed in the Vietnam War ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What planet has the strongest magnetic field of all the planets ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: Who is the governor of Alaska ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What year did Mussolini seize power in Italy ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is the capital of Persia ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: Where is the Eiffel Tower ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: How many hearts does an octopus have ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is pneumonia ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is the deepest lake in the US ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is a fuel cell ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: Who was the first U.S. president to appear on TV ?\n",
            "Predicted Label: TOXIC_toxic\n",
            "\n",
            "Sentence: Where is the Little League Museum ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What are the two types of twins ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is the brightest star ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is diabetes ?\n",
            "Predicted Label: TOXIC_toxic\n",
            "\n",
            "Sentence: When was President Kennedy shot ?\n",
            "Predicted Label: TOXIC_toxic\n",
            "\n",
            "Sentence: What is TMJ ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What color is yak milk ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What date was Dwight D. Eisenhower born ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What does the technical term ISDN mean ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: Why is the sun yellow ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is the conversion rate between dollars and pounds ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: When was Abraham Lincoln born ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is the Milky Way ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is mold ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What year was Mozart born ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is a group of frogs called ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is the name of William Penn s ship ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is the melting point of gold ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is the street address of the White House ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is semolina ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What fruit is Melba sauce made from ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is Ursa Major ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is the percentage of water content in the human body ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: How much does water weigh ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What was President Lyndon Johnson s reform program called ?\n",
            "Predicted Label: REGUL_regul\n",
            "\n",
            "Sentence: What is the murder rate in Windsor\n",
            " Who is the only president to serve 2 non-consecutive terms ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is the population of Australia ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: Who painted the ceiling of the Sistine Chapel ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: Name a stimulant .\n",
            "Predicted Label: TOXIC_toxic\n",
            "\n",
            "Sentence: What is the effect of volcanoes on the climate ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What year did the Andy Griffith show begin ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is acid rain ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is the date of Mexico s independence ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is the location of Lake Champlain ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is the Illinois state flower ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is Maryland s state bird ?\n",
            "Predicted Label: TOXIC_toxic\n",
            "\n",
            "Sentence: What is quicksilver ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: Who wrote  The Divine Comedy  ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is the speed of light ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is the width of a football field ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: Why in tennis are zero points called love ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What kind of dog was Toto in the Wizard of Oz ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is a thyroid ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What does ciao mean ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is the only artery that carries blue blood from the heart to the lungs ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: How often does Old Faithful erupt at Yellowstone National Park ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is acetic acid ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is the elevation of St. Louis\n",
            " What color does litmus paper turn when it comes into contact with a strong acid ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What are the colors of the German flag ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is the Moulin Rouge ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What soviet seaport is on the Black Sea ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is the atomic weight of silver ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What currency do they use in Brazil ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What are pathogens ?\n",
            "Predicted Label: TOXIC_toxic\n",
            "\n",
            "Sentence: What is mad cow disease ?\n",
            "Predicted Label: TOXIC_toxic\n",
            "\n",
            "Sentence: Name a food high in zinc .\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: When did North Carolina enter the union ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: Where do apple snails live ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What are ethics ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What does CPR stand for ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is an annuity ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: Who killed John F. Kennedy ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: Who was the first vice president of the U.S. ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What birthstone is turquoise ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: Who was the first US President to ride in an automobile to his inauguration ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: How old was the youngest president of the United States ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: When was Ulysses S. Grant born ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is Muscular Dystrophy ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: Who lived in the Neuschwanstein castle ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is propylene glycol ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is a panic disorder ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: Who invented the instant Polaroid camera ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is a carcinogen ?\n",
            "Predicted Label: TOXIC_toxic\n",
            "\n",
            "Sentence: What is a baby lion called ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is the world s population ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is nepotism ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is die-casting ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is myopia ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is the sales tax rate in New York ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: Developing nations comprise what percentage of the world s population ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is the fourth highest mountain in the world ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is Shakespeare s nickname ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is the heaviest naturally occurring element ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: When is Father s Day ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What does the acronym NASA stand for ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: How long is the Columbia River in miles ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What city s newspaper is called  The Star  ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is carbon dioxide ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: Where is the Mason/Dixon line ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: When was the Boston tea party ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is metabolism ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: Which U.S.A. president appeared on  Laugh-In  ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What are cigarettes made of ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is the capital of Zimbabwe ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What does NASA stand for ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is the state flower of Michigan ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What are semiconductors ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is nuclear power ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is a tsunami ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: Who is the congressman from state of Texas on the armed forces committee ?\n",
            "Predicted Label: REGUL_regul\n",
            "\n",
            "Sentence: Who was president in 1913 ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: When was the first kidney transplant ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What are Canada s two territories ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What was the name of the plane Lindbergh flew solo across the Atlantic ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is genocide ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What continent is Argentina on ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What monastery was raided by Vikings in the late eighth century ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is an earthquake ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: Where is the tallest roller coaster located ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What are enzymes ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: Who discovered oxygen ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is bangers and mash ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is the name given to the Tiger at Louisiana State University ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: Where are the British crown jewels kept ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: Who was the first person to reach the North Pole ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is an ulcer ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is vertigo ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is the spirometer test ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: When is the official first day of summer ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What does the abbreviation SOS mean ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is the smallest bird in Britain ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: Who invented Trivial Pursuit ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What gasses are in the troposphere ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: Which country has the most water pollution ?\n",
            "Predicted Label: TOXIC_toxic\n",
            "\n",
            "Sentence: What is the scientific name for elephant ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: Who is the actress known for her role in the movie  Gypsy  ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What breed of hunting dog did the Beverly Hillbillies own ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is the rainiest place on Earth ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: Who was the first African American to win the Nobel Prize in literature ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: When is St. Patrick s Day ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What was FDR s dog s name ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What colors need to be mixed to get the color pink ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is the most popular sport in Japan ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is the active ingredient in baking soda ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: When was Thomas Jefferson born ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: How cold should a refrigerator be ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: When was the telephone invented ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is the most common eye color ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: Where was the first golf course in the United States ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is schizophrenia ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is angiotensin ?\n",
            "Predicted Label: TOXIC_toxic\n",
            "\n",
            "Sentence: What did Jesse Jackson organize ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is New York s state bird ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is the National Park in Utah ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is Susan B. Anthony s birthday ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: In which state would you find the Catskill Mountains ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What do you call a word that is spelled the same backwards and forwards ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What are pediatricians ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What chain store is headquartered in Bentonville\n",
            " What are solar cells ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is compounded interest ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What are capers ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is an antigen ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What currency does Luxembourg use ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is the population of Venezuela ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What type of polymer is used for bulletproof vests ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What currency does Argentina use ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is a thermometer ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What Canadian city has the largest population ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What color are crickets ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: Which country gave New York the Statue of Liberty ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What was the name of the first U.S. satellite sent into space ?\n",
            "Predicted Label: TOXIC_toxic\n",
            "\n",
            "Sentence: What precious stone is a form of pure carbon ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What kind of gas is in a fluorescent bulb ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is rheumatoid arthritis ?\n",
            "Predicted Label: TOXIC_toxic\n",
            "\n",
            "Sentence: What river runs through Rowe\n",
            " What is cerebral palsy ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What city is also known as  The Gateway to the West  ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: How far away is the moon ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is the source of natural gas ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: In what spacecraft did U.S. astronaut Alan Shepard make his historic 1961 flight ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is pectin ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is bio-diversity ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What s the easiest way to remove wallpaper ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What year did the Titanic start on its journey ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: How much of an apple is water ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: Who was the 22nd President of the US ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is the money they use in Zambia ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: How many feet in a mile ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is the birthstone of October ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n",
            "Sentence: What is e-coli ?\n",
            "Predicted Label: CHEMI_chemi\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Texto de entrada\n",
        "text = '''\n",
        "     How far is it from Denver to Aspen ?\n",
        " What county is Modesto\n",
        " Who was Galileo ?\n",
        " What is an atom ?\n",
        " When did Hawaii become a state ?\n",
        " How tall is the Sears Building ?\n",
        " George Bush purchased a small interest in which baseball team ?\n",
        " What is Australia s national flower ?\n",
        " Why does the moon turn orange ?\n",
        " What is autism ?\n",
        " What city had a world fair in 1900 ?\n",
        " What person s head is on a dime ?\n",
        " What is the average weight of a Yellow Labrador ?\n",
        " Who was the first man to fly across the Pacific Ocean ?\n",
        " When did Idaho become a state ?\n",
        " What is the life expectancy for crickets ?\n",
        " What metal has the highest melting point ?\n",
        " Who developed the vaccination against polio ?\n",
        " What is epilepsy ?\n",
        " What year did the Titanic sink ?\n",
        " Who was the first American to walk in space ?\n",
        " What is a biosphere ?\n",
        " What river in the US is known as the Big Muddy ?\n",
        " What is bipolar disorder ?\n",
        " What is cholesterol ?\n",
        " Who developed the Macintosh computer ?\n",
        " What is caffeine ?\n",
        " What imaginary line is halfway between the North and South Poles ?\n",
        " Where is John Wayne airport ?\n",
        " What hemisphere is the Philippines in ?\n",
        " What is the average speed of the horses at the Kentucky Derby ?\n",
        " Where are the Rocky Mountains ?\n",
        " What are invertebrates ?\n",
        " What is the temperature at the center of the earth ?\n",
        " When did John F. Kennedy get elected as President ?\n",
        " How old was Elvis Presley when he died ?\n",
        " Where is the Orinoco River ?\n",
        " How far is the service line from the net in tennis ?\n",
        " How much fiber should you have per day ?\n",
        " How many Great Lakes are there ?\n",
        " Material called linen is made from what plant ?\n",
        " What is Teflon ?\n",
        " What is amitriptyline ?\n",
        " What is a shaman ?\n",
        " What is the proper name for a female walrus ?\n",
        " What is a group of turkeys called ?\n",
        " How long did Rip Van Winkle sleep ?\n",
        " What are triglycerides ?\n",
        " How many liters in a gallon ?\n",
        " What is the name of the chocolate company in San Francisco ?\n",
        " What are amphibians ?\n",
        " Who discovered x-rays ?\n",
        " Which comedian s signature line is  Can we talk  ?\n",
        " What is fibromyalgia ?\n",
        " What is done with worn or outdated flags ?\n",
        " What does cc in engines mean ?\n",
        " When did Elvis Presley die ?\n",
        " What is the capital of Yugoslavia ?\n",
        " Where is Milan ?\n",
        " What is the speed hummingbirds fly ?\n",
        " What is the oldest city in the United States ?\n",
        " What was W.C. Fields  real name ?\n",
        " What river flows between Fargo\n",
        " What do bats eat ?\n",
        " What state did the Battle of Bighorn take place in ?\n",
        " Who was Abraham Lincoln ?\n",
        " What do you call a newborn kangaroo ?\n",
        " What are spider veins ?\n",
        " What day and month did John Lennon die ?\n",
        " What strait separates North America from Asia ?\n",
        " What is the population of Seattle ?\n",
        " How much was a ticket for the Titanic ?\n",
        " What is the largest city in the world ?\n",
        " What American composer wrote the music for  West Side Story  ?\n",
        " Where is the Mall of the America ?\n",
        " What is the pH scale ?\n",
        " What type of currency is used in Australia ?\n",
        " How tall is the Gateway Arch in St. Louis\n",
        " How much does the human adult female brain weigh ?\n",
        " Who was the first governor of Alaska ?\n",
        " What is a prism ?\n",
        " When was the first liver transplant ?\n",
        " Who was elected president of South Africa in 1994 ?\n",
        " What is the population of China ?\n",
        " When was Rosa Parks born ?\n",
        " Why is a ladybug helpful ?\n",
        " What is amoxicillin ?\n",
        " Who was the first female United States Representative ?\n",
        " What are xerophytes ?\n",
        " What country did Ponce de Leon come from ?\n",
        " The U.S. Department of Treasury first issued paper currency for the U.S. during which war ?\n",
        " What is desktop publishing ?\n",
        " What is the temperature of the sun s surface ?\n",
        " What year did Canada join the United Nations ?\n",
        " What is the oldest university in the US ?\n",
        " Where is Prince Edward Island ?\n",
        " Mercury\n",
        " What is cryogenics ?\n",
        " What are coral reefs ?\n",
        " What is the longest major league baseball-winning streak ?\n",
        " What is neurology ?\n",
        " Who invented the calculator ?\n",
        " How do you measure earthquakes ?\n",
        " Who is Duke Ellington ?\n",
        " What county is Phoenix\n",
        " What is a micron ?\n",
        " The sun s core\n",
        " What is the Ohio state bird ?\n",
        " When were William Shakespeare s twins born ?\n",
        " What is the highest dam in the U.S. ?\n",
        " What color is a poison arrow frog ?\n",
        " What is acupuncture ?\n",
        " What is the length of the coastline of the state of Alaska ?\n",
        " What is the name of Neil Armstrong s wife ?\n",
        " What is Hawaii s state flower ?\n",
        " Who won Ms. American in 1989 ?\n",
        " When did the Hindenberg crash ?\n",
        " What mineral helps prevent osteoporosis ?\n",
        " What was the last year that the Chicago Cubs won the World Series ?\n",
        " Where is Perth ?\n",
        " What year did WWII begin ?\n",
        " What is the diameter of a golf ball ?\n",
        " What is an eclipse ?\n",
        " Who discovered America ?\n",
        " What is the earth s diameter ?\n",
        " Which president was unmarried ?\n",
        " How wide is the Milky Way galaxy ?\n",
        " During which season do most thunderstorms occur ?\n",
        " What is Wimbledon ?\n",
        " What is the gestation period for a cat ?\n",
        " How far is a nautical mile ?\n",
        " Who was the abolitionist who led the raid on Harper s Ferry in 1859 ?\n",
        " What does target heart rate mean ?\n",
        " What was the first satellite to go into space ?\n",
        " What is foreclosure ?\n",
        " What is the major fault line near Kentucky ?\n",
        " Where is the Holland Tunnel ?\n",
        " Who wrote the hymn  Amazing Grace  ?\n",
        " What position did Willie Davis play in baseball ?\n",
        " What are platelets ?\n",
        " What is severance pay ?\n",
        " What is the name of Roy Roger s dog ?\n",
        " Where are the National Archives ?\n",
        " What is a baby turkey called ?\n",
        " What is poliomyelitis ?\n",
        " What is the longest bone in the human body ?\n",
        " Who is a German philosopher ?\n",
        " What were Christopher Columbus  three ships ?\n",
        " What does Phi Beta Kappa mean ?\n",
        " What is nicotine ?\n",
        " What is another name for vitamin B1 ?\n",
        " Who discovered radium ?\n",
        " What are sunspots ?\n",
        " When was Algeria colonized ?\n",
        " What baseball team was the first to make numbers part of their uniform ?\n",
        " What continent is Egypt on ?\n",
        " What is the capital of Mongolia ?\n",
        " What is nanotechnology ?\n",
        " In the late 1700 s British convicts were used to populate which colony ?\n",
        " What state is the geographic center of the lower 48 states ?\n",
        " What is an obtuse angle ?\n",
        " What are polymers ?\n",
        " When is hurricane season in the Caribbean ?\n",
        " Where is the volcano Mauna Loa ?\n",
        " What is another astronomic term for the Northern Lights ?\n",
        " What peninsula is Spain part of ?\n",
        " When was Lyndon B. Johnson born ?\n",
        " What is acetaminophen ?\n",
        " What state has the least amount of rain per year ?\n",
        " Who founded American Red Cross ?\n",
        " What year did the Milwaukee Braves become the Atlanta Braves ?\n",
        " How fast is alcohol absorbed ?\n",
        " When is the summer solstice ?\n",
        " What is supernova ?\n",
        " Where is the Shawnee National Forest ?\n",
        " What U.S. state s motto is  Live free or Die  ?\n",
        " Where is the Lourve ?\n",
        " When was the first stamp issued ?\n",
        " What primary colors do you mix to make orange ?\n",
        " How far is Pluto from the sun ?\n",
        " What body of water are the Canary Islands in ?\n",
        " What is neuropathy ?\n",
        " Where is the Euphrates River ?\n",
        " What is cryptography ?\n",
        " What is natural gas composed of ?\n",
        " Who is the Prime Minister of Canada ?\n",
        " What French ruler was defeated at the battle of Waterloo ?\n",
        " What is leukemia ?\n",
        " Where did Howard Hughes die ?\n",
        " What is the birthstone for June ?\n",
        " What is the sales tax in Minnesota ?\n",
        " What is the distance in miles from the earth to the sun ?\n",
        " What is the average life span for a chicken ?\n",
        " When was the first Wal-Mart store opened ?\n",
        " What is relative humidity ?\n",
        " What city has the zip code of 35824 ?\n",
        " What currency is used in Algeria ?\n",
        " Who invented the hula hoop ?\n",
        " What was the most popular toy in 1957 ?\n",
        " What is pastrami made of ?\n",
        " What is the name of the satellite that the Soviet Union sent into space in 1957 ?\n",
        " What city s newspaper is called  The Enquirer  ?\n",
        " Who invented the slinky ?\n",
        " What are the animals that don t have backbones called ?\n",
        " What is the melting point of copper ?\n",
        " Where is the volcano Olympus Mons located ?\n",
        " Who was the 23rd president of the United States ?\n",
        " What is the average body temperature ?\n",
        " What does a defibrillator do ?\n",
        " What is the effect of acid rain ?\n",
        " What year did the United States abolish the draft ?\n",
        " How fast is the speed of light ?\n",
        " What province is Montreal in ?\n",
        " What New York City structure is also known as the Twin Towers ?\n",
        " What is fungus ?\n",
        " What is the most frequently spoken language in the Netherlands ?\n",
        " What is sodium chloride ?\n",
        " What are the spots on dominoes called ?\n",
        " How many pounds in a ton ?\n",
        " What is influenza ?\n",
        " What is ozone depletion ?\n",
        " What year was the Mona Lisa painted ?\n",
        " What does  Sitting Shiva  mean ?\n",
        " What is the electrical output in Madrid\n",
        " Which mountain range in North America stretches from Maine to Georgia ?\n",
        " What is plastic made of ?\n",
        " What is the population of Nigeria ?\n",
        " What does your spleen do ?\n",
        " Where is the Grand Canyon ?\n",
        " Who invented the telephone ?\n",
        " What year did the U.S. buy Alaska ?\n",
        " What is the name of the leader of Ireland ?\n",
        " What is phenylalanine ?\n",
        " How many gallons of water are there in a cubic foot ?\n",
        " What are the two houses of the Legislative branch ?\n",
        " What is sonar ?\n",
        " In Poland\n",
        " What is phosphorus ?\n",
        " What is the location of the Sea of Tranquility ?\n",
        " How fast is sound ?\n",
        " What French province is cognac produced in ?\n",
        " What is Valentine s Day ?\n",
        " What causes gray hair ?\n",
        " What is hypertension ?\n",
        " What is bandwidth ?\n",
        " What is the longest suspension bridge in the U.S. ?\n",
        " What is a parasite ?\n",
        " What is home equity ?\n",
        " What do meteorologists do ?\n",
        " What is the criterion for being legally blind ?\n",
        " Who is the tallest man in the world ?\n",
        " What are the twin cities ?\n",
        " What did Edward Binney and Howard Smith invent in 1903 ?\n",
        " What is the statue of liberty made of ?\n",
        " What is pilates ?\n",
        " What planet is known as the  red  planet ?\n",
        " What is the depth of the Nile river ?\n",
        " What is the colorful Korean traditional dress called ?\n",
        " What is Mardi Gras ?\n",
        " Mexican pesos are worth what in U.S. dollars ?\n",
        " Who was the first African American to play for the Brooklyn Dodgers ?\n",
        " Who was the first Prime Minister of Canada ?\n",
        " How many Admirals are there in the U.S. Navy ?\n",
        " What instrument did Glenn Miller play ?\n",
        " How old was Joan of Arc when she died ?\n",
        " What does the word fortnight mean ?\n",
        " What is dianetics ?\n",
        " What is the capital of Ethiopia ?\n",
        " For how long is an elephant pregnant ?\n",
        " How did Janice Joplin die ?\n",
        " What is the primary language in Iceland ?\n",
        " What is the difference between AM radio stations and FM radio stations ?\n",
        " What is osteoporosis ?\n",
        " Who was the first woman governor in the U.S. ?\n",
        " What is peyote ?\n",
        " What is the esophagus used for ?\n",
        " What is viscosity ?\n",
        " What year did Oklahoma become a state ?\n",
        " What is the abbreviation for Texas ?\n",
        " What is a mirror made out of ?\n",
        " Where on the body is a mortarboard worn ?\n",
        " What was J.F.K. s wife s name ?\n",
        " What does I.V. stand for ?\n",
        " What is the chunnel ?\n",
        " Where is Hitler buried ?\n",
        " What are antacids ?\n",
        " What is pulmonary fibrosis ?\n",
        " What are Quaaludes ?\n",
        " What is naproxen ?\n",
        " What is strep throat ?\n",
        " What is the largest city in the U.S. ?\n",
        " What is foot and mouth disease ?\n",
        " What is the life expectancy of a dollar bill ?\n",
        " What do you call a professional map drawer ?\n",
        " What are Aborigines ?\n",
        " What is hybridization ?\n",
        " What color is indigo ?\n",
        " How old do you have to be in order to rent a car in Italy ?\n",
        " What does a barometer measure ?\n",
        " What color is a giraffe s tongue ?\n",
        " What does USPS stand for ?\n",
        " What year did the NFL go on strike ?\n",
        " What is solar wind ?\n",
        " What date did Neil Armstrong land on the moon ?\n",
        " When was Hiroshima bombed ?\n",
        " Where is the Savannah River ?\n",
        " Who was the first woman killed in the Vietnam War ?\n",
        " What planet has the strongest magnetic field of all the planets ?\n",
        " Who is the governor of Alaska ?\n",
        " What year did Mussolini seize power in Italy ?\n",
        " What is the capital of Persia ?\n",
        " Where is the Eiffel Tower ?\n",
        " How many hearts does an octopus have ?\n",
        " What is pneumonia ?\n",
        " What is the deepest lake in the US ?\n",
        " What is a fuel cell ?\n",
        " Who was the first U.S. president to appear on TV ?\n",
        " Where is the Little League Museum ?\n",
        " What are the two types of twins ?\n",
        " What is the brightest star ?\n",
        " What is diabetes ?\n",
        " When was President Kennedy shot ?\n",
        " What is TMJ ?\n",
        " What color is yak milk ?\n",
        " What date was Dwight D. Eisenhower born ?\n",
        " What does the technical term ISDN mean ?\n",
        " Why is the sun yellow ?\n",
        " What is the conversion rate between dollars and pounds ?\n",
        " When was Abraham Lincoln born ?\n",
        " What is the Milky Way ?\n",
        " What is mold ?\n",
        " What year was Mozart born ?\n",
        " What is a group of frogs called ?\n",
        " What is the name of William Penn s ship ?\n",
        " What is the melting point of gold ?\n",
        " What is the street address of the White House ?\n",
        " What is semolina ?\n",
        " What fruit is Melba sauce made from ?\n",
        " What is Ursa Major ?\n",
        " What is the percentage of water content in the human body ?\n",
        " How much does water weigh ?\n",
        " What was President Lyndon Johnson s reform program called ?\n",
        " What is the murder rate in Windsor\n",
        " Who is the only president to serve 2 non-consecutive terms ?\n",
        " What is the population of Australia ?\n",
        " Who painted the ceiling of the Sistine Chapel ?\n",
        " Name a stimulant .\n",
        " What is the effect of volcanoes on the climate ?\n",
        " What year did the Andy Griffith show begin ?\n",
        " What is acid rain ?\n",
        " What is the date of Mexico s independence ?\n",
        " What is the location of Lake Champlain ?\n",
        " What is the Illinois state flower ?\n",
        " What is Maryland s state bird ?\n",
        " What is quicksilver ?\n",
        " Who wrote  The Divine Comedy  ?\n",
        " What is the speed of light ?\n",
        " What is the width of a football field ?\n",
        " Why in tennis are zero points called love ?\n",
        " What kind of dog was Toto in the Wizard of Oz ?\n",
        " What is a thyroid ?\n",
        " What does ciao mean ?\n",
        " What is the only artery that carries blue blood from the heart to the lungs ?\n",
        " How often does Old Faithful erupt at Yellowstone National Park ?\n",
        " What is acetic acid ?\n",
        " What is the elevation of St. Louis\n",
        " What color does litmus paper turn when it comes into contact with a strong acid ?\n",
        " What are the colors of the German flag ?\n",
        " What is the Moulin Rouge ?\n",
        " What soviet seaport is on the Black Sea ?\n",
        " What is the atomic weight of silver ?\n",
        " What currency do they use in Brazil ?\n",
        " What are pathogens ?\n",
        " What is mad cow disease ?\n",
        " Name a food high in zinc .\n",
        " When did North Carolina enter the union ?\n",
        " Where do apple snails live ?\n",
        " What are ethics ?\n",
        " What does CPR stand for ?\n",
        " What is an annuity ?\n",
        " Who killed John F. Kennedy ?\n",
        " Who was the first vice president of the U.S. ?\n",
        " What birthstone is turquoise ?\n",
        " Who was the first US President to ride in an automobile to his inauguration ?\n",
        " How old was the youngest president of the United States ?\n",
        " When was Ulysses S. Grant born ?\n",
        " What is Muscular Dystrophy ?\n",
        " Who lived in the Neuschwanstein castle ?\n",
        " What is propylene glycol ?\n",
        " What is a panic disorder ?\n",
        " Who invented the instant Polaroid camera ?\n",
        " What is a carcinogen ?\n",
        " What is a baby lion called ?\n",
        " What is the world s population ?\n",
        " What is nepotism ?\n",
        " What is die-casting ?\n",
        " What is myopia ?\n",
        " What is the sales tax rate in New York ?\n",
        " Developing nations comprise what percentage of the world s population ?\n",
        " What is the fourth highest mountain in the world ?\n",
        " What is Shakespeare s nickname ?\n",
        " What is the heaviest naturally occurring element ?\n",
        " When is Father s Day ?\n",
        " What does the acronym NASA stand for ?\n",
        " How long is the Columbia River in miles ?\n",
        " What city s newspaper is called  The Star  ?\n",
        " What is carbon dioxide ?\n",
        " Where is the Mason/Dixon line ?\n",
        " When was the Boston tea party ?\n",
        " What is metabolism ?\n",
        " Which U.S.A. president appeared on  Laugh-In  ?\n",
        " What are cigarettes made of ?\n",
        " What is the capital of Zimbabwe ?\n",
        " What does NASA stand for ?\n",
        " What is the state flower of Michigan ?\n",
        " What are semiconductors ?\n",
        " What is nuclear power ?\n",
        " What is a tsunami ?\n",
        " Who is the congressman from state of Texas on the armed forces committee ?\n",
        " Who was president in 1913 ?\n",
        " When was the first kidney transplant ?\n",
        " What are Canada s two territories ?\n",
        " What was the name of the plane Lindbergh flew solo across the Atlantic ?\n",
        " What is genocide ?\n",
        " What continent is Argentina on ?\n",
        " What monastery was raided by Vikings in the late eighth century ?\n",
        " What is an earthquake ?\n",
        " Where is the tallest roller coaster located ?\n",
        " What are enzymes ?\n",
        " Who discovered oxygen ?\n",
        " What is bangers and mash ?\n",
        " What is the name given to the Tiger at Louisiana State University ?\n",
        " Where are the British crown jewels kept ?\n",
        " Who was the first person to reach the North Pole ?\n",
        " What is an ulcer ?\n",
        " What is vertigo ?\n",
        " What is the spirometer test ?\n",
        " When is the official first day of summer ?\n",
        " What does the abbreviation SOS mean ?\n",
        " What is the smallest bird in Britain ?\n",
        " Who invented Trivial Pursuit ?\n",
        " What gasses are in the troposphere ?\n",
        " Which country has the most water pollution ?\n",
        " What is the scientific name for elephant ?\n",
        " Who is the actress known for her role in the movie  Gypsy  ?\n",
        " What breed of hunting dog did the Beverly Hillbillies own ?\n",
        " What is the rainiest place on Earth ?\n",
        " Who was the first African American to win the Nobel Prize in literature ?\n",
        " When is St. Patrick s Day ?\n",
        " What was FDR s dog s name ?\n",
        " What colors need to be mixed to get the color pink ?\n",
        " What is the most popular sport in Japan ?\n",
        " What is the active ingredient in baking soda ?\n",
        " When was Thomas Jefferson born ?\n",
        " How cold should a refrigerator be ?\n",
        " When was the telephone invented ?\n",
        " What is the most common eye color ?\n",
        " Where was the first golf course in the United States ?\n",
        " What is schizophrenia ?\n",
        " What is angiotensin ?\n",
        " What did Jesse Jackson organize ?\n",
        " What is New York s state bird ?\n",
        " What is the National Park in Utah ?\n",
        " What is Susan B. Anthony s birthday ?\n",
        " In which state would you find the Catskill Mountains ?\n",
        " What do you call a word that is spelled the same backwards and forwards ?\n",
        " What are pediatricians ?\n",
        " What chain store is headquartered in Bentonville\n",
        " What are solar cells ?\n",
        " What is compounded interest ?\n",
        " What are capers ?\n",
        " What is an antigen ?\n",
        " What currency does Luxembourg use ?\n",
        " What is the population of Venezuela ?\n",
        " What type of polymer is used for bulletproof vests ?\n",
        " What currency does Argentina use ?\n",
        " What is a thermometer ?\n",
        " What Canadian city has the largest population ?\n",
        " What color are crickets ?\n",
        " Which country gave New York the Statue of Liberty ?\n",
        " What was the name of the first U.S. satellite sent into space ?\n",
        " What precious stone is a form of pure carbon ?\n",
        " What kind of gas is in a fluorescent bulb ?\n",
        " What is rheumatoid arthritis ?\n",
        " What river runs through Rowe\n",
        " What is cerebral palsy ?\n",
        " What city is also known as  The Gateway to the West  ?\n",
        " How far away is the moon ?\n",
        " What is the source of natural gas ?\n",
        " In what spacecraft did U.S. astronaut Alan Shepard make his historic 1961 flight ?\n",
        " What is pectin ?\n",
        " What is bio-diversity ?\n",
        " What s the easiest way to remove wallpaper ?\n",
        " What year did the Titanic start on its journey ?\n",
        " How much of an apple is water ?\n",
        " Who was the 22nd President of the US ?\n",
        " What is the money they use in Zambia ?\n",
        " How many feet in a mile ?\n",
        " What is the birthstone of October ?\n",
        " What is e-coli ?\n",
        "\n",
        "\n",
        "\n",
        "'''\n",
        "\n",
        "# Dividir o texto em sentenças\n",
        "sentences = sent_tokenize(text)\n",
        "# Classificar cada sentença individualmente\n",
        "for sentence in sentences:\n",
        "    predicted_label = classify_question(sentence)\n",
        "    print(f\"Sentence: {sentence}\")\n",
        "    print(f\"Predicted Label: {predicted_label}\\n\")\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "9a21f5cb59334b87bf88778ace59b233": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0d6d878f31a7486eb711a9df7f2f8416",
              "IPY_MODEL_64fa51f191a34d95b71b43dd5262d908",
              "IPY_MODEL_75adc85ad5a0491f9b7ce80a80716f87"
            ],
            "layout": "IPY_MODEL_1b65832dd18545f4b966eb4fcd35ff1f"
          }
        },
        "0d6d878f31a7486eb711a9df7f2f8416": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_628fc8339d0e44af8fbab2a6af4f79ec",
            "placeholder": "​",
            "style": "IPY_MODEL_009a91515e8846edac4ef20be29014e9",
            "value": "config.json: 100%"
          }
        },
        "64fa51f191a34d95b71b43dd5262d908": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fd0e9069580943888f7f5f64b827cf20",
            "max": 570,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6c60348aedfb4b3e92471904270519bb",
            "value": 570
          }
        },
        "75adc85ad5a0491f9b7ce80a80716f87": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a5a450af5a5d42fcb138fc7bfee7403f",
            "placeholder": "​",
            "style": "IPY_MODEL_9fcff26dda244381be993917b516a9b3",
            "value": " 570/570 [00:00&lt;00:00, 46.5kB/s]"
          }
        },
        "1b65832dd18545f4b966eb4fcd35ff1f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "628fc8339d0e44af8fbab2a6af4f79ec": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "009a91515e8846edac4ef20be29014e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fd0e9069580943888f7f5f64b827cf20": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6c60348aedfb4b3e92471904270519bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a5a450af5a5d42fcb138fc7bfee7403f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9fcff26dda244381be993917b516a9b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "25bc61ddf9394550ad8db1e31596c378": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3b2c7a4b9eec41f9a0111826b0e449a5",
              "IPY_MODEL_8a366b05f1904b8480dedef846ecea7d",
              "IPY_MODEL_000c4bee81da46b885fdf2fb6d3d674a"
            ],
            "layout": "IPY_MODEL_91d85aef51a44af2b2c52b4a8e01ce2f"
          }
        },
        "3b2c7a4b9eec41f9a0111826b0e449a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f9471716df1344af87261b1af26a6834",
            "placeholder": "​",
            "style": "IPY_MODEL_063a295338614e538721e088877bde5c",
            "value": "model.safetensors: 100%"
          }
        },
        "8a366b05f1904b8480dedef846ecea7d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9501de1fb478463a9ac0301aee08ca23",
            "max": 435755784,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0853add93b45427cad0bbb67a13bf0ac",
            "value": 435755784
          }
        },
        "000c4bee81da46b885fdf2fb6d3d674a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6ce0e5ccfe854f1a876988e271273195",
            "placeholder": "​",
            "style": "IPY_MODEL_91a3a1a5b0b74e89920feb296f59aeb2",
            "value": " 436M/436M [00:02&lt;00:00, 159MB/s]"
          }
        },
        "91d85aef51a44af2b2c52b4a8e01ce2f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f9471716df1344af87261b1af26a6834": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "063a295338614e538721e088877bde5c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9501de1fb478463a9ac0301aee08ca23": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0853add93b45427cad0bbb67a13bf0ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6ce0e5ccfe854f1a876988e271273195": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "91a3a1a5b0b74e89920feb296f59aeb2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fdf7f385fe8347de8cc2057a45842ca8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5f2e004a3ebd4be59ba2651622b8e8a6",
              "IPY_MODEL_e11f7ab14986410e82e0a6a72ba01f22",
              "IPY_MODEL_eb5c3e6a8dce4528ba7cef0ffd39b805"
            ],
            "layout": "IPY_MODEL_893adb802cf04a24ad876c67e1eae70c"
          }
        },
        "5f2e004a3ebd4be59ba2651622b8e8a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_073bf6a5a2294eb79bdf72110ee13629",
            "placeholder": "​",
            "style": "IPY_MODEL_42f6b5b7b44142659d0204bc3e8898e0",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "e11f7ab14986410e82e0a6a72ba01f22": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3246a158f2e8432cb5e602aa33f0fae2",
            "max": 49,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_dcd7a4bd423442a1b00136cd77d6e9c7",
            "value": 49
          }
        },
        "eb5c3e6a8dce4528ba7cef0ffd39b805": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6f2e60db4d954148b8bdcc2603c9d9b2",
            "placeholder": "​",
            "style": "IPY_MODEL_9e0aa2dc9db24a8983d22758285784fc",
            "value": " 49.0/49.0 [00:00&lt;00:00, 4.21kB/s]"
          }
        },
        "893adb802cf04a24ad876c67e1eae70c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "073bf6a5a2294eb79bdf72110ee13629": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "42f6b5b7b44142659d0204bc3e8898e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3246a158f2e8432cb5e602aa33f0fae2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dcd7a4bd423442a1b00136cd77d6e9c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6f2e60db4d954148b8bdcc2603c9d9b2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9e0aa2dc9db24a8983d22758285784fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "011a4c0c8ea94a25b147ee45edada1d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_10bd7328a03f4289a85a058713b90701",
              "IPY_MODEL_ad2badd2f89646b4a2eb4608bb42203b",
              "IPY_MODEL_657fd587a36f42478b08d4f94c02ed89"
            ],
            "layout": "IPY_MODEL_50b819c91cb94d449805be3dca3191fb"
          }
        },
        "10bd7328a03f4289a85a058713b90701": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_55c6ef6cf98f4fccb5e4179abb69c6c2",
            "placeholder": "​",
            "style": "IPY_MODEL_c173eb4c372a480db771517061628a00",
            "value": "vocab.txt: 100%"
          }
        },
        "ad2badd2f89646b4a2eb4608bb42203b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cc7a8238e5404c54889823326ab82729",
            "max": 213450,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ccc8389be70f43c693c77458efba44d1",
            "value": 213450
          }
        },
        "657fd587a36f42478b08d4f94c02ed89": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6a243193714c4aefa154916cfff9968f",
            "placeholder": "​",
            "style": "IPY_MODEL_2714b7ba9ffd4901bd17e935eb208b95",
            "value": " 213k/213k [00:00&lt;00:00, 12.4MB/s]"
          }
        },
        "50b819c91cb94d449805be3dca3191fb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "55c6ef6cf98f4fccb5e4179abb69c6c2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c173eb4c372a480db771517061628a00": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cc7a8238e5404c54889823326ab82729": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ccc8389be70f43c693c77458efba44d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6a243193714c4aefa154916cfff9968f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2714b7ba9ffd4901bd17e935eb208b95": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6911421a843844a58937aa2997005a6f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1d19b47d5c78419bb4a5689110f8cfb3",
              "IPY_MODEL_17d5ae7a300b49648fc36393bf975152",
              "IPY_MODEL_cea6feff0311474bb22796a487ef52d2"
            ],
            "layout": "IPY_MODEL_f4595f15494645f29c0214d396c202a5"
          }
        },
        "1d19b47d5c78419bb4a5689110f8cfb3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cf52d3b7cd4242e98063810baae49ea8",
            "placeholder": "​",
            "style": "IPY_MODEL_681f5fec5ac94317beab08b2508b8f67",
            "value": "tokenizer.json: 100%"
          }
        },
        "17d5ae7a300b49648fc36393bf975152": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b77df58e65504b79b83506e78d1f4f50",
            "max": 435797,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d2f258d7588b49519b9d5cd5ee1d8019",
            "value": 435797
          }
        },
        "cea6feff0311474bb22796a487ef52d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ead69b417e754be6a4132868e75928b0",
            "placeholder": "​",
            "style": "IPY_MODEL_c989f4f3b7df46958d773423df5349e9",
            "value": " 436k/436k [00:00&lt;00:00, 2.02MB/s]"
          }
        },
        "f4595f15494645f29c0214d396c202a5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cf52d3b7cd4242e98063810baae49ea8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "681f5fec5ac94317beab08b2508b8f67": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b77df58e65504b79b83506e78d1f4f50": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d2f258d7588b49519b9d5cd5ee1d8019": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ead69b417e754be6a4132868e75928b0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c989f4f3b7df46958d773423df5349e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}